{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation for NLP Baseline Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from ast import literal_eval\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig\n",
    "from huggingface_hub import HfFolder\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "HfFolder.save_token(\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2276, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 읽기\n",
    "kmmlu_dataset = pd.read_csv('./kmmlu/kmmlu_korean_history_processed.csv')\n",
    "mmmlu_history_dataset = pd.read_csv('./mmmlu/mmmlu_history.csv')\n",
    "mmmlu_others_dataset = pd.read_csv('./mmmlu/mmmlu_others.csv')\n",
    "\n",
    "# 각 데이터셋을 동일한 형식으로 변환\n",
    "def process_dataset(dataset):\n",
    "    records = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        record = {\n",
    "            'id': row['id'],\n",
    "            'paragraph': row['paragraph'],\n",
    "            'question': row['question'],\n",
    "            'choices': row['choices'],\n",
    "            'answer': row.get('answer', None),\n",
    "        }\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "kmmlu_df = process_dataset(kmmlu_dataset)\n",
    "mmmlu_history_df = process_dataset(mmmlu_history_dataset)\n",
    "mmmlu_others_df = process_dataset(mmmlu_others_dataset)\n",
    "\n",
    "# 3개의 데이터프레임 연결\n",
    "df = pd.concat([kmmlu_df, mmmlu_history_df, mmmlu_others_df], ignore_index=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>mmlu_high_school_psychology_1559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>학생을 장애자로 분류하는 것에 대한 일반적인 비판은 개인들은 하나의 분류와 관련된 ...</td>\n",
       "      <td>['자기실현적 예언', '효과의 법칙', '초두효과', '사회적 태만']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>mmlu_high_school_psychology_1560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott은 맞는 단어의 철자를 찾기 위해 NEBOTYA라는 글자를 20분 동안 고...</td>\n",
       "      <td>['고전적 조건화', '조작적 조건화', '효과의 법칙', '통찰']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>mmlu_high_school_psychology_1561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>처음 성격검사에서는 극도로 외향적이었고 다음 번 검사에서는 극도로 내성적이었다고 알...</td>\n",
       "      <td>['이 성격검사는 신뢰도는 낮지만 타당도는 높습니다.', '이 검사는 아마도 구성 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>mmlu_high_school_psychology_1562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>정서적 애착에 대한 할로우(Harlow)의 연구에서 새끼 원숭이들을 우리에 넣고 \"...</td>\n",
       "      <td>['우유병이 배치된 \"엄마\"', '\"철사로 만든\" 엄마 대 \"헝겊으로 만든\" 엄마'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>mmlu_high_school_psychology_1563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoe의 신경성 식욕부진증을 치료하기 위해 그녀의 의사는 그녀에게 정맥주사로 영양을...</td>\n",
       "      <td>['인지행동적.', '생물학적.', '정신역동적.', '절충주의적.']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id paragraph  \\\n",
       "2271  mmlu_high_school_psychology_1559       NaN   \n",
       "2272  mmlu_high_school_psychology_1560       NaN   \n",
       "2273  mmlu_high_school_psychology_1561       NaN   \n",
       "2274  mmlu_high_school_psychology_1562       NaN   \n",
       "2275  mmlu_high_school_psychology_1563       NaN   \n",
       "\n",
       "                                               question  \\\n",
       "2271  학생을 장애자로 분류하는 것에 대한 일반적인 비판은 개인들은 하나의 분류와 관련된 ...   \n",
       "2272  Scott은 맞는 단어의 철자를 찾기 위해 NEBOTYA라는 글자를 20분 동안 고...   \n",
       "2273  처음 성격검사에서는 극도로 외향적이었고 다음 번 검사에서는 극도로 내성적이었다고 알...   \n",
       "2274  정서적 애착에 대한 할로우(Harlow)의 연구에서 새끼 원숭이들을 우리에 넣고 \"...   \n",
       "2275  Zoe의 신경성 식욕부진증을 치료하기 위해 그녀의 의사는 그녀에게 정맥주사로 영양을...   \n",
       "\n",
       "                                                choices  answer  \n",
       "2271           ['자기실현적 예언', '효과의 법칙', '초두효과', '사회적 태만']       1  \n",
       "2272             ['고전적 조건화', '조작적 조건화', '효과의 법칙', '통찰']       4  \n",
       "2273  ['이 성격검사는 신뢰도는 낮지만 타당도는 높습니다.', '이 검사는 아마도 구성 ...       4  \n",
       "2274  ['우유병이 배치된 \"엄마\"', '\"철사로 만든\" 엄마 대 \"헝겊으로 만든\" 엄마'...       1  \n",
       "2275            ['인지행동적.', '생물학적.', '정신역동적.', '절충주의적.']       4  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "id              0\n",
      "paragraph    1564\n",
      "question        0\n",
      "choices         0\n",
      "answer          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "- https://huggingface.co/beomi/gemma-ko-2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 본인의 Huggingface auth token 입력\n",
    "## Jupyter lab에서 로그인 하는 textbox가 나오지 않을 경우, terminal에서 로그인 하실 수 있습니다.\n",
    "#!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델과 토크나이저를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c8131d8abc4da0ab9f8c3ae442e404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",  # 양자화 지원 장치에 자동 매핑\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\\n' + content + '<end_of_turn>\\n<start_of_turn>model\\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\\n' }}{% endif %}{% endfor %}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=6,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=['q_proj', 'k_proj'],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_PARAGRAPH = \"\"\"지문: \n",
    "{paragraph}\n",
    "\n",
    "질문: \n",
    "{question}\n",
    "\n",
    "선택지: \n",
    "{choices}\n",
    "\n",
    "풀이 과정:\n",
    "1) 먼저 지문을 꼼꼼히 읽고 핵심 내용을 파악합니다.\n",
    "2) 질문이 요구하는 바를 정확히 이해합니다.\n",
    "3) 지문의 내용과 질문을 연결지어 생각합니다.\n",
    "4) 각 선택지를 하나씩 검토하며 지문의 내용과 부합하는지 확인합니다.\n",
    "5) 가장 적절한 답을 선택하고, 그 이유를 설명합니다.\n",
    "정답:\"\"\"\n",
    "\n",
    "PROMPT_NO_PARAGRAPH = \"\"\"질문: \n",
    "{question}\n",
    "\n",
    "선택지: \n",
    "{choices}\n",
    "\n",
    "풀이 과정:\n",
    "1) 질문이 요구하는 바를 정확히 이해합니다.\n",
    "2) 질문과 관련된 배경 지식을 떠올립니다.\n",
    "3) 각 선택지를 하나씩 검토하며 질문의 맥락에 부합하는지 확인합니다.\n",
    "4) 논리적으로 가장 타당한 답을 선택하고, 그 이유를 설명합니다.\n",
    "5) 다른 선택지들이 왜 적절하지 않은지도 간단히 설명합니다.\n",
    "정답:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['ㄱ, ㄴ', 'ㄱ, ㄷ', 'ㄴ, ㄹ', 'ㄷ, ㄹ']\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n",
    "dataset[0]['choices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "processed_dataset = []\n",
    "for i in range(len(dataset)):\n",
    "    choices_string = \"\\n\".join([f\"{idx + 1} - {choice}\" for idx, choice in enumerate(ast.literal_eval(dataset[i]['choices']))])\n",
    "\n",
    "    # <보기>가 있을 때\n",
    "    if dataset[i][\"paragraph\"]:\n",
    "        user_message = PROMPT_PARAGRAPH.format(\n",
    "            paragraph=dataset[i][\"paragraph\"],\n",
    "            question=dataset[i][\"question\"],\n",
    "            choices=choices_string,\n",
    "        )\n",
    "    # <보기>가 없을 때\n",
    "    else:\n",
    "        user_message = PROMPT_NO_PARAGRAPH.format(\n",
    "            question=dataset[i][\"question\"],\n",
    "            choices=choices_string,\n",
    "        )\n",
    "\n",
    "    # chat message 형식으로 변환\n",
    "    processed_dataset.append(\n",
    "        {\n",
    "            \"id\": dataset[i][\"id\"],\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"당신은 수능을 준비하는 고등학생입니다. 차근차근 생각하면서 가장 적절한 답을 고르십시오.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "                {\"role\": \"assistant\", \"content\": f\"{dataset[i]['answer']}\"}\n",
    "            ],\n",
    "            \"label\": dataset[i][\"answer\"],\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'kmmlu_korean_history_0',\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': '당신은 수능을 준비하는 고등학생입니다. 차근차근 생각하면서 가장 적절한 답을 고르십시오.'},\n",
       "  {'role': 'user',\n",
       "   'content': '지문: \\n상소하여 아뢰기를 , “신이 좌참 찬 송준길이 올린 차자를 보았는데 , 상복(喪服) 절차에 대하여 논한 것이 신과는 큰 차이가 있었습니다 . 장자를 위하여 3년을 입는 까닭은 위로 ‘정체(正體)’가 되기 때문이고 또 전 중(傳重: 조상의 제사나 가문의 법통을 전함)하기 때 문입니다 . …(중략) … 무엇보다 중요한 것은 할아버지와 아버지의 뒤를 이은 ‘정체’이지, 꼭 첫째이기 때문에 참 최 3년 복을 입는 것은 아닙니다 .”라고 하였다 .－현종실록 －ㄱ.기 사환국으로 정권을 장악하였다 .ㄴ.인 조반정을 주도 하여 집권세력이 되었다 .ㄷ.정조 시기에 탕평 정치의 한 축을 이루었다 .ㄹ.이 이와 성혼의 문인을 중심으로 형성되었다 .\\n\\n질문: \\n다음과 같이 상소한 인물이 속한 붕당에 대한 설명으로 옳은 것만을 모두 고르면 ?\\n\\n선택지: \\n1 - ㄱ, ㄴ\\n2 - ㄱ, ㄷ\\n3 - ㄴ, ㄹ\\n4 - ㄷ, ㄹ\\n\\n정답:'},\n",
       "  {'role': 'assistant', 'content': '2'}],\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'messages', 'label'],\n",
       "    num_rows: 2276\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = Dataset.from_pandas(pd.DataFrame(processed_dataset))\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddb872ed1234f67a73143448053edcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing (num_proc=4):   0%|          | 0/2276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example[\"messages\"])):\n",
    "        output_texts.append(\n",
    "            tokenizer.apply_chat_template(\n",
    "                example[\"messages\"][i],\n",
    "                tokenize=False,\n",
    "            )\n",
    "        )\n",
    "    return output_texts\n",
    "\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        formatting_prompts_func(element),\n",
    "        truncation=False,\n",
    "        padding=False,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=False,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "# 데이터 토큰화\n",
    "tokenized_dataset = processed_dataset.map(\n",
    "    tokenize,\n",
    "    remove_columns=list(processed_dataset.features),\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Tokenizing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6a16d500884d5cb3ac19062c6840d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신은 수능을 준비하는 고등학생입니다. 차근차근 생각하면서 가장 적절한 답을 고르십시오.<start_of_turn>user\n",
      "지문: \n",
      "이 질문은 다음 정보를 참조한다.\n",
      "그러나 로마의 쇠락은 지나친 위대함의 자연스럽고 필연적인 결과였다. 번영은 부패의 법칙을 익어가게 했다. 정복 범위가 넓은 만큼 파멸의 원인이 더 늘어났으며 시간 또는 사건이 인공의 지지를 제거하자마자 로마라는 거대한 무언가는 스스로의 무게를 버티지 못했다. 먼 옛날의 전쟁에서 이방인과 용병의 악행으로 승리한 부대는 먼저 공화국의 자유를 억압했고 그 다음엔 보라색의 왕권을 위협했다. 자신의 안위와 공공의 평화를 잃을까 두려워한 황제들은 자신들을 국가 내외부로 단결시켜주던 엄격한 규율을 타락시키는 기초 방편으로 전락했다. 이로 인해 군의 사기는 바닥을 쳤다. 이렇게 로마의 세상은 몰려오는 야만인들에게 정복당했다.\n",
      "—에드워드 기번, <로마제국 쇠망사>에서 발췌\n",
      "\n",
      "질문: \n",
      "위 글의 저자는 다음과 같이 주장했습니다. “번영은 부패의 법칙을 익어가게 했다. 정복 범위가 넓은 만금 파멸의 원인이 더 늘어났다.” 저자가 위 문구에서 의미한 바는?\n",
      "\n",
      "선택지: \n",
      "1 - 지배자들이 지나치게 부유해져서 전복되었다.\n",
      "2 - 제국을 효과적으로 지배하기엔 너무 커졌다.\n",
      "3 - 무언가 자라기 시작하면서 부패가 시작되었다.\n",
      "4 - 정복과 번영은 상호 배타적이다.\n",
      "\n",
      "정답:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "2<end_of_turn>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "# vram memory 제약으로 인해 인풋 데이터의 길이가 1024 초과인 데이터는 제외하였습니다. *힌트: 1024보다 길이가 더 긴 데이터를 포함하면 더 높은 점수를 달성할 수 있을 것 같습니다!\n",
    "# over_tokenized_dataset = tokenized_dataset.filter(lambda x: len(x[\"input_ids\"]) > 1024)\n",
    "tokenized_dataset = tokenized_dataset.filter(lambda x: len(x[\"input_ids\"]) <= 1024)\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "train_dataset = tokenized_dataset['train']\n",
    "eval_dataset = tokenized_dataset['test']\n",
    "# 데이터 확인\n",
    "print(tokenizer.decode(train_dataset[100][\"input_ids\"], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신은 수능을 준비하는 고등학생입니다. 차근차근 생각하면서 가장 적절한 답을 고르십시오.<start_of_turn>user\n",
      "질문: \n",
      "1954년 브라운 대 교육위원회 사건에 따르면, 1896년 플레시 대 퍼거슨 사건에서 확립된 “분리 평등 정책” 원칙이 위반한 수정헌법은 다음 중 어느 것입니까?\n",
      "\n",
      "선택지: \n",
      "1 - 수정헌법 제1조\n",
      "2 - 수정헌법 제6조\n",
      "3 - 수정헌법 제9조\n",
      "4 - 수정헌법 제14조\n",
      "\n",
      "정답:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "4<end_of_turn>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completion 부분만 학습하기 위한 data collator 설정\n",
    "\n",
    "- 텍스트 중 response_template 까지는 ignore_index 로 loss 계산에서 제외\n",
    "- 텍스트 중 response_template 이후는 학습에 포함 (정답 + eos 토큰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = \"<start_of_turn>model\"\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 logits 를 조정하여 정답 토큰 부분만 출력하도록 설정\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    logits = logits if not isinstance(logits, tuple) else logits[0]\n",
    "    logit_idx = [tokenizer.vocab[\"1\"], tokenizer.vocab[\"2\"], tokenizer.vocab[\"3\"], tokenizer.vocab[\"4\"], tokenizer.vocab[\"5\"]]\n",
    "    logits = logits[:, -2, logit_idx] # -2: answer token, -1: eos token\n",
    "    logits = logits.float()\n",
    "    return logits\n",
    "\n",
    "# metric 로드\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# 정답 토큰 매핑\n",
    "int_output_map = {\"1\": 0, \"2\": 1, \"3\": 2, \"4\": 3, \"5\": 4}\n",
    "\n",
    "# metric 계산 함수\n",
    "def compute_metrics(evaluation_result):\n",
    "    logits, labels = evaluation_result\n",
    "\n",
    "    # 토큰화된 레이블 디코딩\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    labels = list(map(lambda x: x.split(\"<end_of_turn>\")[0].strip(), labels))\n",
    "    labels = list(map(lambda x: int_output_map[x], labels))\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 로그트 변환\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)\n",
    "    predictions = np.argmax(probs, axis=-1)\n",
    "\n",
    "    # 정확도 계산\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '<|im_end|>',\n",
       " 'pad_token': '<|im_end|>',\n",
       " 'additional_special_tokens': ['<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<|object_ref_start|>',\n",
       "  '<|object_ref_end|>',\n",
       "  '<|box_start|>',\n",
       "  '<|box_end|>',\n",
       "  '<|quad_start|>',\n",
       "  '<|quad_end|>',\n",
       "  '<|vision_start|>',\n",
       "  '<|vision_end|>',\n",
       "  '<|vision_pad|>',\n",
       "  '<|image_pad|>',\n",
       "  '<|video_pad|>']}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad token 설정\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_seq_length=1024,\n",
    "    output_dir=\"outputs_finetune\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    save_only_model=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"chris40461/qwen-finetuned-korean-exam-mcq\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6132' max='6132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6132/6132 1:42:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.176178</td>\n",
       "      <td>0.197368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>0.176522</td>\n",
       "      <td>0.201754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.185353</td>\n",
       "      <td>0.206140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 13min, sys: 28min 42s, total: 1h 41min 42s\n",
      "Wall time: 1h 42min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6132, training_loss=0.16208461944469138, metrics={'train_runtime': 6122.1663, 'train_samples_per_second': 1.002, 'train_steps_per_second': 1.002, 'total_flos': 6.92006916088535e+16, 'train_loss': 0.16208461944469138, 'epoch': 3.0})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/chris40461/qwen-finetuned-korean-exam-mcq/commit/7b042da62fc02c3957253776de3eff38ca6f6c4a', commit_message='End of training', commit_description='', oid='7b042da62fc02c3957253776de3eff38ca6f6c4a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/chris40461/qwen-finetuned-korean-exam-mcq', endpoint='https://huggingface.co', repo_type='model', repo_id='chris40461/qwen-finetuned-korean-exam-mcq'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
