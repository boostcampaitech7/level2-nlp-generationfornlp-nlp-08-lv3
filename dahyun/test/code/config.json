{
    "random_seed": 42,
    "train_data_path": "../data/shuffle_data.csv",
    "test_data_path": "../data/test.csv",
    "output_dir": "../new_prompt",
    "model_name": "Qwen/Qwen2.5-3B-Instruct",
    "checkpoint_path": "/data/ephemeral/home/level2-nlp-generationfornlp-nlp-08-lv3/test/max_length_4096/checkpoint-20250",
    "max_features": 1000,
    "use_lora": true,
    "lora_r": 6,
    "lora_alpha": 8,
    "lora_dropout": 0.05,
    "lora_target_modules": ["q_proj", "k_proj"],
    "lora_bias": "none",
    "lora_task_type": "CAUSAL_LM",
    "max_length": 2048,

    "sft_config": {
        "do_train": true,
        "do_eval": true,
        "lr_scheduler_type": "cosine",
        "max_seq_length": 2048,
        "output_dir": "../new_prompt",
        "per_device_train_batch_size": 1,
        "per_device_eval_batch_size": 1,
        "num_train_epochs": 6,
        "learning_rate": 2e-5,
        "weight_decay": 0.01,
        "logging_steps": 10,
        "logging_strategy": "epoch",
        "save_strategy": "epoch",
        "eval_strategy": "epoch",
        "save_total_limit": 2,
        "save_only_model": true,
        "report_to": "none",
        "fp16": true
    },

    "prompts": {
        "PROMPT_NO_QUESTION_PLUS_PATH": "../prompts/qwen.txt",
        "PROMPT_QUESTION_PLUS_PATH": "../prompts/qwen_question_plus.txt"
    }
}