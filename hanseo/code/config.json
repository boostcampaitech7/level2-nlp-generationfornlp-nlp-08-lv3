{
    "random_seed": 42,
    "train_data_path": "../data/train.csv",
    "test_data_path": "../data/test.csv",
    "output_dir": "../output_gemma-ko-7b",
    "model_name": "beomi/gemma-ko-7b",
    "checkpoint_path": "../output_gemma-ko-7b/checkpoint-5337",
    "max_features": 1000,
    "use_lora": true,
    "lora_r": 6,
    "lora_alpha": 8,
    "lora_dropout": 0.05,
    "lora_target_modules": ["q_proj", "k_proj"],
    "lora_bias": "none",
    "lora_task_type": "CAUSAL_LM",

    "sft_config": {
        "do_train": true,
        "do_eval": true,
        "lr_scheduler_type": "cosine",
        "max_seq_length": 1024,
        "output_dir": "../output_gemma-ko-7b",
        "per_device_train_batch_size": 1,
        "per_device_eval_batch_size": 1,
        "num_train_epochs": 3,
        "learning_rate": 2e-5,
        "weight_decay": 0.01,
        "logging_steps": 1,
        "logging_strategy": "epoch",
        "save_strategy": "epoch",
        "eval_strategy": "epoch",
        "save_total_limit": 2,
        "save_only_model": true,
        "report_to": "none"
    },

    "prompts": {
        "PROMPT_NO_QUESTION_PLUS_PATH": "../prompts/prompt_no_question_plus.txt",
        "PROMPT_QUESTION_PLUS_PATH": "../prompts/prompt_question_plus.txt"
    }
}