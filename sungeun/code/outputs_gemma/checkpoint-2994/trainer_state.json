{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2994,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006680026720106881,
      "grad_norm": 1.06200110912323,
      "learning_rate": 1.9999997553283666e-05,
      "loss": 1.3952,
      "step": 1
    },
    {
      "epoch": 0.0013360053440213762,
      "grad_norm": 0.7651222944259644,
      "learning_rate": 1.999999021313585e-05,
      "loss": 1.4846,
      "step": 2
    },
    {
      "epoch": 0.002004008016032064,
      "grad_norm": 0.704284131526947,
      "learning_rate": 1.9999977979560148e-05,
      "loss": 1.4992,
      "step": 3
    },
    {
      "epoch": 0.0026720106880427524,
      "grad_norm": 0.724556565284729,
      "learning_rate": 1.999996085256255e-05,
      "loss": 1.4904,
      "step": 4
    },
    {
      "epoch": 0.0033400133600534404,
      "grad_norm": 0.7023782730102539,
      "learning_rate": 1.999993883215143e-05,
      "loss": 1.4847,
      "step": 5
    },
    {
      "epoch": 0.004008016032064128,
      "grad_norm": 0.7228637933731079,
      "learning_rate": 1.999991191833757e-05,
      "loss": 1.5063,
      "step": 6
    },
    {
      "epoch": 0.004676018704074816,
      "grad_norm": 0.6863317489624023,
      "learning_rate": 1.9999880111134135e-05,
      "loss": 1.5759,
      "step": 7
    },
    {
      "epoch": 0.005344021376085505,
      "grad_norm": 0.895513117313385,
      "learning_rate": 1.9999843410556696e-05,
      "loss": 1.3728,
      "step": 8
    },
    {
      "epoch": 0.006012024048096192,
      "grad_norm": 0.7713075280189514,
      "learning_rate": 1.9999801816623205e-05,
      "loss": 1.386,
      "step": 9
    },
    {
      "epoch": 0.006680026720106881,
      "grad_norm": 0.9083328247070312,
      "learning_rate": 1.9999755329354018e-05,
      "loss": 1.3362,
      "step": 10
    },
    {
      "epoch": 0.007348029392117568,
      "grad_norm": 0.7254723310470581,
      "learning_rate": 1.9999703948771886e-05,
      "loss": 1.4697,
      "step": 11
    },
    {
      "epoch": 0.008016032064128256,
      "grad_norm": 0.7012404799461365,
      "learning_rate": 1.999964767490195e-05,
      "loss": 1.5939,
      "step": 12
    },
    {
      "epoch": 0.008684034736138945,
      "grad_norm": 0.9833840131759644,
      "learning_rate": 1.9999586507771748e-05,
      "loss": 1.5813,
      "step": 13
    },
    {
      "epoch": 0.009352037408149633,
      "grad_norm": 0.8863595128059387,
      "learning_rate": 1.999952044741121e-05,
      "loss": 1.4305,
      "step": 14
    },
    {
      "epoch": 0.01002004008016032,
      "grad_norm": 0.7956699728965759,
      "learning_rate": 1.9999449493852664e-05,
      "loss": 1.5102,
      "step": 15
    },
    {
      "epoch": 0.01068804275217101,
      "grad_norm": 0.8138089776039124,
      "learning_rate": 1.9999373647130827e-05,
      "loss": 1.3692,
      "step": 16
    },
    {
      "epoch": 0.011356045424181697,
      "grad_norm": 0.9804752469062805,
      "learning_rate": 1.9999292907282816e-05,
      "loss": 1.5143,
      "step": 17
    },
    {
      "epoch": 0.012024048096192385,
      "grad_norm": 0.9921054840087891,
      "learning_rate": 1.9999207274348143e-05,
      "loss": 1.3757,
      "step": 18
    },
    {
      "epoch": 0.012692050768203072,
      "grad_norm": 0.9597827792167664,
      "learning_rate": 1.999911674836871e-05,
      "loss": 1.4334,
      "step": 19
    },
    {
      "epoch": 0.013360053440213761,
      "grad_norm": 0.894804060459137,
      "learning_rate": 1.9999021329388816e-05,
      "loss": 1.4419,
      "step": 20
    },
    {
      "epoch": 0.014028056112224449,
      "grad_norm": 0.8821656107902527,
      "learning_rate": 1.9998921017455154e-05,
      "loss": 1.4495,
      "step": 21
    },
    {
      "epoch": 0.014696058784235137,
      "grad_norm": 1.7597476243972778,
      "learning_rate": 1.999881581261681e-05,
      "loss": 1.4965,
      "step": 22
    },
    {
      "epoch": 0.015364061456245824,
      "grad_norm": 1.796649694442749,
      "learning_rate": 1.9998705714925263e-05,
      "loss": 1.4634,
      "step": 23
    },
    {
      "epoch": 0.01603206412825651,
      "grad_norm": 0.8942387700080872,
      "learning_rate": 1.9998590724434392e-05,
      "loss": 1.4053,
      "step": 24
    },
    {
      "epoch": 0.016700066800267203,
      "grad_norm": 1.3708692789077759,
      "learning_rate": 1.9998470841200464e-05,
      "loss": 1.4108,
      "step": 25
    },
    {
      "epoch": 0.01736806947227789,
      "grad_norm": 0.9328625202178955,
      "learning_rate": 1.9998346065282148e-05,
      "loss": 1.358,
      "step": 26
    },
    {
      "epoch": 0.018036072144288578,
      "grad_norm": 0.8382714986801147,
      "learning_rate": 1.9998216396740497e-05,
      "loss": 1.2793,
      "step": 27
    },
    {
      "epoch": 0.018704074816299265,
      "grad_norm": 1.492112398147583,
      "learning_rate": 1.9998081835638967e-05,
      "loss": 1.4611,
      "step": 28
    },
    {
      "epoch": 0.019372077488309953,
      "grad_norm": 0.926470935344696,
      "learning_rate": 1.99979423820434e-05,
      "loss": 1.3809,
      "step": 29
    },
    {
      "epoch": 0.02004008016032064,
      "grad_norm": 1.2126926183700562,
      "learning_rate": 1.9997798036022043e-05,
      "loss": 1.4157,
      "step": 30
    },
    {
      "epoch": 0.020708082832331328,
      "grad_norm": 1.0316765308380127,
      "learning_rate": 1.9997648797645527e-05,
      "loss": 1.1795,
      "step": 31
    },
    {
      "epoch": 0.02137608550434202,
      "grad_norm": 1.0768158435821533,
      "learning_rate": 1.9997494666986882e-05,
      "loss": 1.4069,
      "step": 32
    },
    {
      "epoch": 0.022044088176352707,
      "grad_norm": 1.190202236175537,
      "learning_rate": 1.9997335644121527e-05,
      "loss": 1.3046,
      "step": 33
    },
    {
      "epoch": 0.022712090848363394,
      "grad_norm": 1.274343729019165,
      "learning_rate": 1.9997171729127282e-05,
      "loss": 1.4512,
      "step": 34
    },
    {
      "epoch": 0.02338009352037408,
      "grad_norm": 0.9759668707847595,
      "learning_rate": 1.999700292208436e-05,
      "loss": 1.2647,
      "step": 35
    },
    {
      "epoch": 0.02404809619238477,
      "grad_norm": 1.2521641254425049,
      "learning_rate": 1.9996829223075363e-05,
      "loss": 1.4089,
      "step": 36
    },
    {
      "epoch": 0.024716098864395457,
      "grad_norm": 1.250152587890625,
      "learning_rate": 1.9996650632185288e-05,
      "loss": 1.3661,
      "step": 37
    },
    {
      "epoch": 0.025384101536406144,
      "grad_norm": 1.3633944988250732,
      "learning_rate": 1.999646714950153e-05,
      "loss": 1.4218,
      "step": 38
    },
    {
      "epoch": 0.026052104208416832,
      "grad_norm": 1.598252773284912,
      "learning_rate": 1.999627877511387e-05,
      "loss": 1.3192,
      "step": 39
    },
    {
      "epoch": 0.026720106880427523,
      "grad_norm": 1.1625661849975586,
      "learning_rate": 1.9996085509114498e-05,
      "loss": 1.2816,
      "step": 40
    },
    {
      "epoch": 0.02738810955243821,
      "grad_norm": 1.291577935218811,
      "learning_rate": 1.9995887351597976e-05,
      "loss": 1.2786,
      "step": 41
    },
    {
      "epoch": 0.028056112224448898,
      "grad_norm": 1.5107008218765259,
      "learning_rate": 1.999568430266128e-05,
      "loss": 1.3815,
      "step": 42
    },
    {
      "epoch": 0.028724114896459586,
      "grad_norm": 0.8983311057090759,
      "learning_rate": 1.9995476362403764e-05,
      "loss": 1.414,
      "step": 43
    },
    {
      "epoch": 0.029392117568470273,
      "grad_norm": 1.4893708229064941,
      "learning_rate": 1.9995263530927184e-05,
      "loss": 1.3956,
      "step": 44
    },
    {
      "epoch": 0.03006012024048096,
      "grad_norm": 1.6887972354888916,
      "learning_rate": 1.999504580833569e-05,
      "loss": 1.2278,
      "step": 45
    },
    {
      "epoch": 0.03072812291249165,
      "grad_norm": 1.4673407077789307,
      "learning_rate": 1.999482319473582e-05,
      "loss": 1.2478,
      "step": 46
    },
    {
      "epoch": 0.03139612558450234,
      "grad_norm": 1.091848611831665,
      "learning_rate": 1.999459569023651e-05,
      "loss": 1.2445,
      "step": 47
    },
    {
      "epoch": 0.03206412825651302,
      "grad_norm": 2.0209009647369385,
      "learning_rate": 1.9994363294949088e-05,
      "loss": 1.3508,
      "step": 48
    },
    {
      "epoch": 0.032732130928523714,
      "grad_norm": 1.040399193763733,
      "learning_rate": 1.9994126008987277e-05,
      "loss": 1.2449,
      "step": 49
    },
    {
      "epoch": 0.033400133600534405,
      "grad_norm": 1.0715171098709106,
      "learning_rate": 1.9993883832467188e-05,
      "loss": 1.2714,
      "step": 50
    },
    {
      "epoch": 0.03406813627254509,
      "grad_norm": 1.4646024703979492,
      "learning_rate": 1.9993636765507327e-05,
      "loss": 1.327,
      "step": 51
    },
    {
      "epoch": 0.03473613894455578,
      "grad_norm": 1.5096782445907593,
      "learning_rate": 1.99933848082286e-05,
      "loss": 1.3459,
      "step": 52
    },
    {
      "epoch": 0.035404141616566465,
      "grad_norm": 1.200183629989624,
      "learning_rate": 1.9993127960754297e-05,
      "loss": 1.3462,
      "step": 53
    },
    {
      "epoch": 0.036072144288577156,
      "grad_norm": 1.2089033126831055,
      "learning_rate": 1.9992866223210105e-05,
      "loss": 1.3647,
      "step": 54
    },
    {
      "epoch": 0.03674014696058784,
      "grad_norm": 1.372495412826538,
      "learning_rate": 1.9992599595724106e-05,
      "loss": 1.2012,
      "step": 55
    },
    {
      "epoch": 0.03740814963259853,
      "grad_norm": 1.362749695777893,
      "learning_rate": 1.999232807842677e-05,
      "loss": 1.0916,
      "step": 56
    },
    {
      "epoch": 0.03807615230460922,
      "grad_norm": 1.4286972284317017,
      "learning_rate": 1.999205167145096e-05,
      "loss": 1.1982,
      "step": 57
    },
    {
      "epoch": 0.038744154976619906,
      "grad_norm": 1.4996998310089111,
      "learning_rate": 1.9991770374931936e-05,
      "loss": 1.2427,
      "step": 58
    },
    {
      "epoch": 0.0394121576486306,
      "grad_norm": 1.1852368116378784,
      "learning_rate": 1.999148418900735e-05,
      "loss": 1.252,
      "step": 59
    },
    {
      "epoch": 0.04008016032064128,
      "grad_norm": 1.2149511575698853,
      "learning_rate": 1.9991193113817244e-05,
      "loss": 1.2632,
      "step": 60
    },
    {
      "epoch": 0.04074816299265197,
      "grad_norm": 2.001677989959717,
      "learning_rate": 1.9990897149504053e-05,
      "loss": 1.3257,
      "step": 61
    },
    {
      "epoch": 0.041416165664662656,
      "grad_norm": 1.4290595054626465,
      "learning_rate": 1.9990596296212606e-05,
      "loss": 1.1611,
      "step": 62
    },
    {
      "epoch": 0.04208416833667335,
      "grad_norm": 1.58809494972229,
      "learning_rate": 1.9990290554090123e-05,
      "loss": 1.1804,
      "step": 63
    },
    {
      "epoch": 0.04275217100868404,
      "grad_norm": 1.4062697887420654,
      "learning_rate": 1.9989979923286217e-05,
      "loss": 1.2429,
      "step": 64
    },
    {
      "epoch": 0.04342017368069472,
      "grad_norm": 1.3530917167663574,
      "learning_rate": 1.9989664403952897e-05,
      "loss": 1.2673,
      "step": 65
    },
    {
      "epoch": 0.04408817635270541,
      "grad_norm": 1.620527744293213,
      "learning_rate": 1.9989343996244553e-05,
      "loss": 1.185,
      "step": 66
    },
    {
      "epoch": 0.0447561790247161,
      "grad_norm": 1.2690937519073486,
      "learning_rate": 1.9989018700317978e-05,
      "loss": 1.2704,
      "step": 67
    },
    {
      "epoch": 0.04542418169672679,
      "grad_norm": 1.6444200277328491,
      "learning_rate": 1.9988688516332356e-05,
      "loss": 1.1748,
      "step": 68
    },
    {
      "epoch": 0.04609218436873747,
      "grad_norm": 1.489427924156189,
      "learning_rate": 1.9988353444449254e-05,
      "loss": 1.1118,
      "step": 69
    },
    {
      "epoch": 0.04676018704074816,
      "grad_norm": 1.5312129259109497,
      "learning_rate": 1.998801348483264e-05,
      "loss": 1.1639,
      "step": 70
    },
    {
      "epoch": 0.047428189712758854,
      "grad_norm": 1.7187039852142334,
      "learning_rate": 1.9987668637648877e-05,
      "loss": 1.2226,
      "step": 71
    },
    {
      "epoch": 0.04809619238476954,
      "grad_norm": 1.674506425857544,
      "learning_rate": 1.9987318903066704e-05,
      "loss": 1.2115,
      "step": 72
    },
    {
      "epoch": 0.04876419505678023,
      "grad_norm": 1.258650302886963,
      "learning_rate": 1.9986964281257268e-05,
      "loss": 1.0629,
      "step": 73
    },
    {
      "epoch": 0.049432197728790914,
      "grad_norm": 1.3225582838058472,
      "learning_rate": 1.9986604772394095e-05,
      "loss": 1.078,
      "step": 74
    },
    {
      "epoch": 0.050100200400801605,
      "grad_norm": 1.4843716621398926,
      "learning_rate": 1.9986240376653113e-05,
      "loss": 1.1311,
      "step": 75
    },
    {
      "epoch": 0.05076820307281229,
      "grad_norm": 1.5231273174285889,
      "learning_rate": 1.9985871094212637e-05,
      "loss": 1.0389,
      "step": 76
    },
    {
      "epoch": 0.05143620574482298,
      "grad_norm": 1.5770208835601807,
      "learning_rate": 1.9985496925253373e-05,
      "loss": 1.0997,
      "step": 77
    },
    {
      "epoch": 0.052104208416833664,
      "grad_norm": 1.3772187232971191,
      "learning_rate": 1.998511786995841e-05,
      "loss": 1.0859,
      "step": 78
    },
    {
      "epoch": 0.052772211088844355,
      "grad_norm": 1.758318305015564,
      "learning_rate": 1.9984733928513247e-05,
      "loss": 1.1269,
      "step": 79
    },
    {
      "epoch": 0.053440213760855046,
      "grad_norm": 1.364709734916687,
      "learning_rate": 1.9984345101105757e-05,
      "loss": 1.0111,
      "step": 80
    },
    {
      "epoch": 0.05410821643286573,
      "grad_norm": 1.4780185222625732,
      "learning_rate": 1.9983951387926216e-05,
      "loss": 1.1213,
      "step": 81
    },
    {
      "epoch": 0.05477621910487642,
      "grad_norm": 1.248088002204895,
      "learning_rate": 1.9983552789167273e-05,
      "loss": 1.0743,
      "step": 82
    },
    {
      "epoch": 0.055444221776887105,
      "grad_norm": 1.3516443967819214,
      "learning_rate": 1.998314930502399e-05,
      "loss": 1.0674,
      "step": 83
    },
    {
      "epoch": 0.056112224448897796,
      "grad_norm": 1.37941575050354,
      "learning_rate": 1.9982740935693807e-05,
      "loss": 1.1595,
      "step": 84
    },
    {
      "epoch": 0.05678022712090848,
      "grad_norm": 1.4288904666900635,
      "learning_rate": 1.9982327681376556e-05,
      "loss": 1.0917,
      "step": 85
    },
    {
      "epoch": 0.05744822979291917,
      "grad_norm": 1.1927775144577026,
      "learning_rate": 1.998190954227446e-05,
      "loss": 1.1056,
      "step": 86
    },
    {
      "epoch": 0.05811623246492986,
      "grad_norm": 1.318953514099121,
      "learning_rate": 1.9981486518592134e-05,
      "loss": 1.0398,
      "step": 87
    },
    {
      "epoch": 0.058784235136940546,
      "grad_norm": 1.599560260772705,
      "learning_rate": 1.998105861053658e-05,
      "loss": 1.1353,
      "step": 88
    },
    {
      "epoch": 0.05945223780895124,
      "grad_norm": 1.0571997165679932,
      "learning_rate": 1.9980625818317194e-05,
      "loss": 1.1522,
      "step": 89
    },
    {
      "epoch": 0.06012024048096192,
      "grad_norm": 1.4815428256988525,
      "learning_rate": 1.9980188142145755e-05,
      "loss": 1.1799,
      "step": 90
    },
    {
      "epoch": 0.06078824315297261,
      "grad_norm": 1.3921313285827637,
      "learning_rate": 1.997974558223644e-05,
      "loss": 0.9318,
      "step": 91
    },
    {
      "epoch": 0.0614562458249833,
      "grad_norm": 1.3387905359268188,
      "learning_rate": 1.9979298138805818e-05,
      "loss": 0.9507,
      "step": 92
    },
    {
      "epoch": 0.06212424849699399,
      "grad_norm": 1.2746868133544922,
      "learning_rate": 1.9978845812072834e-05,
      "loss": 1.0992,
      "step": 93
    },
    {
      "epoch": 0.06279225116900468,
      "grad_norm": 1.3242113590240479,
      "learning_rate": 1.997838860225884e-05,
      "loss": 0.9267,
      "step": 94
    },
    {
      "epoch": 0.06346025384101536,
      "grad_norm": 1.322954535484314,
      "learning_rate": 1.9977926509587556e-05,
      "loss": 1.1803,
      "step": 95
    },
    {
      "epoch": 0.06412825651302605,
      "grad_norm": 1.4662177562713623,
      "learning_rate": 1.9977459534285114e-05,
      "loss": 1.0299,
      "step": 96
    },
    {
      "epoch": 0.06479625918503674,
      "grad_norm": 1.5184369087219238,
      "learning_rate": 1.997698767658002e-05,
      "loss": 0.9599,
      "step": 97
    },
    {
      "epoch": 0.06546426185704743,
      "grad_norm": 1.498616337776184,
      "learning_rate": 1.997651093670318e-05,
      "loss": 1.0425,
      "step": 98
    },
    {
      "epoch": 0.06613226452905811,
      "grad_norm": 1.3216239213943481,
      "learning_rate": 1.9976029314887882e-05,
      "loss": 1.0689,
      "step": 99
    },
    {
      "epoch": 0.06680026720106881,
      "grad_norm": 1.5822829008102417,
      "learning_rate": 1.9975542811369798e-05,
      "loss": 1.1867,
      "step": 100
    },
    {
      "epoch": 0.0674682698730795,
      "grad_norm": 1.2759650945663452,
      "learning_rate": 1.9975051426387e-05,
      "loss": 0.8464,
      "step": 101
    },
    {
      "epoch": 0.06813627254509018,
      "grad_norm": 1.5329675674438477,
      "learning_rate": 1.9974555160179948e-05,
      "loss": 1.1565,
      "step": 102
    },
    {
      "epoch": 0.06880427521710086,
      "grad_norm": 1.6777478456497192,
      "learning_rate": 1.997405401299148e-05,
      "loss": 0.9452,
      "step": 103
    },
    {
      "epoch": 0.06947227788911156,
      "grad_norm": 1.4368585348129272,
      "learning_rate": 1.997354798506683e-05,
      "loss": 0.9561,
      "step": 104
    },
    {
      "epoch": 0.07014028056112225,
      "grad_norm": 1.5261763334274292,
      "learning_rate": 1.997303707665362e-05,
      "loss": 0.897,
      "step": 105
    },
    {
      "epoch": 0.07080828323313293,
      "grad_norm": 1.4132907390594482,
      "learning_rate": 1.9972521288001864e-05,
      "loss": 0.8971,
      "step": 106
    },
    {
      "epoch": 0.07147628590514363,
      "grad_norm": 1.2977826595306396,
      "learning_rate": 1.997200061936395e-05,
      "loss": 0.9621,
      "step": 107
    },
    {
      "epoch": 0.07214428857715431,
      "grad_norm": 1.4354889392852783,
      "learning_rate": 1.9971475070994675e-05,
      "loss": 0.8318,
      "step": 108
    },
    {
      "epoch": 0.072812291249165,
      "grad_norm": 1.5008233785629272,
      "learning_rate": 1.9970944643151205e-05,
      "loss": 0.9363,
      "step": 109
    },
    {
      "epoch": 0.07348029392117568,
      "grad_norm": 1.7662765979766846,
      "learning_rate": 1.9970409336093108e-05,
      "loss": 1.0237,
      "step": 110
    },
    {
      "epoch": 0.07414829659318638,
      "grad_norm": 1.6896228790283203,
      "learning_rate": 1.996986915008232e-05,
      "loss": 1.0503,
      "step": 111
    },
    {
      "epoch": 0.07481629926519706,
      "grad_norm": 1.545491099357605,
      "learning_rate": 1.996932408538319e-05,
      "loss": 0.8731,
      "step": 112
    },
    {
      "epoch": 0.07548430193720775,
      "grad_norm": 1.4097051620483398,
      "learning_rate": 1.9968774142262436e-05,
      "loss": 0.8782,
      "step": 113
    },
    {
      "epoch": 0.07615230460921844,
      "grad_norm": 1.5316272974014282,
      "learning_rate": 1.9968219320989175e-05,
      "loss": 0.986,
      "step": 114
    },
    {
      "epoch": 0.07682030728122913,
      "grad_norm": 1.6540744304656982,
      "learning_rate": 1.9967659621834896e-05,
      "loss": 1.0077,
      "step": 115
    },
    {
      "epoch": 0.07748830995323981,
      "grad_norm": 1.6835800409317017,
      "learning_rate": 1.996709504507349e-05,
      "loss": 1.0154,
      "step": 116
    },
    {
      "epoch": 0.0781563126252505,
      "grad_norm": 1.4349329471588135,
      "learning_rate": 1.9966525590981228e-05,
      "loss": 0.7847,
      "step": 117
    },
    {
      "epoch": 0.0788243152972612,
      "grad_norm": 2.1287643909454346,
      "learning_rate": 1.9965951259836766e-05,
      "loss": 1.0627,
      "step": 118
    },
    {
      "epoch": 0.07949231796927188,
      "grad_norm": 1.4225202798843384,
      "learning_rate": 1.996537205192115e-05,
      "loss": 0.7317,
      "step": 119
    },
    {
      "epoch": 0.08016032064128256,
      "grad_norm": 1.6733025312423706,
      "learning_rate": 1.9964787967517817e-05,
      "loss": 1.0214,
      "step": 120
    },
    {
      "epoch": 0.08082832331329326,
      "grad_norm": 1.7667429447174072,
      "learning_rate": 1.9964199006912577e-05,
      "loss": 0.8612,
      "step": 121
    },
    {
      "epoch": 0.08149632598530394,
      "grad_norm": 1.8731261491775513,
      "learning_rate": 1.9963605170393637e-05,
      "loss": 0.8549,
      "step": 122
    },
    {
      "epoch": 0.08216432865731463,
      "grad_norm": 1.9500148296356201,
      "learning_rate": 1.996300645825159e-05,
      "loss": 0.8407,
      "step": 123
    },
    {
      "epoch": 0.08283233132932531,
      "grad_norm": 1.4501616954803467,
      "learning_rate": 1.9962402870779403e-05,
      "loss": 0.7546,
      "step": 124
    },
    {
      "epoch": 0.08350033400133601,
      "grad_norm": 1.9864797592163086,
      "learning_rate": 1.996179440827245e-05,
      "loss": 0.9717,
      "step": 125
    },
    {
      "epoch": 0.0841683366733467,
      "grad_norm": 1.6012943983078003,
      "learning_rate": 1.996118107102847e-05,
      "loss": 0.785,
      "step": 126
    },
    {
      "epoch": 0.08483633934535738,
      "grad_norm": 1.765365481376648,
      "learning_rate": 1.9960562859347593e-05,
      "loss": 0.8023,
      "step": 127
    },
    {
      "epoch": 0.08550434201736808,
      "grad_norm": 1.642730474472046,
      "learning_rate": 1.9959939773532343e-05,
      "loss": 0.7408,
      "step": 128
    },
    {
      "epoch": 0.08617234468937876,
      "grad_norm": 1.816781997680664,
      "learning_rate": 1.995931181388762e-05,
      "loss": 0.9701,
      "step": 129
    },
    {
      "epoch": 0.08684034736138944,
      "grad_norm": 1.4757401943206787,
      "learning_rate": 1.9958678980720712e-05,
      "loss": 0.7662,
      "step": 130
    },
    {
      "epoch": 0.08750835003340013,
      "grad_norm": 2.0781288146972656,
      "learning_rate": 1.995804127434129e-05,
      "loss": 0.7396,
      "step": 131
    },
    {
      "epoch": 0.08817635270541083,
      "grad_norm": 1.760306715965271,
      "learning_rate": 1.9957398695061417e-05,
      "loss": 0.7703,
      "step": 132
    },
    {
      "epoch": 0.08884435537742151,
      "grad_norm": 2.2177908420562744,
      "learning_rate": 1.995675124319553e-05,
      "loss": 0.7548,
      "step": 133
    },
    {
      "epoch": 0.0895123580494322,
      "grad_norm": 1.979670524597168,
      "learning_rate": 1.9956098919060453e-05,
      "loss": 0.9408,
      "step": 134
    },
    {
      "epoch": 0.09018036072144289,
      "grad_norm": 1.8462032079696655,
      "learning_rate": 1.99554417229754e-05,
      "loss": 0.7195,
      "step": 135
    },
    {
      "epoch": 0.09084836339345358,
      "grad_norm": 1.9187086820602417,
      "learning_rate": 1.9954779655261967e-05,
      "loss": 0.8664,
      "step": 136
    },
    {
      "epoch": 0.09151636606546426,
      "grad_norm": 2.2399137020111084,
      "learning_rate": 1.995411271624413e-05,
      "loss": 0.7078,
      "step": 137
    },
    {
      "epoch": 0.09218436873747494,
      "grad_norm": 1.8088473081588745,
      "learning_rate": 1.9953440906248252e-05,
      "loss": 0.8489,
      "step": 138
    },
    {
      "epoch": 0.09285237140948564,
      "grad_norm": 2.008837938308716,
      "learning_rate": 1.995276422560308e-05,
      "loss": 0.8163,
      "step": 139
    },
    {
      "epoch": 0.09352037408149633,
      "grad_norm": 2.000671863555908,
      "learning_rate": 1.9952082674639736e-05,
      "loss": 0.8935,
      "step": 140
    },
    {
      "epoch": 0.09418837675350701,
      "grad_norm": 1.7921075820922852,
      "learning_rate": 1.995139625369174e-05,
      "loss": 0.6574,
      "step": 141
    },
    {
      "epoch": 0.09485637942551771,
      "grad_norm": 1.8218539953231812,
      "learning_rate": 1.9950704963094987e-05,
      "loss": 0.6907,
      "step": 142
    },
    {
      "epoch": 0.09552438209752839,
      "grad_norm": 1.9558660984039307,
      "learning_rate": 1.9950008803187756e-05,
      "loss": 0.6418,
      "step": 143
    },
    {
      "epoch": 0.09619238476953908,
      "grad_norm": 1.6054401397705078,
      "learning_rate": 1.99493077743107e-05,
      "loss": 0.6297,
      "step": 144
    },
    {
      "epoch": 0.09686038744154976,
      "grad_norm": 1.6568107604980469,
      "learning_rate": 1.9948601876806874e-05,
      "loss": 0.6185,
      "step": 145
    },
    {
      "epoch": 0.09752839011356046,
      "grad_norm": 2.170900344848633,
      "learning_rate": 1.9947891111021694e-05,
      "loss": 0.6185,
      "step": 146
    },
    {
      "epoch": 0.09819639278557114,
      "grad_norm": 1.9909721612930298,
      "learning_rate": 1.9947175477302974e-05,
      "loss": 0.7771,
      "step": 147
    },
    {
      "epoch": 0.09886439545758183,
      "grad_norm": 1.8849576711654663,
      "learning_rate": 1.9946454976000903e-05,
      "loss": 0.5747,
      "step": 148
    },
    {
      "epoch": 0.09953239812959253,
      "grad_norm": 1.8980035781860352,
      "learning_rate": 1.994572960746806e-05,
      "loss": 0.7818,
      "step": 149
    },
    {
      "epoch": 0.10020040080160321,
      "grad_norm": 1.8871923685073853,
      "learning_rate": 1.994499937205939e-05,
      "loss": 0.5868,
      "step": 150
    },
    {
      "epoch": 0.1008684034736139,
      "grad_norm": 1.8675537109375,
      "learning_rate": 1.994426427013223e-05,
      "loss": 0.6682,
      "step": 151
    },
    {
      "epoch": 0.10153640614562458,
      "grad_norm": 2.093182325363159,
      "learning_rate": 1.99435243020463e-05,
      "loss": 0.794,
      "step": 152
    },
    {
      "epoch": 0.10220440881763528,
      "grad_norm": 1.8860658407211304,
      "learning_rate": 1.9942779468163696e-05,
      "loss": 0.586,
      "step": 153
    },
    {
      "epoch": 0.10287241148964596,
      "grad_norm": 2.124260663986206,
      "learning_rate": 1.9942029768848905e-05,
      "loss": 0.8107,
      "step": 154
    },
    {
      "epoch": 0.10354041416165664,
      "grad_norm": 2.222975730895996,
      "learning_rate": 1.994127520446878e-05,
      "loss": 0.8475,
      "step": 155
    },
    {
      "epoch": 0.10420841683366733,
      "grad_norm": 2.0941710472106934,
      "learning_rate": 1.994051577539256e-05,
      "loss": 0.7988,
      "step": 156
    },
    {
      "epoch": 0.10487641950567803,
      "grad_norm": 2.172241687774658,
      "learning_rate": 1.9939751481991872e-05,
      "loss": 0.7503,
      "step": 157
    },
    {
      "epoch": 0.10554442217768871,
      "grad_norm": 2.217434883117676,
      "learning_rate": 1.9938982324640716e-05,
      "loss": 0.6624,
      "step": 158
    },
    {
      "epoch": 0.1062124248496994,
      "grad_norm": 1.870750069618225,
      "learning_rate": 1.9938208303715474e-05,
      "loss": 0.5346,
      "step": 159
    },
    {
      "epoch": 0.10688042752171009,
      "grad_norm": 2.0576868057250977,
      "learning_rate": 1.9937429419594907e-05,
      "loss": 0.6491,
      "step": 160
    },
    {
      "epoch": 0.10754843019372078,
      "grad_norm": 2.0101122856140137,
      "learning_rate": 1.9936645672660157e-05,
      "loss": 0.7751,
      "step": 161
    },
    {
      "epoch": 0.10821643286573146,
      "grad_norm": 2.1006052494049072,
      "learning_rate": 1.993585706329475e-05,
      "loss": 0.8155,
      "step": 162
    },
    {
      "epoch": 0.10888443553774214,
      "grad_norm": 2.7274370193481445,
      "learning_rate": 1.9935063591884577e-05,
      "loss": 0.7794,
      "step": 163
    },
    {
      "epoch": 0.10955243820975284,
      "grad_norm": 2.1424427032470703,
      "learning_rate": 1.9934265258817925e-05,
      "loss": 0.4751,
      "step": 164
    },
    {
      "epoch": 0.11022044088176353,
      "grad_norm": 1.8986274003982544,
      "learning_rate": 1.9933462064485453e-05,
      "loss": 0.5212,
      "step": 165
    },
    {
      "epoch": 0.11088844355377421,
      "grad_norm": 1.991309642791748,
      "learning_rate": 1.9932654009280195e-05,
      "loss": 0.5855,
      "step": 166
    },
    {
      "epoch": 0.11155644622578491,
      "grad_norm": 2.5070998668670654,
      "learning_rate": 1.9931841093597568e-05,
      "loss": 0.4283,
      "step": 167
    },
    {
      "epoch": 0.11222444889779559,
      "grad_norm": 2.240424871444702,
      "learning_rate": 1.993102331783537e-05,
      "loss": 0.7201,
      "step": 168
    },
    {
      "epoch": 0.11289245156980628,
      "grad_norm": 1.690470576286316,
      "learning_rate": 1.9930200682393775e-05,
      "loss": 0.7116,
      "step": 169
    },
    {
      "epoch": 0.11356045424181696,
      "grad_norm": 2.0192790031433105,
      "learning_rate": 1.9929373187675327e-05,
      "loss": 0.6675,
      "step": 170
    },
    {
      "epoch": 0.11422845691382766,
      "grad_norm": 1.9085801839828491,
      "learning_rate": 1.992854083408496e-05,
      "loss": 0.6378,
      "step": 171
    },
    {
      "epoch": 0.11489645958583834,
      "grad_norm": 1.9595073461532593,
      "learning_rate": 1.9927703622029982e-05,
      "loss": 0.3976,
      "step": 172
    },
    {
      "epoch": 0.11556446225784903,
      "grad_norm": 1.7905257940292358,
      "learning_rate": 1.9926861551920072e-05,
      "loss": 0.5133,
      "step": 173
    },
    {
      "epoch": 0.11623246492985972,
      "grad_norm": 2.109450578689575,
      "learning_rate": 1.9926014624167297e-05,
      "loss": 0.5873,
      "step": 174
    },
    {
      "epoch": 0.11690046760187041,
      "grad_norm": 1.9476211071014404,
      "learning_rate": 1.9925162839186095e-05,
      "loss": 0.776,
      "step": 175
    },
    {
      "epoch": 0.11756847027388109,
      "grad_norm": 1.882137417793274,
      "learning_rate": 1.9924306197393274e-05,
      "loss": 0.4183,
      "step": 176
    },
    {
      "epoch": 0.11823647294589178,
      "grad_norm": 1.8058816194534302,
      "learning_rate": 1.9923444699208036e-05,
      "loss": 0.464,
      "step": 177
    },
    {
      "epoch": 0.11890447561790247,
      "grad_norm": 1.870074987411499,
      "learning_rate": 1.992257834505194e-05,
      "loss": 0.398,
      "step": 178
    },
    {
      "epoch": 0.11957247828991316,
      "grad_norm": 1.9569936990737915,
      "learning_rate": 1.9921707135348935e-05,
      "loss": 0.3626,
      "step": 179
    },
    {
      "epoch": 0.12024048096192384,
      "grad_norm": 1.5532679557800293,
      "learning_rate": 1.992083107052534e-05,
      "loss": 0.3799,
      "step": 180
    },
    {
      "epoch": 0.12090848363393454,
      "grad_norm": 1.5553193092346191,
      "learning_rate": 1.9919950151009856e-05,
      "loss": 0.4153,
      "step": 181
    },
    {
      "epoch": 0.12157648630594522,
      "grad_norm": 1.976386308670044,
      "learning_rate": 1.9919064377233552e-05,
      "loss": 0.641,
      "step": 182
    },
    {
      "epoch": 0.12224448897795591,
      "grad_norm": 1.2910865545272827,
      "learning_rate": 1.9918173749629875e-05,
      "loss": 0.4894,
      "step": 183
    },
    {
      "epoch": 0.1229124916499666,
      "grad_norm": 1.323454737663269,
      "learning_rate": 1.9917278268634646e-05,
      "loss": 0.5416,
      "step": 184
    },
    {
      "epoch": 0.12358049432197729,
      "grad_norm": 1.5732473134994507,
      "learning_rate": 1.9916377934686066e-05,
      "loss": 0.6262,
      "step": 185
    },
    {
      "epoch": 0.12424849699398798,
      "grad_norm": 1.5793483257293701,
      "learning_rate": 1.9915472748224703e-05,
      "loss": 0.3478,
      "step": 186
    },
    {
      "epoch": 0.12491649966599866,
      "grad_norm": 1.6373236179351807,
      "learning_rate": 1.991456270969351e-05,
      "loss": 0.5565,
      "step": 187
    },
    {
      "epoch": 0.12558450233800936,
      "grad_norm": 1.3498607873916626,
      "learning_rate": 1.9913647819537804e-05,
      "loss": 0.2973,
      "step": 188
    },
    {
      "epoch": 0.12625250501002003,
      "grad_norm": 1.3120152950286865,
      "learning_rate": 1.9912728078205285e-05,
      "loss": 0.4139,
      "step": 189
    },
    {
      "epoch": 0.12692050768203073,
      "grad_norm": 1.1535564661026,
      "learning_rate": 1.991180348614601e-05,
      "loss": 0.4481,
      "step": 190
    },
    {
      "epoch": 0.12758851035404142,
      "grad_norm": 2.150394916534424,
      "learning_rate": 1.9910874043812442e-05,
      "loss": 0.4949,
      "step": 191
    },
    {
      "epoch": 0.1282565130260521,
      "grad_norm": 2.3164706230163574,
      "learning_rate": 1.9909939751659376e-05,
      "loss": 0.4762,
      "step": 192
    },
    {
      "epoch": 0.1289245156980628,
      "grad_norm": 1.829498052597046,
      "learning_rate": 1.9909000610144017e-05,
      "loss": 0.5657,
      "step": 193
    },
    {
      "epoch": 0.1295925183700735,
      "grad_norm": 1.827927589416504,
      "learning_rate": 1.990805661972592e-05,
      "loss": 0.5606,
      "step": 194
    },
    {
      "epoch": 0.13026052104208416,
      "grad_norm": 1.5829670429229736,
      "learning_rate": 1.990710778086702e-05,
      "loss": 0.3747,
      "step": 195
    },
    {
      "epoch": 0.13092852371409486,
      "grad_norm": 1.3228363990783691,
      "learning_rate": 1.990615409403163e-05,
      "loss": 0.5165,
      "step": 196
    },
    {
      "epoch": 0.13159652638610556,
      "grad_norm": 1.7812517881393433,
      "learning_rate": 1.990519555968643e-05,
      "loss": 0.3858,
      "step": 197
    },
    {
      "epoch": 0.13226452905811623,
      "grad_norm": 1.4843915700912476,
      "learning_rate": 1.9904232178300465e-05,
      "loss": 0.4115,
      "step": 198
    },
    {
      "epoch": 0.13293253173012692,
      "grad_norm": 1.946770191192627,
      "learning_rate": 1.9903263950345165e-05,
      "loss": 0.4829,
      "step": 199
    },
    {
      "epoch": 0.13360053440213762,
      "grad_norm": 1.4765061140060425,
      "learning_rate": 1.9902290876294324e-05,
      "loss": 0.2819,
      "step": 200
    },
    {
      "epoch": 0.1342685370741483,
      "grad_norm": 1.4122662544250488,
      "learning_rate": 1.9901312956624115e-05,
      "loss": 0.5358,
      "step": 201
    },
    {
      "epoch": 0.134936539746159,
      "grad_norm": 1.2905173301696777,
      "learning_rate": 1.9900330191813066e-05,
      "loss": 0.4929,
      "step": 202
    },
    {
      "epoch": 0.13560454241816966,
      "grad_norm": 1.3967835903167725,
      "learning_rate": 1.9899342582342093e-05,
      "loss": 0.2467,
      "step": 203
    },
    {
      "epoch": 0.13627254509018036,
      "grad_norm": 1.4304561614990234,
      "learning_rate": 1.989835012869448e-05,
      "loss": 0.5333,
      "step": 204
    },
    {
      "epoch": 0.13694054776219106,
      "grad_norm": 1.6993608474731445,
      "learning_rate": 1.9897352831355864e-05,
      "loss": 0.252,
      "step": 205
    },
    {
      "epoch": 0.13760855043420173,
      "grad_norm": 1.6798574924468994,
      "learning_rate": 1.989635069081428e-05,
      "loss": 0.4405,
      "step": 206
    },
    {
      "epoch": 0.13827655310621242,
      "grad_norm": 1.6598626375198364,
      "learning_rate": 1.989534370756011e-05,
      "loss": 0.3468,
      "step": 207
    },
    {
      "epoch": 0.13894455577822312,
      "grad_norm": 1.4695122241973877,
      "learning_rate": 1.9894331882086117e-05,
      "loss": 0.4144,
      "step": 208
    },
    {
      "epoch": 0.1396125584502338,
      "grad_norm": 1.4047623872756958,
      "learning_rate": 1.9893315214887433e-05,
      "loss": 0.2708,
      "step": 209
    },
    {
      "epoch": 0.1402805611222445,
      "grad_norm": 1.2503982782363892,
      "learning_rate": 1.9892293706461555e-05,
      "loss": 0.2129,
      "step": 210
    },
    {
      "epoch": 0.1409485637942552,
      "grad_norm": 1.4964848756790161,
      "learning_rate": 1.9891267357308354e-05,
      "loss": 0.5023,
      "step": 211
    },
    {
      "epoch": 0.14161656646626586,
      "grad_norm": 1.8016202449798584,
      "learning_rate": 1.9890236167930062e-05,
      "loss": 0.2399,
      "step": 212
    },
    {
      "epoch": 0.14228456913827656,
      "grad_norm": 1.216315507888794,
      "learning_rate": 1.9889200138831288e-05,
      "loss": 0.4435,
      "step": 213
    },
    {
      "epoch": 0.14295257181028725,
      "grad_norm": 1.3443182706832886,
      "learning_rate": 1.9888159270519004e-05,
      "loss": 0.2645,
      "step": 214
    },
    {
      "epoch": 0.14362057448229792,
      "grad_norm": 2.0573034286499023,
      "learning_rate": 1.9887113563502556e-05,
      "loss": 0.3429,
      "step": 215
    },
    {
      "epoch": 0.14428857715430862,
      "grad_norm": 1.3034780025482178,
      "learning_rate": 1.988606301829365e-05,
      "loss": 0.1942,
      "step": 216
    },
    {
      "epoch": 0.1449565798263193,
      "grad_norm": 1.096592664718628,
      "learning_rate": 1.9885007635406362e-05,
      "loss": 0.429,
      "step": 217
    },
    {
      "epoch": 0.14562458249833,
      "grad_norm": 1.4704856872558594,
      "learning_rate": 1.988394741535714e-05,
      "loss": 0.3397,
      "step": 218
    },
    {
      "epoch": 0.1462925851703407,
      "grad_norm": 1.8881282806396484,
      "learning_rate": 1.9882882358664795e-05,
      "loss": 0.3877,
      "step": 219
    },
    {
      "epoch": 0.14696058784235136,
      "grad_norm": 1.4908385276794434,
      "learning_rate": 1.9881812465850502e-05,
      "loss": 0.386,
      "step": 220
    },
    {
      "epoch": 0.14762859051436206,
      "grad_norm": 1.3807226419448853,
      "learning_rate": 1.9880737737437813e-05,
      "loss": 0.4042,
      "step": 221
    },
    {
      "epoch": 0.14829659318637275,
      "grad_norm": 1.711470127105713,
      "learning_rate": 1.9879658173952633e-05,
      "loss": 0.4243,
      "step": 222
    },
    {
      "epoch": 0.14896459585838343,
      "grad_norm": 2.2146081924438477,
      "learning_rate": 1.9878573775923236e-05,
      "loss": 0.3074,
      "step": 223
    },
    {
      "epoch": 0.14963259853039412,
      "grad_norm": 1.4192442893981934,
      "learning_rate": 1.9877484543880272e-05,
      "loss": 0.214,
      "step": 224
    },
    {
      "epoch": 0.15030060120240482,
      "grad_norm": 1.5198482275009155,
      "learning_rate": 1.987639047835675e-05,
      "loss": 0.2812,
      "step": 225
    },
    {
      "epoch": 0.1509686038744155,
      "grad_norm": 1.5674140453338623,
      "learning_rate": 1.9875291579888037e-05,
      "loss": 0.355,
      "step": 226
    },
    {
      "epoch": 0.1516366065464262,
      "grad_norm": 1.2231605052947998,
      "learning_rate": 1.9874187849011875e-05,
      "loss": 0.2051,
      "step": 227
    },
    {
      "epoch": 0.1523046092184369,
      "grad_norm": 1.7621049880981445,
      "learning_rate": 1.9873079286268368e-05,
      "loss": 0.2214,
      "step": 228
    },
    {
      "epoch": 0.15297261189044756,
      "grad_norm": 0.9335027933120728,
      "learning_rate": 1.9871965892199983e-05,
      "loss": 0.2104,
      "step": 229
    },
    {
      "epoch": 0.15364061456245826,
      "grad_norm": 1.753999948501587,
      "learning_rate": 1.9870847667351555e-05,
      "loss": 0.2745,
      "step": 230
    },
    {
      "epoch": 0.15430861723446893,
      "grad_norm": 0.9278760552406311,
      "learning_rate": 1.986972461227027e-05,
      "loss": 0.1979,
      "step": 231
    },
    {
      "epoch": 0.15497661990647962,
      "grad_norm": 0.9884293079376221,
      "learning_rate": 1.98685967275057e-05,
      "loss": 0.1709,
      "step": 232
    },
    {
      "epoch": 0.15564462257849032,
      "grad_norm": 1.483455777168274,
      "learning_rate": 1.986746401360976e-05,
      "loss": 0.2399,
      "step": 233
    },
    {
      "epoch": 0.156312625250501,
      "grad_norm": 1.1468769311904907,
      "learning_rate": 1.9866326471136738e-05,
      "loss": 0.1761,
      "step": 234
    },
    {
      "epoch": 0.1569806279225117,
      "grad_norm": 1.2699546813964844,
      "learning_rate": 1.986518410064328e-05,
      "loss": 0.2922,
      "step": 235
    },
    {
      "epoch": 0.1576486305945224,
      "grad_norm": 2.0970914363861084,
      "learning_rate": 1.9864036902688402e-05,
      "loss": 0.2064,
      "step": 236
    },
    {
      "epoch": 0.15831663326653306,
      "grad_norm": 1.5578904151916504,
      "learning_rate": 1.9862884877833476e-05,
      "loss": 0.2949,
      "step": 237
    },
    {
      "epoch": 0.15898463593854376,
      "grad_norm": 1.3226770162582397,
      "learning_rate": 1.9861728026642235e-05,
      "loss": 0.1866,
      "step": 238
    },
    {
      "epoch": 0.15965263861055445,
      "grad_norm": 0.8900975584983826,
      "learning_rate": 1.9860566349680782e-05,
      "loss": 0.1871,
      "step": 239
    },
    {
      "epoch": 0.16032064128256512,
      "grad_norm": 1.5560287237167358,
      "learning_rate": 1.9859399847517568e-05,
      "loss": 0.1689,
      "step": 240
    },
    {
      "epoch": 0.16098864395457582,
      "grad_norm": 0.9316651225090027,
      "learning_rate": 1.985822852072342e-05,
      "loss": 0.2169,
      "step": 241
    },
    {
      "epoch": 0.16165664662658652,
      "grad_norm": 1.4020768404006958,
      "learning_rate": 1.9857052369871518e-05,
      "loss": 0.253,
      "step": 242
    },
    {
      "epoch": 0.1623246492985972,
      "grad_norm": 1.3062762022018433,
      "learning_rate": 1.9855871395537395e-05,
      "loss": 0.1495,
      "step": 243
    },
    {
      "epoch": 0.1629926519706079,
      "grad_norm": 1.0894888639450073,
      "learning_rate": 1.9854685598298965e-05,
      "loss": 0.1382,
      "step": 244
    },
    {
      "epoch": 0.16366065464261856,
      "grad_norm": 1.0174025297164917,
      "learning_rate": 1.9853494978736483e-05,
      "loss": 0.145,
      "step": 245
    },
    {
      "epoch": 0.16432865731462926,
      "grad_norm": 1.2577697038650513,
      "learning_rate": 1.9852299537432573e-05,
      "loss": 0.1517,
      "step": 246
    },
    {
      "epoch": 0.16499665998663995,
      "grad_norm": 1.3152683973312378,
      "learning_rate": 1.9851099274972215e-05,
      "loss": 0.1629,
      "step": 247
    },
    {
      "epoch": 0.16566466265865062,
      "grad_norm": 0.7220048308372498,
      "learning_rate": 1.9849894191942746e-05,
      "loss": 0.1249,
      "step": 248
    },
    {
      "epoch": 0.16633266533066132,
      "grad_norm": 1.6315109729766846,
      "learning_rate": 1.9848684288933873e-05,
      "loss": 0.3158,
      "step": 249
    },
    {
      "epoch": 0.16700066800267202,
      "grad_norm": 1.8681488037109375,
      "learning_rate": 1.9847469566537646e-05,
      "loss": 0.3042,
      "step": 250
    },
    {
      "epoch": 0.1676686706746827,
      "grad_norm": 1.1605335474014282,
      "learning_rate": 1.9846250025348487e-05,
      "loss": 0.1184,
      "step": 251
    },
    {
      "epoch": 0.1683366733466934,
      "grad_norm": 2.2042324542999268,
      "learning_rate": 1.984502566596317e-05,
      "loss": 0.2581,
      "step": 252
    },
    {
      "epoch": 0.1690046760187041,
      "grad_norm": 1.1586498022079468,
      "learning_rate": 1.984379648898082e-05,
      "loss": 0.1647,
      "step": 253
    },
    {
      "epoch": 0.16967267869071476,
      "grad_norm": 1.4665508270263672,
      "learning_rate": 1.984256249500294e-05,
      "loss": 0.2279,
      "step": 254
    },
    {
      "epoch": 0.17034068136272545,
      "grad_norm": 1.088077425956726,
      "learning_rate": 1.984132368463336e-05,
      "loss": 0.1131,
      "step": 255
    },
    {
      "epoch": 0.17100868403473615,
      "grad_norm": 1.5894631147384644,
      "learning_rate": 1.9840080058478296e-05,
      "loss": 0.3174,
      "step": 256
    },
    {
      "epoch": 0.17167668670674682,
      "grad_norm": 0.9283255934715271,
      "learning_rate": 1.98388316171463e-05,
      "loss": 0.1149,
      "step": 257
    },
    {
      "epoch": 0.17234468937875752,
      "grad_norm": 3.1176931858062744,
      "learning_rate": 1.9837578361248298e-05,
      "loss": 0.3122,
      "step": 258
    },
    {
      "epoch": 0.1730126920507682,
      "grad_norm": 1.265340805053711,
      "learning_rate": 1.983632029139755e-05,
      "loss": 0.1998,
      "step": 259
    },
    {
      "epoch": 0.1736806947227789,
      "grad_norm": 1.6767674684524536,
      "learning_rate": 1.9835057408209695e-05,
      "loss": 0.1471,
      "step": 260
    },
    {
      "epoch": 0.1743486973947896,
      "grad_norm": 1.11454439163208,
      "learning_rate": 1.9833789712302714e-05,
      "loss": 0.1756,
      "step": 261
    },
    {
      "epoch": 0.17501670006680026,
      "grad_norm": 1.6714057922363281,
      "learning_rate": 1.983251720429694e-05,
      "loss": 0.2397,
      "step": 262
    },
    {
      "epoch": 0.17568470273881096,
      "grad_norm": 3.2601511478424072,
      "learning_rate": 1.983123988481507e-05,
      "loss": 0.2447,
      "step": 263
    },
    {
      "epoch": 0.17635270541082165,
      "grad_norm": 1.1043345928192139,
      "learning_rate": 1.9829957754482154e-05,
      "loss": 0.1863,
      "step": 264
    },
    {
      "epoch": 0.17702070808283232,
      "grad_norm": 1.3029893636703491,
      "learning_rate": 1.9828670813925587e-05,
      "loss": 0.129,
      "step": 265
    },
    {
      "epoch": 0.17768871075484302,
      "grad_norm": 1.0323830842971802,
      "learning_rate": 1.9827379063775132e-05,
      "loss": 0.1238,
      "step": 266
    },
    {
      "epoch": 0.17835671342685372,
      "grad_norm": 1.3984551429748535,
      "learning_rate": 1.9826082504662895e-05,
      "loss": 0.1028,
      "step": 267
    },
    {
      "epoch": 0.1790247160988644,
      "grad_norm": 0.7329056262969971,
      "learning_rate": 1.982478113722334e-05,
      "loss": 0.0823,
      "step": 268
    },
    {
      "epoch": 0.1796927187708751,
      "grad_norm": 0.8509952425956726,
      "learning_rate": 1.9823474962093276e-05,
      "loss": 0.0814,
      "step": 269
    },
    {
      "epoch": 0.18036072144288579,
      "grad_norm": 2.2149577140808105,
      "learning_rate": 1.9822163979911878e-05,
      "loss": 0.2325,
      "step": 270
    },
    {
      "epoch": 0.18102872411489646,
      "grad_norm": 1.243377923965454,
      "learning_rate": 1.9820848191320666e-05,
      "loss": 0.1605,
      "step": 271
    },
    {
      "epoch": 0.18169672678690715,
      "grad_norm": 1.3003389835357666,
      "learning_rate": 1.981952759696351e-05,
      "loss": 0.0959,
      "step": 272
    },
    {
      "epoch": 0.18236472945891782,
      "grad_norm": 1.21255624294281,
      "learning_rate": 1.9818202197486634e-05,
      "loss": 0.1308,
      "step": 273
    },
    {
      "epoch": 0.18303273213092852,
      "grad_norm": 1.041029453277588,
      "learning_rate": 1.9816871993538616e-05,
      "loss": 0.1393,
      "step": 274
    },
    {
      "epoch": 0.18370073480293922,
      "grad_norm": 0.7659093141555786,
      "learning_rate": 1.981553698577038e-05,
      "loss": 0.072,
      "step": 275
    },
    {
      "epoch": 0.1843687374749499,
      "grad_norm": 1.3298969268798828,
      "learning_rate": 1.9814197174835203e-05,
      "loss": 0.1042,
      "step": 276
    },
    {
      "epoch": 0.1850367401469606,
      "grad_norm": 1.3261984586715698,
      "learning_rate": 1.9812852561388707e-05,
      "loss": 0.1548,
      "step": 277
    },
    {
      "epoch": 0.18570474281897129,
      "grad_norm": 2.6357779502868652,
      "learning_rate": 1.981150314608888e-05,
      "loss": 0.3047,
      "step": 278
    },
    {
      "epoch": 0.18637274549098196,
      "grad_norm": 0.8018449544906616,
      "learning_rate": 1.9810148929596047e-05,
      "loss": 0.0622,
      "step": 279
    },
    {
      "epoch": 0.18704074816299265,
      "grad_norm": 1.0179375410079956,
      "learning_rate": 1.980878991257288e-05,
      "loss": 0.0669,
      "step": 280
    },
    {
      "epoch": 0.18770875083500335,
      "grad_norm": 0.8251602649688721,
      "learning_rate": 1.9807426095684407e-05,
      "loss": 0.0533,
      "step": 281
    },
    {
      "epoch": 0.18837675350701402,
      "grad_norm": 0.7551161646842957,
      "learning_rate": 1.9806057479598002e-05,
      "loss": 0.0936,
      "step": 282
    },
    {
      "epoch": 0.18904475617902472,
      "grad_norm": 0.9010550379753113,
      "learning_rate": 1.9804684064983392e-05,
      "loss": 0.118,
      "step": 283
    },
    {
      "epoch": 0.18971275885103542,
      "grad_norm": 1.893842339515686,
      "learning_rate": 1.9803305852512638e-05,
      "loss": 0.351,
      "step": 284
    },
    {
      "epoch": 0.1903807615230461,
      "grad_norm": 1.7932512760162354,
      "learning_rate": 1.9801922842860173e-05,
      "loss": 0.2428,
      "step": 285
    },
    {
      "epoch": 0.19104876419505679,
      "grad_norm": 0.9089131355285645,
      "learning_rate": 1.9800535036702754e-05,
      "loss": 0.0765,
      "step": 286
    },
    {
      "epoch": 0.19171676686706746,
      "grad_norm": 0.9855298399925232,
      "learning_rate": 1.9799142434719497e-05,
      "loss": 0.0639,
      "step": 287
    },
    {
      "epoch": 0.19238476953907815,
      "grad_norm": 2.419404983520508,
      "learning_rate": 1.9797745037591866e-05,
      "loss": 0.3266,
      "step": 288
    },
    {
      "epoch": 0.19305277221108885,
      "grad_norm": 0.8373790383338928,
      "learning_rate": 1.979634284600366e-05,
      "loss": 0.0591,
      "step": 289
    },
    {
      "epoch": 0.19372077488309952,
      "grad_norm": 0.999725878238678,
      "learning_rate": 1.9794935860641038e-05,
      "loss": 0.0756,
      "step": 290
    },
    {
      "epoch": 0.19438877755511022,
      "grad_norm": 0.5529278516769409,
      "learning_rate": 1.9793524082192498e-05,
      "loss": 0.0453,
      "step": 291
    },
    {
      "epoch": 0.19505678022712092,
      "grad_norm": 0.9955092072486877,
      "learning_rate": 1.979210751134888e-05,
      "loss": 0.0583,
      "step": 292
    },
    {
      "epoch": 0.1957247828991316,
      "grad_norm": 0.8359704613685608,
      "learning_rate": 1.979068614880338e-05,
      "loss": 0.0491,
      "step": 293
    },
    {
      "epoch": 0.1963927855711423,
      "grad_norm": 1.6512119770050049,
      "learning_rate": 1.9789259995251528e-05,
      "loss": 0.3313,
      "step": 294
    },
    {
      "epoch": 0.19706078824315298,
      "grad_norm": 2.390646457672119,
      "learning_rate": 1.9787829051391203e-05,
      "loss": 0.251,
      "step": 295
    },
    {
      "epoch": 0.19772879091516365,
      "grad_norm": 0.7203893065452576,
      "learning_rate": 1.978639331792263e-05,
      "loss": 0.0474,
      "step": 296
    },
    {
      "epoch": 0.19839679358717435,
      "grad_norm": 0.8923636078834534,
      "learning_rate": 1.9784952795548374e-05,
      "loss": 0.0644,
      "step": 297
    },
    {
      "epoch": 0.19906479625918505,
      "grad_norm": 2.3347134590148926,
      "learning_rate": 1.9783507484973343e-05,
      "loss": 0.2814,
      "step": 298
    },
    {
      "epoch": 0.19973279893119572,
      "grad_norm": 2.1758978366851807,
      "learning_rate": 1.9782057386904793e-05,
      "loss": 0.348,
      "step": 299
    },
    {
      "epoch": 0.20040080160320642,
      "grad_norm": 0.79861980676651,
      "learning_rate": 1.978060250205232e-05,
      "loss": 0.0886,
      "step": 300
    },
    {
      "epoch": 0.2010688042752171,
      "grad_norm": 1.54511559009552,
      "learning_rate": 1.9779142831127857e-05,
      "loss": 0.2011,
      "step": 301
    },
    {
      "epoch": 0.2017368069472278,
      "grad_norm": 4.234498977661133,
      "learning_rate": 1.977767837484569e-05,
      "loss": 0.5179,
      "step": 302
    },
    {
      "epoch": 0.20240480961923848,
      "grad_norm": 2.763340473175049,
      "learning_rate": 1.977620913392244e-05,
      "loss": 0.4402,
      "step": 303
    },
    {
      "epoch": 0.20307281229124916,
      "grad_norm": 1.6735520362854004,
      "learning_rate": 1.977473510907707e-05,
      "loss": 0.3705,
      "step": 304
    },
    {
      "epoch": 0.20374081496325985,
      "grad_norm": 3.723071813583374,
      "learning_rate": 1.977325630103088e-05,
      "loss": 0.4533,
      "step": 305
    },
    {
      "epoch": 0.20440881763527055,
      "grad_norm": 3.0442094802856445,
      "learning_rate": 1.9771772710507516e-05,
      "loss": 0.2795,
      "step": 306
    },
    {
      "epoch": 0.20507682030728122,
      "grad_norm": 0.7249768376350403,
      "learning_rate": 1.9770284338232967e-05,
      "loss": 0.0549,
      "step": 307
    },
    {
      "epoch": 0.20574482297929192,
      "grad_norm": 0.4899275600910187,
      "learning_rate": 1.9768791184935558e-05,
      "loss": 0.0366,
      "step": 308
    },
    {
      "epoch": 0.20641282565130262,
      "grad_norm": 0.7400692701339722,
      "learning_rate": 1.976729325134595e-05,
      "loss": 0.0426,
      "step": 309
    },
    {
      "epoch": 0.2070808283233133,
      "grad_norm": 0.9601795077323914,
      "learning_rate": 1.9765790538197144e-05,
      "loss": 0.065,
      "step": 310
    },
    {
      "epoch": 0.20774883099532399,
      "grad_norm": 3.372772693634033,
      "learning_rate": 1.9764283046224492e-05,
      "loss": 0.2069,
      "step": 311
    },
    {
      "epoch": 0.20841683366733466,
      "grad_norm": 1.686120629310608,
      "learning_rate": 1.9762770776165666e-05,
      "loss": 0.2112,
      "step": 312
    },
    {
      "epoch": 0.20908483633934535,
      "grad_norm": 3.22760272026062,
      "learning_rate": 1.976125372876069e-05,
      "loss": 0.3018,
      "step": 313
    },
    {
      "epoch": 0.20975283901135605,
      "grad_norm": 2.7246241569519043,
      "learning_rate": 1.975973190475192e-05,
      "loss": 0.4109,
      "step": 314
    },
    {
      "epoch": 0.21042084168336672,
      "grad_norm": 1.7328475713729858,
      "learning_rate": 1.9758205304884048e-05,
      "loss": 0.2097,
      "step": 315
    },
    {
      "epoch": 0.21108884435537742,
      "grad_norm": 3.261807441711426,
      "learning_rate": 1.9756673929904113e-05,
      "loss": 0.3564,
      "step": 316
    },
    {
      "epoch": 0.21175684702738812,
      "grad_norm": 1.1189067363739014,
      "learning_rate": 1.9755137780561472e-05,
      "loss": 0.1179,
      "step": 317
    },
    {
      "epoch": 0.2124248496993988,
      "grad_norm": 3.759390354156494,
      "learning_rate": 1.9753596857607834e-05,
      "loss": 0.3142,
      "step": 318
    },
    {
      "epoch": 0.21309285237140949,
      "grad_norm": 0.8236711621284485,
      "learning_rate": 1.975205116179724e-05,
      "loss": 0.0548,
      "step": 319
    },
    {
      "epoch": 0.21376085504342018,
      "grad_norm": 2.66799259185791,
      "learning_rate": 1.975050069388607e-05,
      "loss": 0.1464,
      "step": 320
    },
    {
      "epoch": 0.21442885771543085,
      "grad_norm": 5.931332111358643,
      "learning_rate": 1.9748945454633028e-05,
      "loss": 0.2529,
      "step": 321
    },
    {
      "epoch": 0.21509686038744155,
      "grad_norm": 1.476887583732605,
      "learning_rate": 1.9747385444799165e-05,
      "loss": 0.0896,
      "step": 322
    },
    {
      "epoch": 0.21576486305945225,
      "grad_norm": 2.6211540699005127,
      "learning_rate": 1.9745820665147856e-05,
      "loss": 0.3187,
      "step": 323
    },
    {
      "epoch": 0.21643286573146292,
      "grad_norm": 1.647347092628479,
      "learning_rate": 1.974425111644482e-05,
      "loss": 0.1909,
      "step": 324
    },
    {
      "epoch": 0.21710086840347362,
      "grad_norm": 1.1162747144699097,
      "learning_rate": 1.9742676799458103e-05,
      "loss": 0.1018,
      "step": 325
    },
    {
      "epoch": 0.2177688710754843,
      "grad_norm": 1.9480150938034058,
      "learning_rate": 1.974109771495809e-05,
      "loss": 0.231,
      "step": 326
    },
    {
      "epoch": 0.218436873747495,
      "grad_norm": 3.18092679977417,
      "learning_rate": 1.973951386371749e-05,
      "loss": 0.2925,
      "step": 327
    },
    {
      "epoch": 0.21910487641950568,
      "grad_norm": 0.8562182188034058,
      "learning_rate": 1.9737925246511353e-05,
      "loss": 0.06,
      "step": 328
    },
    {
      "epoch": 0.21977287909151635,
      "grad_norm": 1.1267461776733398,
      "learning_rate": 1.9736331864117054e-05,
      "loss": 0.1199,
      "step": 329
    },
    {
      "epoch": 0.22044088176352705,
      "grad_norm": 1.0762670040130615,
      "learning_rate": 1.973473371731431e-05,
      "loss": 0.0662,
      "step": 330
    },
    {
      "epoch": 0.22110888443553775,
      "grad_norm": 0.9353739619255066,
      "learning_rate": 1.9733130806885162e-05,
      "loss": 0.0731,
      "step": 331
    },
    {
      "epoch": 0.22177688710754842,
      "grad_norm": 0.9713696837425232,
      "learning_rate": 1.9731523133613978e-05,
      "loss": 0.0481,
      "step": 332
    },
    {
      "epoch": 0.22244488977955912,
      "grad_norm": 1.8638921976089478,
      "learning_rate": 1.972991069828747e-05,
      "loss": 0.214,
      "step": 333
    },
    {
      "epoch": 0.22311289245156982,
      "grad_norm": 3.1937835216522217,
      "learning_rate": 1.972829350169467e-05,
      "loss": 0.2865,
      "step": 334
    },
    {
      "epoch": 0.2237808951235805,
      "grad_norm": 1.6153621673583984,
      "learning_rate": 1.9726671544626934e-05,
      "loss": 0.246,
      "step": 335
    },
    {
      "epoch": 0.22444889779559118,
      "grad_norm": 2.8311374187469482,
      "learning_rate": 1.9725044827877967e-05,
      "loss": 0.2266,
      "step": 336
    },
    {
      "epoch": 0.22511690046760188,
      "grad_norm": 1.1917911767959595,
      "learning_rate": 1.9723413352243788e-05,
      "loss": 0.0683,
      "step": 337
    },
    {
      "epoch": 0.22578490313961255,
      "grad_norm": 1.2257949113845825,
      "learning_rate": 1.972177711852275e-05,
      "loss": 0.2654,
      "step": 338
    },
    {
      "epoch": 0.22645290581162325,
      "grad_norm": 0.9363863468170166,
      "learning_rate": 1.9720136127515528e-05,
      "loss": 0.0968,
      "step": 339
    },
    {
      "epoch": 0.22712090848363392,
      "grad_norm": 0.7734029293060303,
      "learning_rate": 1.9718490380025134e-05,
      "loss": 0.0478,
      "step": 340
    },
    {
      "epoch": 0.22778891115564462,
      "grad_norm": 0.8482262492179871,
      "learning_rate": 1.97168398768569e-05,
      "loss": 0.0481,
      "step": 341
    },
    {
      "epoch": 0.22845691382765532,
      "grad_norm": 1.1171197891235352,
      "learning_rate": 1.9715184618818493e-05,
      "loss": 0.0641,
      "step": 342
    },
    {
      "epoch": 0.229124916499666,
      "grad_norm": 3.357245445251465,
      "learning_rate": 1.9713524606719904e-05,
      "loss": 0.3054,
      "step": 343
    },
    {
      "epoch": 0.22979291917167669,
      "grad_norm": 0.7471925616264343,
      "learning_rate": 1.971185984137344e-05,
      "loss": 0.0723,
      "step": 344
    },
    {
      "epoch": 0.23046092184368738,
      "grad_norm": 0.8025577664375305,
      "learning_rate": 1.971019032359375e-05,
      "loss": 0.0839,
      "step": 345
    },
    {
      "epoch": 0.23112892451569805,
      "grad_norm": 1.3033397197723389,
      "learning_rate": 1.97085160541978e-05,
      "loss": 0.2101,
      "step": 346
    },
    {
      "epoch": 0.23179692718770875,
      "grad_norm": 1.3436284065246582,
      "learning_rate": 1.970683703400488e-05,
      "loss": 0.197,
      "step": 347
    },
    {
      "epoch": 0.23246492985971945,
      "grad_norm": 0.6798595190048218,
      "learning_rate": 1.9705153263836608e-05,
      "loss": 0.0378,
      "step": 348
    },
    {
      "epoch": 0.23313293253173012,
      "grad_norm": 0.8721703290939331,
      "learning_rate": 1.970346474451693e-05,
      "loss": 0.0658,
      "step": 349
    },
    {
      "epoch": 0.23380093520374082,
      "grad_norm": 2.266040325164795,
      "learning_rate": 1.9701771476872108e-05,
      "loss": 0.226,
      "step": 350
    },
    {
      "epoch": 0.23446893787575152,
      "grad_norm": 2.0734121799468994,
      "learning_rate": 1.9700073461730725e-05,
      "loss": 0.2829,
      "step": 351
    },
    {
      "epoch": 0.23513694054776219,
      "grad_norm": 2.6132397651672363,
      "learning_rate": 1.9698370699923706e-05,
      "loss": 0.2906,
      "step": 352
    },
    {
      "epoch": 0.23580494321977288,
      "grad_norm": 2.519395351409912,
      "learning_rate": 1.9696663192284275e-05,
      "loss": 0.2468,
      "step": 353
    },
    {
      "epoch": 0.23647294589178355,
      "grad_norm": 1.1681400537490845,
      "learning_rate": 1.9694950939647997e-05,
      "loss": 0.1486,
      "step": 354
    },
    {
      "epoch": 0.23714094856379425,
      "grad_norm": 0.7695271968841553,
      "learning_rate": 1.9693233942852746e-05,
      "loss": 0.0368,
      "step": 355
    },
    {
      "epoch": 0.23780895123580495,
      "grad_norm": 0.7852323055267334,
      "learning_rate": 1.9691512202738727e-05,
      "loss": 0.0395,
      "step": 356
    },
    {
      "epoch": 0.23847695390781562,
      "grad_norm": 1.8671141862869263,
      "learning_rate": 1.968978572014846e-05,
      "loss": 0.2266,
      "step": 357
    },
    {
      "epoch": 0.23914495657982632,
      "grad_norm": 1.9330480098724365,
      "learning_rate": 1.9688054495926786e-05,
      "loss": 0.2598,
      "step": 358
    },
    {
      "epoch": 0.23981295925183702,
      "grad_norm": 2.559544324874878,
      "learning_rate": 1.968631853092087e-05,
      "loss": 0.2611,
      "step": 359
    },
    {
      "epoch": 0.24048096192384769,
      "grad_norm": 2.686769962310791,
      "learning_rate": 1.9684577825980192e-05,
      "loss": 0.3334,
      "step": 360
    },
    {
      "epoch": 0.24114896459585838,
      "grad_norm": 1.9284791946411133,
      "learning_rate": 1.968283238195656e-05,
      "loss": 0.1497,
      "step": 361
    },
    {
      "epoch": 0.24181696726786908,
      "grad_norm": 1.5035126209259033,
      "learning_rate": 1.9681082199704092e-05,
      "loss": 0.1808,
      "step": 362
    },
    {
      "epoch": 0.24248496993987975,
      "grad_norm": 0.9266881346702576,
      "learning_rate": 1.9679327280079223e-05,
      "loss": 0.0432,
      "step": 363
    },
    {
      "epoch": 0.24315297261189045,
      "grad_norm": 0.8088781833648682,
      "learning_rate": 1.967756762394072e-05,
      "loss": 0.0441,
      "step": 364
    },
    {
      "epoch": 0.24382097528390115,
      "grad_norm": 0.6978743672370911,
      "learning_rate": 1.9675803232149654e-05,
      "loss": 0.0379,
      "step": 365
    },
    {
      "epoch": 0.24448897795591182,
      "grad_norm": 3.717164993286133,
      "learning_rate": 1.967403410556942e-05,
      "loss": 0.294,
      "step": 366
    },
    {
      "epoch": 0.24515698062792252,
      "grad_norm": 0.7527445554733276,
      "learning_rate": 1.9672260245065722e-05,
      "loss": 0.054,
      "step": 367
    },
    {
      "epoch": 0.2458249832999332,
      "grad_norm": 1.939957857131958,
      "learning_rate": 1.9670481651506598e-05,
      "loss": 0.2218,
      "step": 368
    },
    {
      "epoch": 0.24649298597194388,
      "grad_norm": 1.6765433549880981,
      "learning_rate": 1.9668698325762378e-05,
      "loss": 0.0922,
      "step": 369
    },
    {
      "epoch": 0.24716098864395458,
      "grad_norm": 1.4731872081756592,
      "learning_rate": 1.9666910268705733e-05,
      "loss": 0.0685,
      "step": 370
    },
    {
      "epoch": 0.24782899131596525,
      "grad_norm": 4.773686408996582,
      "learning_rate": 1.9665117481211627e-05,
      "loss": 0.3358,
      "step": 371
    },
    {
      "epoch": 0.24849699398797595,
      "grad_norm": 2.311093807220459,
      "learning_rate": 1.9663319964157354e-05,
      "loss": 0.2093,
      "step": 372
    },
    {
      "epoch": 0.24916499665998665,
      "grad_norm": 1.3712509870529175,
      "learning_rate": 1.9661517718422515e-05,
      "loss": 0.171,
      "step": 373
    },
    {
      "epoch": 0.24983299933199732,
      "grad_norm": 1.0737318992614746,
      "learning_rate": 1.9659710744889025e-05,
      "loss": 0.0875,
      "step": 374
    },
    {
      "epoch": 0.250501002004008,
      "grad_norm": 3.3337740898132324,
      "learning_rate": 1.965789904444112e-05,
      "loss": 0.315,
      "step": 375
    },
    {
      "epoch": 0.2511690046760187,
      "grad_norm": 0.9628034234046936,
      "learning_rate": 1.9656082617965335e-05,
      "loss": 0.0464,
      "step": 376
    },
    {
      "epoch": 0.2518370073480294,
      "grad_norm": 1.7632100582122803,
      "learning_rate": 1.9654261466350533e-05,
      "loss": 0.112,
      "step": 377
    },
    {
      "epoch": 0.25250501002004005,
      "grad_norm": 1.023847222328186,
      "learning_rate": 1.9652435590487878e-05,
      "loss": 0.0476,
      "step": 378
    },
    {
      "epoch": 0.2531730126920508,
      "grad_norm": 2.8420331478118896,
      "learning_rate": 1.9650604991270853e-05,
      "loss": 0.2231,
      "step": 379
    },
    {
      "epoch": 0.25384101536406145,
      "grad_norm": 0.8874754905700684,
      "learning_rate": 1.964876966959525e-05,
      "loss": 0.0401,
      "step": 380
    },
    {
      "epoch": 0.2545090180360721,
      "grad_norm": 1.9366549253463745,
      "learning_rate": 1.964692962635917e-05,
      "loss": 0.2429,
      "step": 381
    },
    {
      "epoch": 0.25517702070808285,
      "grad_norm": 1.1903690099716187,
      "learning_rate": 1.9645084862463023e-05,
      "loss": 0.0516,
      "step": 382
    },
    {
      "epoch": 0.2558450233800935,
      "grad_norm": 2.0080947875976562,
      "learning_rate": 1.9643235378809537e-05,
      "loss": 0.2795,
      "step": 383
    },
    {
      "epoch": 0.2565130260521042,
      "grad_norm": 1.3589997291564941,
      "learning_rate": 1.964138117630374e-05,
      "loss": 0.2001,
      "step": 384
    },
    {
      "epoch": 0.2571810287241149,
      "grad_norm": 1.5195585489273071,
      "learning_rate": 1.9639522255852977e-05,
      "loss": 0.2259,
      "step": 385
    },
    {
      "epoch": 0.2578490313961256,
      "grad_norm": 0.8370922207832336,
      "learning_rate": 1.963765861836689e-05,
      "loss": 0.0532,
      "step": 386
    },
    {
      "epoch": 0.25851703406813625,
      "grad_norm": 1.5958610773086548,
      "learning_rate": 1.963579026475745e-05,
      "loss": 0.1171,
      "step": 387
    },
    {
      "epoch": 0.259185036740147,
      "grad_norm": 1.4360123872756958,
      "learning_rate": 1.963391719593892e-05,
      "loss": 0.2499,
      "step": 388
    },
    {
      "epoch": 0.25985303941215765,
      "grad_norm": 2.0966784954071045,
      "learning_rate": 1.9632039412827864e-05,
      "loss": 0.2115,
      "step": 389
    },
    {
      "epoch": 0.2605210420841683,
      "grad_norm": 2.405975818634033,
      "learning_rate": 1.963015691634317e-05,
      "loss": 0.1356,
      "step": 390
    },
    {
      "epoch": 0.26118904475617905,
      "grad_norm": 1.3654146194458008,
      "learning_rate": 1.9628269707406025e-05,
      "loss": 0.2112,
      "step": 391
    },
    {
      "epoch": 0.2618570474281897,
      "grad_norm": 2.2710912227630615,
      "learning_rate": 1.9626377786939927e-05,
      "loss": 0.2612,
      "step": 392
    },
    {
      "epoch": 0.2625250501002004,
      "grad_norm": 0.9460981488227844,
      "learning_rate": 1.962448115587066e-05,
      "loss": 0.0445,
      "step": 393
    },
    {
      "epoch": 0.2631930527722111,
      "grad_norm": 1.2969928979873657,
      "learning_rate": 1.962257981512634e-05,
      "loss": 0.2088,
      "step": 394
    },
    {
      "epoch": 0.2638610554442218,
      "grad_norm": 1.115600347518921,
      "learning_rate": 1.9620673765637373e-05,
      "loss": 0.0507,
      "step": 395
    },
    {
      "epoch": 0.26452905811623245,
      "grad_norm": 0.9024732708930969,
      "learning_rate": 1.961876300833647e-05,
      "loss": 0.0349,
      "step": 396
    },
    {
      "epoch": 0.2651970607882432,
      "grad_norm": 1.1783478260040283,
      "learning_rate": 1.9616847544158645e-05,
      "loss": 0.0459,
      "step": 397
    },
    {
      "epoch": 0.26586506346025385,
      "grad_norm": 1.63950777053833,
      "learning_rate": 1.9614927374041223e-05,
      "loss": 0.1613,
      "step": 398
    },
    {
      "epoch": 0.2665330661322645,
      "grad_norm": 0.6264683604240417,
      "learning_rate": 1.9613002498923818e-05,
      "loss": 0.0281,
      "step": 399
    },
    {
      "epoch": 0.26720106880427524,
      "grad_norm": 2.1400387287139893,
      "learning_rate": 1.9611072919748364e-05,
      "loss": 0.2591,
      "step": 400
    },
    {
      "epoch": 0.2678690714762859,
      "grad_norm": 1.0317983627319336,
      "learning_rate": 1.9609138637459085e-05,
      "loss": 0.1778,
      "step": 401
    },
    {
      "epoch": 0.2685370741482966,
      "grad_norm": 0.6877316236495972,
      "learning_rate": 1.9607199653002502e-05,
      "loss": 0.0262,
      "step": 402
    },
    {
      "epoch": 0.26920507682030725,
      "grad_norm": 1.1419932842254639,
      "learning_rate": 1.9605255967327452e-05,
      "loss": 0.0954,
      "step": 403
    },
    {
      "epoch": 0.269873079492318,
      "grad_norm": 1.1398128271102905,
      "learning_rate": 1.9603307581385063e-05,
      "loss": 0.0374,
      "step": 404
    },
    {
      "epoch": 0.27054108216432865,
      "grad_norm": 1.9014568328857422,
      "learning_rate": 1.9601354496128765e-05,
      "loss": 0.2395,
      "step": 405
    },
    {
      "epoch": 0.2712090848363393,
      "grad_norm": 2.045936107635498,
      "learning_rate": 1.9599396712514283e-05,
      "loss": 0.2582,
      "step": 406
    },
    {
      "epoch": 0.27187708750835005,
      "grad_norm": 1.5560736656188965,
      "learning_rate": 1.959743423149965e-05,
      "loss": 0.1832,
      "step": 407
    },
    {
      "epoch": 0.2725450901803607,
      "grad_norm": 1.0305907726287842,
      "learning_rate": 1.9595467054045187e-05,
      "loss": 0.0459,
      "step": 408
    },
    {
      "epoch": 0.2732130928523714,
      "grad_norm": 2.744169235229492,
      "learning_rate": 1.9593495181113528e-05,
      "loss": 0.2579,
      "step": 409
    },
    {
      "epoch": 0.2738810955243821,
      "grad_norm": 1.2960249185562134,
      "learning_rate": 1.9591518613669586e-05,
      "loss": 0.1442,
      "step": 410
    },
    {
      "epoch": 0.2745490981963928,
      "grad_norm": 0.5047690272331238,
      "learning_rate": 1.9589537352680586e-05,
      "loss": 0.0224,
      "step": 411
    },
    {
      "epoch": 0.27521710086840345,
      "grad_norm": 0.6055000424385071,
      "learning_rate": 1.9587551399116048e-05,
      "loss": 0.0285,
      "step": 412
    },
    {
      "epoch": 0.2758851035404142,
      "grad_norm": 1.4434478282928467,
      "learning_rate": 1.9585560753947775e-05,
      "loss": 0.0745,
      "step": 413
    },
    {
      "epoch": 0.27655310621242485,
      "grad_norm": 1.6580711603164673,
      "learning_rate": 1.9583565418149887e-05,
      "loss": 0.1744,
      "step": 414
    },
    {
      "epoch": 0.2772211088844355,
      "grad_norm": 1.0207228660583496,
      "learning_rate": 1.958156539269878e-05,
      "loss": 0.0438,
      "step": 415
    },
    {
      "epoch": 0.27788911155644624,
      "grad_norm": 4.15825080871582,
      "learning_rate": 1.957956067857316e-05,
      "loss": 0.2596,
      "step": 416
    },
    {
      "epoch": 0.2785571142284569,
      "grad_norm": 2.0618221759796143,
      "learning_rate": 1.9577551276754015e-05,
      "loss": 0.1815,
      "step": 417
    },
    {
      "epoch": 0.2792251169004676,
      "grad_norm": 2.4694361686706543,
      "learning_rate": 1.9575537188224633e-05,
      "loss": 0.2672,
      "step": 418
    },
    {
      "epoch": 0.2798931195724783,
      "grad_norm": 2.237250328063965,
      "learning_rate": 1.9573518413970593e-05,
      "loss": 0.1995,
      "step": 419
    },
    {
      "epoch": 0.280561122244489,
      "grad_norm": 3.0681445598602295,
      "learning_rate": 1.9571494954979776e-05,
      "loss": 0.1926,
      "step": 420
    },
    {
      "epoch": 0.28122912491649965,
      "grad_norm": 0.8816598057746887,
      "learning_rate": 1.956946681224234e-05,
      "loss": 0.0305,
      "step": 421
    },
    {
      "epoch": 0.2818971275885104,
      "grad_norm": 2.267550230026245,
      "learning_rate": 1.956743398675075e-05,
      "loss": 0.1735,
      "step": 422
    },
    {
      "epoch": 0.28256513026052105,
      "grad_norm": 1.013169288635254,
      "learning_rate": 1.9565396479499744e-05,
      "loss": 0.0389,
      "step": 423
    },
    {
      "epoch": 0.2832331329325317,
      "grad_norm": 2.030935525894165,
      "learning_rate": 1.9563354291486372e-05,
      "loss": 0.1214,
      "step": 424
    },
    {
      "epoch": 0.28390113560454244,
      "grad_norm": 1.5877490043640137,
      "learning_rate": 1.9561307423709968e-05,
      "loss": 0.0564,
      "step": 425
    },
    {
      "epoch": 0.2845691382765531,
      "grad_norm": 1.0020464658737183,
      "learning_rate": 1.9559255877172146e-05,
      "loss": 0.1665,
      "step": 426
    },
    {
      "epoch": 0.2852371409485638,
      "grad_norm": 1.7694032192230225,
      "learning_rate": 1.9557199652876818e-05,
      "loss": 0.2102,
      "step": 427
    },
    {
      "epoch": 0.2859051436205745,
      "grad_norm": 1.0077401399612427,
      "learning_rate": 1.955513875183018e-05,
      "loss": 0.0406,
      "step": 428
    },
    {
      "epoch": 0.2865731462925852,
      "grad_norm": 1.2892402410507202,
      "learning_rate": 1.9553073175040728e-05,
      "loss": 0.0967,
      "step": 429
    },
    {
      "epoch": 0.28724114896459585,
      "grad_norm": 1.292860746383667,
      "learning_rate": 1.9551002923519235e-05,
      "loss": 0.0602,
      "step": 430
    },
    {
      "epoch": 0.2879091516366065,
      "grad_norm": 2.6418590545654297,
      "learning_rate": 1.9548927998278763e-05,
      "loss": 0.147,
      "step": 431
    },
    {
      "epoch": 0.28857715430861725,
      "grad_norm": 3.3435721397399902,
      "learning_rate": 1.9546848400334658e-05,
      "loss": 0.1975,
      "step": 432
    },
    {
      "epoch": 0.2892451569806279,
      "grad_norm": 0.8489255905151367,
      "learning_rate": 1.954476413070457e-05,
      "loss": 0.0295,
      "step": 433
    },
    {
      "epoch": 0.2899131596526386,
      "grad_norm": 0.7919626832008362,
      "learning_rate": 1.9542675190408412e-05,
      "loss": 0.0251,
      "step": 434
    },
    {
      "epoch": 0.2905811623246493,
      "grad_norm": 2.476919412612915,
      "learning_rate": 1.9540581580468398e-05,
      "loss": 0.2214,
      "step": 435
    },
    {
      "epoch": 0.29124916499666,
      "grad_norm": 1.700636386871338,
      "learning_rate": 1.9538483301909013e-05,
      "loss": 0.139,
      "step": 436
    },
    {
      "epoch": 0.29191716766867065,
      "grad_norm": 3.16455078125,
      "learning_rate": 1.953638035575705e-05,
      "loss": 0.3175,
      "step": 437
    },
    {
      "epoch": 0.2925851703406814,
      "grad_norm": 2.597511053085327,
      "learning_rate": 1.953427274304156e-05,
      "loss": 0.2666,
      "step": 438
    },
    {
      "epoch": 0.29325317301269205,
      "grad_norm": 1.1245648860931396,
      "learning_rate": 1.9532160464793893e-05,
      "loss": 0.1012,
      "step": 439
    },
    {
      "epoch": 0.2939211756847027,
      "grad_norm": 1.1354448795318604,
      "learning_rate": 1.9530043522047678e-05,
      "loss": 0.1326,
      "step": 440
    },
    {
      "epoch": 0.29458917835671344,
      "grad_norm": 1.1554499864578247,
      "learning_rate": 1.9527921915838827e-05,
      "loss": 0.0788,
      "step": 441
    },
    {
      "epoch": 0.2952571810287241,
      "grad_norm": 3.3615059852600098,
      "learning_rate": 1.9525795647205534e-05,
      "loss": 0.168,
      "step": 442
    },
    {
      "epoch": 0.2959251837007348,
      "grad_norm": 6.799528121948242,
      "learning_rate": 1.9523664717188274e-05,
      "loss": 0.3825,
      "step": 443
    },
    {
      "epoch": 0.2965931863727455,
      "grad_norm": 0.6910368204116821,
      "learning_rate": 1.9521529126829803e-05,
      "loss": 0.0257,
      "step": 444
    },
    {
      "epoch": 0.2972611890447562,
      "grad_norm": 0.3451730012893677,
      "learning_rate": 1.9519388877175155e-05,
      "loss": 0.0154,
      "step": 445
    },
    {
      "epoch": 0.29792919171676685,
      "grad_norm": 2.2097256183624268,
      "learning_rate": 1.951724396927165e-05,
      "loss": 0.2211,
      "step": 446
    },
    {
      "epoch": 0.2985971943887776,
      "grad_norm": 5.14554500579834,
      "learning_rate": 1.9515094404168885e-05,
      "loss": 0.3068,
      "step": 447
    },
    {
      "epoch": 0.29926519706078825,
      "grad_norm": 1.0453097820281982,
      "learning_rate": 1.9512940182918734e-05,
      "loss": 0.0299,
      "step": 448
    },
    {
      "epoch": 0.2999331997327989,
      "grad_norm": 0.638062059879303,
      "learning_rate": 1.951078130657535e-05,
      "loss": 0.0206,
      "step": 449
    },
    {
      "epoch": 0.30060120240480964,
      "grad_norm": 0.6020998358726501,
      "learning_rate": 1.9508617776195167e-05,
      "loss": 0.02,
      "step": 450
    },
    {
      "epoch": 0.3012692050768203,
      "grad_norm": 0.760014533996582,
      "learning_rate": 1.950644959283689e-05,
      "loss": 0.0282,
      "step": 451
    },
    {
      "epoch": 0.301937207748831,
      "grad_norm": 2.8818113803863525,
      "learning_rate": 1.9504276757561507e-05,
      "loss": 0.2477,
      "step": 452
    },
    {
      "epoch": 0.3026052104208417,
      "grad_norm": 1.5047123432159424,
      "learning_rate": 1.9502099271432282e-05,
      "loss": 0.1567,
      "step": 453
    },
    {
      "epoch": 0.3032732130928524,
      "grad_norm": 0.9165982007980347,
      "learning_rate": 1.949991713551475e-05,
      "loss": 0.0412,
      "step": 454
    },
    {
      "epoch": 0.30394121576486305,
      "grad_norm": 1.3127779960632324,
      "learning_rate": 1.9497730350876727e-05,
      "loss": 0.032,
      "step": 455
    },
    {
      "epoch": 0.3046092184368738,
      "grad_norm": 4.206820964813232,
      "learning_rate": 1.94955389185883e-05,
      "loss": 0.3231,
      "step": 456
    },
    {
      "epoch": 0.30527722110888444,
      "grad_norm": 0.6187949180603027,
      "learning_rate": 1.9493342839721833e-05,
      "loss": 0.0199,
      "step": 457
    },
    {
      "epoch": 0.3059452237808951,
      "grad_norm": 4.279544830322266,
      "learning_rate": 1.949114211535196e-05,
      "loss": 0.3011,
      "step": 458
    },
    {
      "epoch": 0.3066132264529058,
      "grad_norm": 1.150491714477539,
      "learning_rate": 1.9488936746555593e-05,
      "loss": 0.0473,
      "step": 459
    },
    {
      "epoch": 0.3072812291249165,
      "grad_norm": 0.4845108985900879,
      "learning_rate": 1.9486726734411913e-05,
      "loss": 0.0183,
      "step": 460
    },
    {
      "epoch": 0.3079492317969272,
      "grad_norm": 0.667567253112793,
      "learning_rate": 1.9484512080002376e-05,
      "loss": 0.0202,
      "step": 461
    },
    {
      "epoch": 0.30861723446893785,
      "grad_norm": 0.33902835845947266,
      "learning_rate": 1.9482292784410707e-05,
      "loss": 0.0132,
      "step": 462
    },
    {
      "epoch": 0.3092852371409486,
      "grad_norm": 1.9776402711868286,
      "learning_rate": 1.9480068848722903e-05,
      "loss": 0.2063,
      "step": 463
    },
    {
      "epoch": 0.30995323981295925,
      "grad_norm": 2.973560333251953,
      "learning_rate": 1.947784027402723e-05,
      "loss": 0.2057,
      "step": 464
    },
    {
      "epoch": 0.3106212424849699,
      "grad_norm": 0.8361791968345642,
      "learning_rate": 1.9475607061414235e-05,
      "loss": 0.0238,
      "step": 465
    },
    {
      "epoch": 0.31128924515698064,
      "grad_norm": 1.0088087320327759,
      "learning_rate": 1.9473369211976715e-05,
      "loss": 0.0383,
      "step": 466
    },
    {
      "epoch": 0.3119572478289913,
      "grad_norm": 4.948399543762207,
      "learning_rate": 1.947112672680975e-05,
      "loss": 0.3462,
      "step": 467
    },
    {
      "epoch": 0.312625250501002,
      "grad_norm": 2.0473310947418213,
      "learning_rate": 1.946887960701069e-05,
      "loss": 0.1778,
      "step": 468
    },
    {
      "epoch": 0.3132932531730127,
      "grad_norm": 0.41895154118537903,
      "learning_rate": 1.9466627853679142e-05,
      "loss": 0.0168,
      "step": 469
    },
    {
      "epoch": 0.3139612558450234,
      "grad_norm": 0.2144852876663208,
      "learning_rate": 1.9464371467916985e-05,
      "loss": 0.0076,
      "step": 470
    },
    {
      "epoch": 0.31462925851703405,
      "grad_norm": 0.3889913260936737,
      "learning_rate": 1.9462110450828375e-05,
      "loss": 0.0131,
      "step": 471
    },
    {
      "epoch": 0.3152972611890448,
      "grad_norm": 6.53591775894165,
      "learning_rate": 1.9459844803519713e-05,
      "loss": 0.4573,
      "step": 472
    },
    {
      "epoch": 0.31596526386105545,
      "grad_norm": 1.3148611783981323,
      "learning_rate": 1.9457574527099693e-05,
      "loss": 0.1743,
      "step": 473
    },
    {
      "epoch": 0.3166332665330661,
      "grad_norm": 0.7458335757255554,
      "learning_rate": 1.9455299622679243e-05,
      "loss": 0.0221,
      "step": 474
    },
    {
      "epoch": 0.31730126920507684,
      "grad_norm": 2.2882347106933594,
      "learning_rate": 1.9453020091371585e-05,
      "loss": 0.234,
      "step": 475
    },
    {
      "epoch": 0.3179692718770875,
      "grad_norm": 0.6966751217842102,
      "learning_rate": 1.945073593429219e-05,
      "loss": 0.0245,
      "step": 476
    },
    {
      "epoch": 0.3186372745490982,
      "grad_norm": 3.0426177978515625,
      "learning_rate": 1.944844715255879e-05,
      "loss": 0.2372,
      "step": 477
    },
    {
      "epoch": 0.3193052772211089,
      "grad_norm": 0.19581617414951324,
      "learning_rate": 1.9446153747291387e-05,
      "loss": 0.0083,
      "step": 478
    },
    {
      "epoch": 0.3199732798931196,
      "grad_norm": 1.732581377029419,
      "learning_rate": 1.9443855719612245e-05,
      "loss": 0.1881,
      "step": 479
    },
    {
      "epoch": 0.32064128256513025,
      "grad_norm": 0.1257486641407013,
      "learning_rate": 1.9441553070645887e-05,
      "loss": 0.0061,
      "step": 480
    },
    {
      "epoch": 0.321309285237141,
      "grad_norm": 3.9726972579956055,
      "learning_rate": 1.94392458015191e-05,
      "loss": 0.2914,
      "step": 481
    },
    {
      "epoch": 0.32197728790915164,
      "grad_norm": 0.33816686272621155,
      "learning_rate": 1.943693391336093e-05,
      "loss": 0.0097,
      "step": 482
    },
    {
      "epoch": 0.3226452905811623,
      "grad_norm": 1.6251202821731567,
      "learning_rate": 1.9434617407302686e-05,
      "loss": 0.1896,
      "step": 483
    },
    {
      "epoch": 0.32331329325317304,
      "grad_norm": 1.8683418035507202,
      "learning_rate": 1.943229628447793e-05,
      "loss": 0.2167,
      "step": 484
    },
    {
      "epoch": 0.3239812959251837,
      "grad_norm": 1.3837144374847412,
      "learning_rate": 1.9429970546022486e-05,
      "loss": 0.1173,
      "step": 485
    },
    {
      "epoch": 0.3246492985971944,
      "grad_norm": 5.470568656921387,
      "learning_rate": 1.942764019307445e-05,
      "loss": 0.3114,
      "step": 486
    },
    {
      "epoch": 0.32531730126920505,
      "grad_norm": 0.5320578217506409,
      "learning_rate": 1.9425305226774155e-05,
      "loss": 0.0162,
      "step": 487
    },
    {
      "epoch": 0.3259853039412158,
      "grad_norm": 1.1068981885910034,
      "learning_rate": 1.9422965648264202e-05,
      "loss": 0.087,
      "step": 488
    },
    {
      "epoch": 0.32665330661322645,
      "grad_norm": 0.26107093691825867,
      "learning_rate": 1.942062145868945e-05,
      "loss": 0.0107,
      "step": 489
    },
    {
      "epoch": 0.3273213092852371,
      "grad_norm": 1.0778493881225586,
      "learning_rate": 1.941827265919701e-05,
      "loss": 0.028,
      "step": 490
    },
    {
      "epoch": 0.32798931195724784,
      "grad_norm": 2.7158868312835693,
      "learning_rate": 1.941591925093626e-05,
      "loss": 0.2976,
      "step": 491
    },
    {
      "epoch": 0.3286573146292585,
      "grad_norm": 2.122526168823242,
      "learning_rate": 1.9413561235058812e-05,
      "loss": 0.1799,
      "step": 492
    },
    {
      "epoch": 0.3293253173012692,
      "grad_norm": 2.8344533443450928,
      "learning_rate": 1.9411198612718548e-05,
      "loss": 0.3013,
      "step": 493
    },
    {
      "epoch": 0.3299933199732799,
      "grad_norm": 0.3841102123260498,
      "learning_rate": 1.9408831385071608e-05,
      "loss": 0.0104,
      "step": 494
    },
    {
      "epoch": 0.3306613226452906,
      "grad_norm": 3.794832468032837,
      "learning_rate": 1.940645955327637e-05,
      "loss": 0.2138,
      "step": 495
    },
    {
      "epoch": 0.33132932531730125,
      "grad_norm": 1.3763749599456787,
      "learning_rate": 1.9404083118493485e-05,
      "loss": 0.184,
      "step": 496
    },
    {
      "epoch": 0.331997327989312,
      "grad_norm": 0.18485668301582336,
      "learning_rate": 1.9401702081885836e-05,
      "loss": 0.0091,
      "step": 497
    },
    {
      "epoch": 0.33266533066132264,
      "grad_norm": 0.8945978879928589,
      "learning_rate": 1.939931644461857e-05,
      "loss": 0.0278,
      "step": 498
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.22010013461112976,
      "learning_rate": 1.9396926207859085e-05,
      "loss": 0.008,
      "step": 499
    },
    {
      "epoch": 0.33400133600534404,
      "grad_norm": 4.520571231842041,
      "learning_rate": 1.9394531372777025e-05,
      "loss": 0.2649,
      "step": 500
    },
    {
      "epoch": 0.3346693386773547,
      "grad_norm": 0.4613184332847595,
      "learning_rate": 1.9392131940544285e-05,
      "loss": 0.0139,
      "step": 501
    },
    {
      "epoch": 0.3353373413493654,
      "grad_norm": 5.122935771942139,
      "learning_rate": 1.9389727912335012e-05,
      "loss": 0.2487,
      "step": 502
    },
    {
      "epoch": 0.3360053440213761,
      "grad_norm": 1.1016066074371338,
      "learning_rate": 1.9387319289325606e-05,
      "loss": 0.0941,
      "step": 503
    },
    {
      "epoch": 0.3366733466933868,
      "grad_norm": 0.5507741570472717,
      "learning_rate": 1.9384906072694703e-05,
      "loss": 0.0168,
      "step": 504
    },
    {
      "epoch": 0.33734134936539745,
      "grad_norm": 1.9984657764434814,
      "learning_rate": 1.9382488263623196e-05,
      "loss": 0.2376,
      "step": 505
    },
    {
      "epoch": 0.3380093520374082,
      "grad_norm": 0.5617219805717468,
      "learning_rate": 1.9380065863294227e-05,
      "loss": 0.016,
      "step": 506
    },
    {
      "epoch": 0.33867735470941884,
      "grad_norm": 1.8261157274246216,
      "learning_rate": 1.9377638872893178e-05,
      "loss": 0.1806,
      "step": 507
    },
    {
      "epoch": 0.3393453573814295,
      "grad_norm": 1.348601222038269,
      "learning_rate": 1.937520729360768e-05,
      "loss": 0.1643,
      "step": 508
    },
    {
      "epoch": 0.34001336005344024,
      "grad_norm": 6.688627243041992,
      "learning_rate": 1.9372771126627613e-05,
      "loss": 0.3041,
      "step": 509
    },
    {
      "epoch": 0.3406813627254509,
      "grad_norm": 2.112067461013794,
      "learning_rate": 1.93703303731451e-05,
      "loss": 0.2098,
      "step": 510
    },
    {
      "epoch": 0.3413493653974616,
      "grad_norm": 1.7164045572280884,
      "learning_rate": 1.9367885034354505e-05,
      "loss": 0.2261,
      "step": 511
    },
    {
      "epoch": 0.3420173680694723,
      "grad_norm": 1.7733252048492432,
      "learning_rate": 1.9365435111452434e-05,
      "loss": 0.1753,
      "step": 512
    },
    {
      "epoch": 0.342685370741483,
      "grad_norm": 3.833765983581543,
      "learning_rate": 1.936298060563775e-05,
      "loss": 0.2244,
      "step": 513
    },
    {
      "epoch": 0.34335337341349365,
      "grad_norm": 2.951949119567871,
      "learning_rate": 1.9360521518111537e-05,
      "loss": 0.2421,
      "step": 514
    },
    {
      "epoch": 0.3440213760855043,
      "grad_norm": 3.510586738586426,
      "learning_rate": 1.9358057850077142e-05,
      "loss": 0.2124,
      "step": 515
    },
    {
      "epoch": 0.34468937875751504,
      "grad_norm": 0.6149975657463074,
      "learning_rate": 1.9355589602740142e-05,
      "loss": 0.0207,
      "step": 516
    },
    {
      "epoch": 0.3453573814295257,
      "grad_norm": 0.7196821570396423,
      "learning_rate": 1.9353116777308353e-05,
      "loss": 0.0209,
      "step": 517
    },
    {
      "epoch": 0.3460253841015364,
      "grad_norm": 5.124246120452881,
      "learning_rate": 1.935063937499184e-05,
      "loss": 0.3199,
      "step": 518
    },
    {
      "epoch": 0.3466933867735471,
      "grad_norm": 2.220663070678711,
      "learning_rate": 1.9348157397002904e-05,
      "loss": 0.2081,
      "step": 519
    },
    {
      "epoch": 0.3473613894455578,
      "grad_norm": 0.851001501083374,
      "learning_rate": 1.9345670844556082e-05,
      "loss": 0.02,
      "step": 520
    },
    {
      "epoch": 0.34802939211756845,
      "grad_norm": 1.000343680381775,
      "learning_rate": 1.9343179718868155e-05,
      "loss": 0.032,
      "step": 521
    },
    {
      "epoch": 0.3486973947895792,
      "grad_norm": 0.8897082805633545,
      "learning_rate": 1.9340684021158133e-05,
      "loss": 0.0251,
      "step": 522
    },
    {
      "epoch": 0.34936539746158984,
      "grad_norm": 1.1546361446380615,
      "learning_rate": 1.933818375264727e-05,
      "loss": 0.0415,
      "step": 523
    },
    {
      "epoch": 0.3500334001336005,
      "grad_norm": 5.194324016571045,
      "learning_rate": 1.933567891455906e-05,
      "loss": 0.377,
      "step": 524
    },
    {
      "epoch": 0.35070140280561124,
      "grad_norm": 1.8543459177017212,
      "learning_rate": 1.9333169508119224e-05,
      "loss": 0.2106,
      "step": 525
    },
    {
      "epoch": 0.3513694054776219,
      "grad_norm": 0.575332522392273,
      "learning_rate": 1.9330655534555728e-05,
      "loss": 0.0173,
      "step": 526
    },
    {
      "epoch": 0.3520374081496326,
      "grad_norm": 2.889744281768799,
      "learning_rate": 1.932813699509876e-05,
      "loss": 0.2032,
      "step": 527
    },
    {
      "epoch": 0.3527054108216433,
      "grad_norm": 3.8143749237060547,
      "learning_rate": 1.932561389098076e-05,
      "loss": 0.263,
      "step": 528
    },
    {
      "epoch": 0.353373413493654,
      "grad_norm": 2.1111490726470947,
      "learning_rate": 1.932308622343638e-05,
      "loss": 0.1409,
      "step": 529
    },
    {
      "epoch": 0.35404141616566465,
      "grad_norm": 5.605349540710449,
      "learning_rate": 1.932055399370253e-05,
      "loss": 0.357,
      "step": 530
    },
    {
      "epoch": 0.35470941883767537,
      "grad_norm": 2.65592098236084,
      "learning_rate": 1.9318017203018334e-05,
      "loss": 0.1843,
      "step": 531
    },
    {
      "epoch": 0.35537742150968604,
      "grad_norm": 0.3033870458602905,
      "learning_rate": 1.9315475852625154e-05,
      "loss": 0.0108,
      "step": 532
    },
    {
      "epoch": 0.3560454241816967,
      "grad_norm": 1.3783836364746094,
      "learning_rate": 1.9312929943766582e-05,
      "loss": 0.041,
      "step": 533
    },
    {
      "epoch": 0.35671342685370744,
      "grad_norm": 4.477558135986328,
      "learning_rate": 1.931037947768844e-05,
      "loss": 0.3646,
      "step": 534
    },
    {
      "epoch": 0.3573814295257181,
      "grad_norm": 1.3324060440063477,
      "learning_rate": 1.9307824455638783e-05,
      "loss": 0.092,
      "step": 535
    },
    {
      "epoch": 0.3580494321977288,
      "grad_norm": 1.234930157661438,
      "learning_rate": 1.9305264878867892e-05,
      "loss": 0.1527,
      "step": 536
    },
    {
      "epoch": 0.3587174348697395,
      "grad_norm": 0.5068759918212891,
      "learning_rate": 1.9302700748628285e-05,
      "loss": 0.015,
      "step": 537
    },
    {
      "epoch": 0.3593854375417502,
      "grad_norm": 0.38292255997657776,
      "learning_rate": 1.9300132066174696e-05,
      "loss": 0.0123,
      "step": 538
    },
    {
      "epoch": 0.36005344021376084,
      "grad_norm": 1.0385808944702148,
      "learning_rate": 1.9297558832764093e-05,
      "loss": 0.1161,
      "step": 539
    },
    {
      "epoch": 0.36072144288577157,
      "grad_norm": 1.2346712350845337,
      "learning_rate": 1.929498104965567e-05,
      "loss": 0.1871,
      "step": 540
    },
    {
      "epoch": 0.36138944555778224,
      "grad_norm": 1.002089023590088,
      "learning_rate": 1.929239871811085e-05,
      "loss": 0.172,
      "step": 541
    },
    {
      "epoch": 0.3620574482297929,
      "grad_norm": 5.339087963104248,
      "learning_rate": 1.928981183939328e-05,
      "loss": 0.3837,
      "step": 542
    },
    {
      "epoch": 0.3627254509018036,
      "grad_norm": 2.589266777038574,
      "learning_rate": 1.9287220414768824e-05,
      "loss": 0.1756,
      "step": 543
    },
    {
      "epoch": 0.3633934535738143,
      "grad_norm": 1.727308988571167,
      "learning_rate": 1.9284624445505592e-05,
      "loss": 0.1566,
      "step": 544
    },
    {
      "epoch": 0.364061456245825,
      "grad_norm": 2.308790683746338,
      "learning_rate": 1.928202393287389e-05,
      "loss": 0.1699,
      "step": 545
    },
    {
      "epoch": 0.36472945891783565,
      "grad_norm": 2.562610387802124,
      "learning_rate": 1.9279418878146273e-05,
      "loss": 0.212,
      "step": 546
    },
    {
      "epoch": 0.3653974615898464,
      "grad_norm": 2.681917428970337,
      "learning_rate": 1.9276809282597502e-05,
      "loss": 0.1909,
      "step": 547
    },
    {
      "epoch": 0.36606546426185704,
      "grad_norm": 1.5534125566482544,
      "learning_rate": 1.9274195147504563e-05,
      "loss": 0.0725,
      "step": 548
    },
    {
      "epoch": 0.3667334669338677,
      "grad_norm": 1.0743001699447632,
      "learning_rate": 1.9271576474146667e-05,
      "loss": 0.1098,
      "step": 549
    },
    {
      "epoch": 0.36740146960587844,
      "grad_norm": 1.5919314622879028,
      "learning_rate": 1.9268953263805246e-05,
      "loss": 0.1513,
      "step": 550
    },
    {
      "epoch": 0.3680694722778891,
      "grad_norm": 4.096851825714111,
      "learning_rate": 1.9266325517763946e-05,
      "loss": 0.2959,
      "step": 551
    },
    {
      "epoch": 0.3687374749498998,
      "grad_norm": 1.3196872472763062,
      "learning_rate": 1.926369323730864e-05,
      "loss": 0.0464,
      "step": 552
    },
    {
      "epoch": 0.3694054776219105,
      "grad_norm": 2.967085838317871,
      "learning_rate": 1.926105642372742e-05,
      "loss": 0.2254,
      "step": 553
    },
    {
      "epoch": 0.3700734802939212,
      "grad_norm": 1.783129096031189,
      "learning_rate": 1.9258415078310584e-05,
      "loss": 0.0618,
      "step": 554
    },
    {
      "epoch": 0.37074148296593185,
      "grad_norm": 1.4577451944351196,
      "learning_rate": 1.9255769202350663e-05,
      "loss": 0.132,
      "step": 555
    },
    {
      "epoch": 0.37140948563794257,
      "grad_norm": 2.1618552207946777,
      "learning_rate": 1.92531187971424e-05,
      "loss": 0.1718,
      "step": 556
    },
    {
      "epoch": 0.37207748830995324,
      "grad_norm": 1.5536320209503174,
      "learning_rate": 1.925046386398275e-05,
      "loss": 0.1403,
      "step": 557
    },
    {
      "epoch": 0.3727454909819639,
      "grad_norm": 1.3473740816116333,
      "learning_rate": 1.9247804404170888e-05,
      "loss": 0.128,
      "step": 558
    },
    {
      "epoch": 0.37341349365397464,
      "grad_norm": 1.3929935693740845,
      "learning_rate": 1.92451404190082e-05,
      "loss": 0.165,
      "step": 559
    },
    {
      "epoch": 0.3740814963259853,
      "grad_norm": 1.6078590154647827,
      "learning_rate": 1.9242471909798293e-05,
      "loss": 0.0576,
      "step": 560
    },
    {
      "epoch": 0.374749498997996,
      "grad_norm": 1.1638273000717163,
      "learning_rate": 1.923979887784698e-05,
      "loss": 0.1148,
      "step": 561
    },
    {
      "epoch": 0.3754175016700067,
      "grad_norm": 1.017415165901184,
      "learning_rate": 1.9237121324462293e-05,
      "loss": 0.0235,
      "step": 562
    },
    {
      "epoch": 0.3760855043420174,
      "grad_norm": 1.640529751777649,
      "learning_rate": 1.9234439250954476e-05,
      "loss": 0.0317,
      "step": 563
    },
    {
      "epoch": 0.37675350701402804,
      "grad_norm": 2.0647499561309814,
      "learning_rate": 1.9231752658635984e-05,
      "loss": 0.1739,
      "step": 564
    },
    {
      "epoch": 0.37742150968603877,
      "grad_norm": 1.2669670581817627,
      "learning_rate": 1.9229061548821478e-05,
      "loss": 0.162,
      "step": 565
    },
    {
      "epoch": 0.37808951235804944,
      "grad_norm": 0.8336933851242065,
      "learning_rate": 1.922636592282784e-05,
      "loss": 0.0188,
      "step": 566
    },
    {
      "epoch": 0.3787575150300601,
      "grad_norm": 1.1782691478729248,
      "learning_rate": 1.9223665781974154e-05,
      "loss": 0.0345,
      "step": 567
    },
    {
      "epoch": 0.37942551770207084,
      "grad_norm": 3.388110637664795,
      "learning_rate": 1.9220961127581716e-05,
      "loss": 0.2596,
      "step": 568
    },
    {
      "epoch": 0.3800935203740815,
      "grad_norm": 1.0239752531051636,
      "learning_rate": 1.921825196097403e-05,
      "loss": 0.0286,
      "step": 569
    },
    {
      "epoch": 0.3807615230460922,
      "grad_norm": 0.773328959941864,
      "learning_rate": 1.921553828347681e-05,
      "loss": 0.153,
      "step": 570
    },
    {
      "epoch": 0.38142952571810285,
      "grad_norm": 2.132838726043701,
      "learning_rate": 1.9212820096417975e-05,
      "loss": 0.134,
      "step": 571
    },
    {
      "epoch": 0.38209752839011357,
      "grad_norm": 1.8240654468536377,
      "learning_rate": 1.921009740112765e-05,
      "loss": 0.1804,
      "step": 572
    },
    {
      "epoch": 0.38276553106212424,
      "grad_norm": 1.5850048065185547,
      "learning_rate": 1.920737019893817e-05,
      "loss": 0.1347,
      "step": 573
    },
    {
      "epoch": 0.3834335337341349,
      "grad_norm": 2.6765096187591553,
      "learning_rate": 1.9204638491184072e-05,
      "loss": 0.0962,
      "step": 574
    },
    {
      "epoch": 0.38410153640614564,
      "grad_norm": 0.6526788473129272,
      "learning_rate": 1.92019022792021e-05,
      "loss": 0.0182,
      "step": 575
    },
    {
      "epoch": 0.3847695390781563,
      "grad_norm": 1.8496503829956055,
      "learning_rate": 1.9199161564331196e-05,
      "loss": 0.204,
      "step": 576
    },
    {
      "epoch": 0.385437541750167,
      "grad_norm": 2.6198997497558594,
      "learning_rate": 1.9196416347912517e-05,
      "loss": 0.2114,
      "step": 577
    },
    {
      "epoch": 0.3861055444221777,
      "grad_norm": 3.1264941692352295,
      "learning_rate": 1.9193666631289413e-05,
      "loss": 0.2527,
      "step": 578
    },
    {
      "epoch": 0.3867735470941884,
      "grad_norm": 1.5141514539718628,
      "learning_rate": 1.9190912415807436e-05,
      "loss": 0.1494,
      "step": 579
    },
    {
      "epoch": 0.38744154976619904,
      "grad_norm": 3.9601175785064697,
      "learning_rate": 1.9188153702814348e-05,
      "loss": 0.2475,
      "step": 580
    },
    {
      "epoch": 0.38810955243820977,
      "grad_norm": 0.9584656953811646,
      "learning_rate": 1.918539049366011e-05,
      "loss": 0.0273,
      "step": 581
    },
    {
      "epoch": 0.38877755511022044,
      "grad_norm": 2.2064385414123535,
      "learning_rate": 1.918262278969687e-05,
      "loss": 0.1252,
      "step": 582
    },
    {
      "epoch": 0.3894455577822311,
      "grad_norm": 0.5676106810569763,
      "learning_rate": 1.9179850592278992e-05,
      "loss": 0.0155,
      "step": 583
    },
    {
      "epoch": 0.39011356045424184,
      "grad_norm": 1.2534668445587158,
      "learning_rate": 1.9177073902763025e-05,
      "loss": 0.1466,
      "step": 584
    },
    {
      "epoch": 0.3907815631262525,
      "grad_norm": 2.2551169395446777,
      "learning_rate": 1.9174292722507735e-05,
      "loss": 0.0904,
      "step": 585
    },
    {
      "epoch": 0.3914495657982632,
      "grad_norm": 1.0592325925827026,
      "learning_rate": 1.9171507052874063e-05,
      "loss": 0.178,
      "step": 586
    },
    {
      "epoch": 0.3921175684702739,
      "grad_norm": 1.8254363536834717,
      "learning_rate": 1.9168716895225167e-05,
      "loss": 0.1985,
      "step": 587
    },
    {
      "epoch": 0.3927855711422846,
      "grad_norm": 1.3659522533416748,
      "learning_rate": 1.916592225092638e-05,
      "loss": 0.1183,
      "step": 588
    },
    {
      "epoch": 0.39345357381429524,
      "grad_norm": 0.9277905821800232,
      "learning_rate": 1.9163123121345255e-05,
      "loss": 0.0185,
      "step": 589
    },
    {
      "epoch": 0.39412157648630597,
      "grad_norm": 1.846496343612671,
      "learning_rate": 1.9160319507851518e-05,
      "loss": 0.1331,
      "step": 590
    },
    {
      "epoch": 0.39478957915831664,
      "grad_norm": 4.221363067626953,
      "learning_rate": 1.9157511411817103e-05,
      "loss": 0.1924,
      "step": 591
    },
    {
      "epoch": 0.3954575818303273,
      "grad_norm": 1.9182318449020386,
      "learning_rate": 1.915469883461613e-05,
      "loss": 0.0462,
      "step": 592
    },
    {
      "epoch": 0.39612558450233804,
      "grad_norm": 1.7449740171432495,
      "learning_rate": 1.915188177762492e-05,
      "loss": 0.0385,
      "step": 593
    },
    {
      "epoch": 0.3967935871743487,
      "grad_norm": 0.9495962262153625,
      "learning_rate": 1.914906024222198e-05,
      "loss": 0.0238,
      "step": 594
    },
    {
      "epoch": 0.3974615898463594,
      "grad_norm": 1.5324692726135254,
      "learning_rate": 1.9146234229788e-05,
      "loss": 0.1707,
      "step": 595
    },
    {
      "epoch": 0.3981295925183701,
      "grad_norm": 0.8757203817367554,
      "learning_rate": 1.9143403741705883e-05,
      "loss": 0.0309,
      "step": 596
    },
    {
      "epoch": 0.39879759519038077,
      "grad_norm": 3.3754117488861084,
      "learning_rate": 1.9140568779360697e-05,
      "loss": 0.1988,
      "step": 597
    },
    {
      "epoch": 0.39946559786239144,
      "grad_norm": 4.573604106903076,
      "learning_rate": 1.913772934413972e-05,
      "loss": 0.2364,
      "step": 598
    },
    {
      "epoch": 0.4001336005344021,
      "grad_norm": 1.7557228803634644,
      "learning_rate": 1.913488543743241e-05,
      "loss": 0.0962,
      "step": 599
    },
    {
      "epoch": 0.40080160320641284,
      "grad_norm": 7.361747741699219,
      "learning_rate": 1.913203706063041e-05,
      "loss": 0.3055,
      "step": 600
    },
    {
      "epoch": 0.4014696058784235,
      "grad_norm": 1.5210119485855103,
      "learning_rate": 1.9129184215127557e-05,
      "loss": 0.1292,
      "step": 601
    },
    {
      "epoch": 0.4021376085504342,
      "grad_norm": 1.7778701782226562,
      "learning_rate": 1.9126326902319873e-05,
      "loss": 0.1298,
      "step": 602
    },
    {
      "epoch": 0.4028056112224449,
      "grad_norm": 1.904051661491394,
      "learning_rate": 1.9123465123605558e-05,
      "loss": 0.0749,
      "step": 603
    },
    {
      "epoch": 0.4034736138944556,
      "grad_norm": 0.567793071269989,
      "learning_rate": 1.912059888038501e-05,
      "loss": 0.0141,
      "step": 604
    },
    {
      "epoch": 0.40414161656646624,
      "grad_norm": 5.561967372894287,
      "learning_rate": 1.9117728174060807e-05,
      "loss": 0.2113,
      "step": 605
    },
    {
      "epoch": 0.40480961923847697,
      "grad_norm": 0.37509530782699585,
      "learning_rate": 1.9114853006037702e-05,
      "loss": 0.0114,
      "step": 606
    },
    {
      "epoch": 0.40547762191048764,
      "grad_norm": 1.417484998703003,
      "learning_rate": 1.911197337772265e-05,
      "loss": 0.1486,
      "step": 607
    },
    {
      "epoch": 0.4061456245824983,
      "grad_norm": 2.87907075881958,
      "learning_rate": 1.910908929052477e-05,
      "loss": 0.1488,
      "step": 608
    },
    {
      "epoch": 0.40681362725450904,
      "grad_norm": 1.5749866962432861,
      "learning_rate": 1.9106200745855373e-05,
      "loss": 0.1411,
      "step": 609
    },
    {
      "epoch": 0.4074816299265197,
      "grad_norm": 1.0859700441360474,
      "learning_rate": 1.910330774512795e-05,
      "loss": 0.1233,
      "step": 610
    },
    {
      "epoch": 0.4081496325985304,
      "grad_norm": 2.9299612045288086,
      "learning_rate": 1.9100410289758165e-05,
      "loss": 0.1738,
      "step": 611
    },
    {
      "epoch": 0.4088176352705411,
      "grad_norm": 1.707845687866211,
      "learning_rate": 1.9097508381163877e-05,
      "loss": 0.1607,
      "step": 612
    },
    {
      "epoch": 0.4094856379425518,
      "grad_norm": 0.30238261818885803,
      "learning_rate": 1.9094602020765115e-05,
      "loss": 0.0075,
      "step": 613
    },
    {
      "epoch": 0.41015364061456244,
      "grad_norm": 0.7010360360145569,
      "learning_rate": 1.909169120998408e-05,
      "loss": 0.0157,
      "step": 614
    },
    {
      "epoch": 0.41082164328657317,
      "grad_norm": 1.1502530574798584,
      "learning_rate": 1.9088775950245163e-05,
      "loss": 0.0232,
      "step": 615
    },
    {
      "epoch": 0.41148964595858384,
      "grad_norm": 1.4640545845031738,
      "learning_rate": 1.9085856242974924e-05,
      "loss": 0.0382,
      "step": 616
    },
    {
      "epoch": 0.4121576486305945,
      "grad_norm": 1.8184953927993774,
      "learning_rate": 1.90829320896021e-05,
      "loss": 0.0797,
      "step": 617
    },
    {
      "epoch": 0.41282565130260523,
      "grad_norm": 1.9021778106689453,
      "learning_rate": 1.9080003491557616e-05,
      "loss": 0.0906,
      "step": 618
    },
    {
      "epoch": 0.4134936539746159,
      "grad_norm": 3.8321421146392822,
      "learning_rate": 1.907707045027455e-05,
      "loss": 0.2329,
      "step": 619
    },
    {
      "epoch": 0.4141616566466266,
      "grad_norm": 1.4533954858779907,
      "learning_rate": 1.9074132967188174e-05,
      "loss": 0.1479,
      "step": 620
    },
    {
      "epoch": 0.4148296593186373,
      "grad_norm": 4.522078990936279,
      "learning_rate": 1.907119104373592e-05,
      "loss": 0.2484,
      "step": 621
    },
    {
      "epoch": 0.41549766199064797,
      "grad_norm": 4.708596229553223,
      "learning_rate": 1.90682446813574e-05,
      "loss": 0.1287,
      "step": 622
    },
    {
      "epoch": 0.41616566466265864,
      "grad_norm": 2.5144944190979004,
      "learning_rate": 1.9065293881494397e-05,
      "loss": 0.1369,
      "step": 623
    },
    {
      "epoch": 0.4168336673346693,
      "grad_norm": 1.7580933570861816,
      "learning_rate": 1.9062338645590866e-05,
      "loss": 0.1566,
      "step": 624
    },
    {
      "epoch": 0.41750167000668004,
      "grad_norm": 3.956852436065674,
      "learning_rate": 1.9059378975092934e-05,
      "loss": 0.166,
      "step": 625
    },
    {
      "epoch": 0.4181696726786907,
      "grad_norm": 1.1394718885421753,
      "learning_rate": 1.905641487144889e-05,
      "loss": 0.0273,
      "step": 626
    },
    {
      "epoch": 0.4188376753507014,
      "grad_norm": 2.038341522216797,
      "learning_rate": 1.90534463361092e-05,
      "loss": 0.0538,
      "step": 627
    },
    {
      "epoch": 0.4195056780227121,
      "grad_norm": 1.2637981176376343,
      "learning_rate": 1.9050473370526502e-05,
      "loss": 0.1456,
      "step": 628
    },
    {
      "epoch": 0.4201736806947228,
      "grad_norm": 13.080526351928711,
      "learning_rate": 1.9047495976155588e-05,
      "loss": 0.4656,
      "step": 629
    },
    {
      "epoch": 0.42084168336673344,
      "grad_norm": 1.331830382347107,
      "learning_rate": 1.9044514154453434e-05,
      "loss": 0.1002,
      "step": 630
    },
    {
      "epoch": 0.42150968603874417,
      "grad_norm": 1.6796690225601196,
      "learning_rate": 1.904152790687917e-05,
      "loss": 0.032,
      "step": 631
    },
    {
      "epoch": 0.42217768871075484,
      "grad_norm": 7.2132391929626465,
      "learning_rate": 1.9038537234894097e-05,
      "loss": 0.3189,
      "step": 632
    },
    {
      "epoch": 0.4228456913827655,
      "grad_norm": 2.4535529613494873,
      "learning_rate": 1.9035542139961677e-05,
      "loss": 0.0364,
      "step": 633
    },
    {
      "epoch": 0.42351369405477624,
      "grad_norm": 0.8654754161834717,
      "learning_rate": 1.903254262354755e-05,
      "loss": 0.0199,
      "step": 634
    },
    {
      "epoch": 0.4241816967267869,
      "grad_norm": 2.504216432571411,
      "learning_rate": 1.9029538687119495e-05,
      "loss": 0.1477,
      "step": 635
    },
    {
      "epoch": 0.4248496993987976,
      "grad_norm": 2.1164281368255615,
      "learning_rate": 1.902653033214748e-05,
      "loss": 0.1257,
      "step": 636
    },
    {
      "epoch": 0.4255177020708083,
      "grad_norm": 0.20666910707950592,
      "learning_rate": 1.9023517560103614e-05,
      "loss": 0.0062,
      "step": 637
    },
    {
      "epoch": 0.42618570474281897,
      "grad_norm": 0.3956620395183563,
      "learning_rate": 1.902050037246218e-05,
      "loss": 0.0097,
      "step": 638
    },
    {
      "epoch": 0.42685370741482964,
      "grad_norm": 2.0692598819732666,
      "learning_rate": 1.9017478770699624e-05,
      "loss": 0.117,
      "step": 639
    },
    {
      "epoch": 0.42752171008684037,
      "grad_norm": 3.2946693897247314,
      "learning_rate": 1.901445275629454e-05,
      "loss": 0.1835,
      "step": 640
    },
    {
      "epoch": 0.42818971275885104,
      "grad_norm": 2.0461294651031494,
      "learning_rate": 1.9011422330727693e-05,
      "loss": 0.1853,
      "step": 641
    },
    {
      "epoch": 0.4288577154308617,
      "grad_norm": 5.2007880210876465,
      "learning_rate": 1.9008387495481996e-05,
      "loss": 0.3382,
      "step": 642
    },
    {
      "epoch": 0.42952571810287243,
      "grad_norm": 3.140930652618408,
      "learning_rate": 1.9005348252042525e-05,
      "loss": 0.1759,
      "step": 643
    },
    {
      "epoch": 0.4301937207748831,
      "grad_norm": 0.6440505385398865,
      "learning_rate": 1.9002304601896517e-05,
      "loss": 0.0123,
      "step": 644
    },
    {
      "epoch": 0.4308617234468938,
      "grad_norm": 1.9460504055023193,
      "learning_rate": 1.8999256546533358e-05,
      "loss": 0.1523,
      "step": 645
    },
    {
      "epoch": 0.4315297261189045,
      "grad_norm": 7.11604118347168,
      "learning_rate": 1.89962040874446e-05,
      "loss": 0.1506,
      "step": 646
    },
    {
      "epoch": 0.43219772879091517,
      "grad_norm": 2.459019184112549,
      "learning_rate": 1.8993147226123937e-05,
      "loss": 0.1677,
      "step": 647
    },
    {
      "epoch": 0.43286573146292584,
      "grad_norm": 2.3284358978271484,
      "learning_rate": 1.899008596406722e-05,
      "loss": 0.1387,
      "step": 648
    },
    {
      "epoch": 0.43353373413493657,
      "grad_norm": 1.1859122514724731,
      "learning_rate": 1.898702030277247e-05,
      "loss": 0.0192,
      "step": 649
    },
    {
      "epoch": 0.43420173680694724,
      "grad_norm": 1.0869227647781372,
      "learning_rate": 1.8983950243739836e-05,
      "loss": 0.0205,
      "step": 650
    },
    {
      "epoch": 0.4348697394789579,
      "grad_norm": 10.414073944091797,
      "learning_rate": 1.898087578847164e-05,
      "loss": 0.4087,
      "step": 651
    },
    {
      "epoch": 0.4355377421509686,
      "grad_norm": 3.359442710876465,
      "learning_rate": 1.8977796938472335e-05,
      "loss": 0.1038,
      "step": 652
    },
    {
      "epoch": 0.4362057448229793,
      "grad_norm": 2.7887868881225586,
      "learning_rate": 1.8974713695248545e-05,
      "loss": 0.1982,
      "step": 653
    },
    {
      "epoch": 0.43687374749499,
      "grad_norm": 1.5930118560791016,
      "learning_rate": 1.8971626060309028e-05,
      "loss": 0.1377,
      "step": 654
    },
    {
      "epoch": 0.43754175016700064,
      "grad_norm": 1.9243978261947632,
      "learning_rate": 1.89685340351647e-05,
      "loss": 0.1348,
      "step": 655
    },
    {
      "epoch": 0.43820975283901137,
      "grad_norm": 3.736804246902466,
      "learning_rate": 1.8965437621328626e-05,
      "loss": 0.1548,
      "step": 656
    },
    {
      "epoch": 0.43887775551102204,
      "grad_norm": 0.459838330745697,
      "learning_rate": 1.896233682031601e-05,
      "loss": 0.0081,
      "step": 657
    },
    {
      "epoch": 0.4395457581830327,
      "grad_norm": 0.2710069715976715,
      "learning_rate": 1.8959231633644207e-05,
      "loss": 0.0068,
      "step": 658
    },
    {
      "epoch": 0.44021376085504343,
      "grad_norm": 2.4533300399780273,
      "learning_rate": 1.8956122062832728e-05,
      "loss": 0.053,
      "step": 659
    },
    {
      "epoch": 0.4408817635270541,
      "grad_norm": 2.9008357524871826,
      "learning_rate": 1.895300810940321e-05,
      "loss": 0.22,
      "step": 660
    },
    {
      "epoch": 0.4415497661990648,
      "grad_norm": 2.4549765586853027,
      "learning_rate": 1.894988977487945e-05,
      "loss": 0.1211,
      "step": 661
    },
    {
      "epoch": 0.4422177688710755,
      "grad_norm": 3.6274585723876953,
      "learning_rate": 1.8946767060787387e-05,
      "loss": 0.1732,
      "step": 662
    },
    {
      "epoch": 0.44288577154308617,
      "grad_norm": 4.10560941696167,
      "learning_rate": 1.8943639968655097e-05,
      "loss": 0.0967,
      "step": 663
    },
    {
      "epoch": 0.44355377421509684,
      "grad_norm": 0.5266541242599487,
      "learning_rate": 1.8940508500012803e-05,
      "loss": 0.0115,
      "step": 664
    },
    {
      "epoch": 0.44422177688710757,
      "grad_norm": 1.8732229471206665,
      "learning_rate": 1.8937372656392864e-05,
      "loss": 0.1108,
      "step": 665
    },
    {
      "epoch": 0.44488977955911824,
      "grad_norm": 2.028294086456299,
      "learning_rate": 1.8934232439329786e-05,
      "loss": 0.0365,
      "step": 666
    },
    {
      "epoch": 0.4455577822311289,
      "grad_norm": 9.913568496704102,
      "learning_rate": 1.8931087850360215e-05,
      "loss": 0.3602,
      "step": 667
    },
    {
      "epoch": 0.44622578490313963,
      "grad_norm": 3.1283457279205322,
      "learning_rate": 1.8927938891022932e-05,
      "loss": 0.1536,
      "step": 668
    },
    {
      "epoch": 0.4468937875751503,
      "grad_norm": 4.156754493713379,
      "learning_rate": 1.892478556285886e-05,
      "loss": 0.2083,
      "step": 669
    },
    {
      "epoch": 0.447561790247161,
      "grad_norm": 1.2837902307510376,
      "learning_rate": 1.892162786741106e-05,
      "loss": 0.1607,
      "step": 670
    },
    {
      "epoch": 0.4482297929191717,
      "grad_norm": 1.9651871919631958,
      "learning_rate": 1.8918465806224732e-05,
      "loss": 0.0576,
      "step": 671
    },
    {
      "epoch": 0.44889779559118237,
      "grad_norm": 0.9728243947029114,
      "learning_rate": 1.89152993808472e-05,
      "loss": 0.019,
      "step": 672
    },
    {
      "epoch": 0.44956579826319304,
      "grad_norm": 3.1569724082946777,
      "learning_rate": 1.891212859282794e-05,
      "loss": 0.1185,
      "step": 673
    },
    {
      "epoch": 0.45023380093520377,
      "grad_norm": 1.730711817741394,
      "learning_rate": 1.8908953443718554e-05,
      "loss": 0.1748,
      "step": 674
    },
    {
      "epoch": 0.45090180360721444,
      "grad_norm": 3.2000789642333984,
      "learning_rate": 1.890577393507278e-05,
      "loss": 0.1941,
      "step": 675
    },
    {
      "epoch": 0.4515698062792251,
      "grad_norm": 1.91588294506073,
      "learning_rate": 1.890259006844649e-05,
      "loss": 0.096,
      "step": 676
    },
    {
      "epoch": 0.45223780895123583,
      "grad_norm": 2.2116072177886963,
      "learning_rate": 1.8899401845397686e-05,
      "loss": 0.1701,
      "step": 677
    },
    {
      "epoch": 0.4529058116232465,
      "grad_norm": 0.7524645924568176,
      "learning_rate": 1.8896209267486505e-05,
      "loss": 0.0125,
      "step": 678
    },
    {
      "epoch": 0.45357381429525717,
      "grad_norm": 1.2864489555358887,
      "learning_rate": 1.889301233627521e-05,
      "loss": 0.1585,
      "step": 679
    },
    {
      "epoch": 0.45424181696726784,
      "grad_norm": 1.087654948234558,
      "learning_rate": 1.8889811053328205e-05,
      "loss": 0.109,
      "step": 680
    },
    {
      "epoch": 0.45490981963927857,
      "grad_norm": 2.672537088394165,
      "learning_rate": 1.8886605420212012e-05,
      "loss": 0.1773,
      "step": 681
    },
    {
      "epoch": 0.45557782231128924,
      "grad_norm": 0.7797920107841492,
      "learning_rate": 1.8883395438495285e-05,
      "loss": 0.0149,
      "step": 682
    },
    {
      "epoch": 0.4562458249832999,
      "grad_norm": 3.5477726459503174,
      "learning_rate": 1.8880181109748803e-05,
      "loss": 0.1792,
      "step": 683
    },
    {
      "epoch": 0.45691382765531063,
      "grad_norm": 0.43520045280456543,
      "learning_rate": 1.887696243554549e-05,
      "loss": 0.0091,
      "step": 684
    },
    {
      "epoch": 0.4575818303273213,
      "grad_norm": 1.0147149562835693,
      "learning_rate": 1.8873739417460366e-05,
      "loss": 0.1173,
      "step": 685
    },
    {
      "epoch": 0.458249832999332,
      "grad_norm": 2.5252645015716553,
      "learning_rate": 1.88705120570706e-05,
      "loss": 0.0799,
      "step": 686
    },
    {
      "epoch": 0.4589178356713427,
      "grad_norm": 4.757303714752197,
      "learning_rate": 1.8867280355955483e-05,
      "loss": 0.3489,
      "step": 687
    },
    {
      "epoch": 0.45958583834335337,
      "grad_norm": 6.663198471069336,
      "learning_rate": 1.8864044315696425e-05,
      "loss": 0.1987,
      "step": 688
    },
    {
      "epoch": 0.46025384101536404,
      "grad_norm": 1.2504347562789917,
      "learning_rate": 1.8860803937876955e-05,
      "loss": 0.131,
      "step": 689
    },
    {
      "epoch": 0.46092184368737477,
      "grad_norm": 1.3643780946731567,
      "learning_rate": 1.8857559224082734e-05,
      "loss": 0.1316,
      "step": 690
    },
    {
      "epoch": 0.46158984635938544,
      "grad_norm": 0.7413414716720581,
      "learning_rate": 1.885431017590154e-05,
      "loss": 0.013,
      "step": 691
    },
    {
      "epoch": 0.4622578490313961,
      "grad_norm": 3.131160020828247,
      "learning_rate": 1.8851056794923276e-05,
      "loss": 0.0525,
      "step": 692
    },
    {
      "epoch": 0.46292585170340683,
      "grad_norm": 3.9972147941589355,
      "learning_rate": 1.8847799082739957e-05,
      "loss": 0.1369,
      "step": 693
    },
    {
      "epoch": 0.4635938543754175,
      "grad_norm": 2.3195559978485107,
      "learning_rate": 1.8844537040945725e-05,
      "loss": 0.1698,
      "step": 694
    },
    {
      "epoch": 0.4642618570474282,
      "grad_norm": 2.3670785427093506,
      "learning_rate": 1.884127067113684e-05,
      "loss": 0.1458,
      "step": 695
    },
    {
      "epoch": 0.4649298597194389,
      "grad_norm": 1.3018996715545654,
      "learning_rate": 1.8837999974911675e-05,
      "loss": 0.1756,
      "step": 696
    },
    {
      "epoch": 0.46559786239144957,
      "grad_norm": 4.667927265167236,
      "learning_rate": 1.883472495387072e-05,
      "loss": 0.1942,
      "step": 697
    },
    {
      "epoch": 0.46626586506346024,
      "grad_norm": 1.0304148197174072,
      "learning_rate": 1.8831445609616595e-05,
      "loss": 0.0159,
      "step": 698
    },
    {
      "epoch": 0.46693386773547096,
      "grad_norm": 9.246983528137207,
      "learning_rate": 1.8828161943754014e-05,
      "loss": 0.5434,
      "step": 699
    },
    {
      "epoch": 0.46760187040748163,
      "grad_norm": 1.739070177078247,
      "learning_rate": 1.8824873957889824e-05,
      "loss": 0.1216,
      "step": 700
    },
    {
      "epoch": 0.4682698730794923,
      "grad_norm": 1.8182361125946045,
      "learning_rate": 1.8821581653632978e-05,
      "loss": 0.1799,
      "step": 701
    },
    {
      "epoch": 0.46893787575150303,
      "grad_norm": 3.3237528800964355,
      "learning_rate": 1.8818285032594537e-05,
      "loss": 0.1629,
      "step": 702
    },
    {
      "epoch": 0.4696058784235137,
      "grad_norm": 1.8279502391815186,
      "learning_rate": 1.881498409638769e-05,
      "loss": 0.1233,
      "step": 703
    },
    {
      "epoch": 0.47027388109552437,
      "grad_norm": 3.405630350112915,
      "learning_rate": 1.881167884662772e-05,
      "loss": 0.179,
      "step": 704
    },
    {
      "epoch": 0.4709418837675351,
      "grad_norm": 0.45223763585090637,
      "learning_rate": 1.880836928493203e-05,
      "loss": 0.0068,
      "step": 705
    },
    {
      "epoch": 0.47160988643954577,
      "grad_norm": 3.4070584774017334,
      "learning_rate": 1.8805055412920133e-05,
      "loss": 0.1343,
      "step": 706
    },
    {
      "epoch": 0.47227788911155644,
      "grad_norm": 7.226129531860352,
      "learning_rate": 1.8801737232213653e-05,
      "loss": 0.1802,
      "step": 707
    },
    {
      "epoch": 0.4729458917835671,
      "grad_norm": 1.1260058879852295,
      "learning_rate": 1.8798414744436313e-05,
      "loss": 0.1019,
      "step": 708
    },
    {
      "epoch": 0.47361389445557783,
      "grad_norm": 1.509109377861023,
      "learning_rate": 1.8795087951213954e-05,
      "loss": 0.0178,
      "step": 709
    },
    {
      "epoch": 0.4742818971275885,
      "grad_norm": 1.3323110342025757,
      "learning_rate": 1.8791756854174517e-05,
      "loss": 0.079,
      "step": 710
    },
    {
      "epoch": 0.4749498997995992,
      "grad_norm": 4.388589382171631,
      "learning_rate": 1.878842145494806e-05,
      "loss": 0.1991,
      "step": 711
    },
    {
      "epoch": 0.4756179024716099,
      "grad_norm": 5.050856113433838,
      "learning_rate": 1.8785081755166727e-05,
      "loss": 0.1781,
      "step": 712
    },
    {
      "epoch": 0.47628590514362057,
      "grad_norm": 1.639949083328247,
      "learning_rate": 1.8781737756464788e-05,
      "loss": 0.0844,
      "step": 713
    },
    {
      "epoch": 0.47695390781563124,
      "grad_norm": 1.2193553447723389,
      "learning_rate": 1.8778389460478596e-05,
      "loss": 0.0532,
      "step": 714
    },
    {
      "epoch": 0.47762191048764197,
      "grad_norm": 4.000432014465332,
      "learning_rate": 1.8775036868846625e-05,
      "loss": 0.2283,
      "step": 715
    },
    {
      "epoch": 0.47828991315965264,
      "grad_norm": 7.227356433868408,
      "learning_rate": 1.8771679983209436e-05,
      "loss": 0.6303,
      "step": 716
    },
    {
      "epoch": 0.4789579158316633,
      "grad_norm": 1.1963212490081787,
      "learning_rate": 1.8768318805209707e-05,
      "loss": 0.1265,
      "step": 717
    },
    {
      "epoch": 0.47962591850367403,
      "grad_norm": 1.1800291538238525,
      "learning_rate": 1.8764953336492202e-05,
      "loss": 0.0698,
      "step": 718
    },
    {
      "epoch": 0.4802939211756847,
      "grad_norm": 1.5660333633422852,
      "learning_rate": 1.8761583578703792e-05,
      "loss": 0.1145,
      "step": 719
    },
    {
      "epoch": 0.48096192384769537,
      "grad_norm": 1.4217476844787598,
      "learning_rate": 1.8758209533493447e-05,
      "loss": 0.0819,
      "step": 720
    },
    {
      "epoch": 0.4816299265197061,
      "grad_norm": 1.5825079679489136,
      "learning_rate": 1.875483120251223e-05,
      "loss": 0.0223,
      "step": 721
    },
    {
      "epoch": 0.48229792919171677,
      "grad_norm": 2.502544403076172,
      "learning_rate": 1.8751448587413306e-05,
      "loss": 0.1508,
      "step": 722
    },
    {
      "epoch": 0.48296593186372744,
      "grad_norm": 2.0654759407043457,
      "learning_rate": 1.8748061689851934e-05,
      "loss": 0.1944,
      "step": 723
    },
    {
      "epoch": 0.48363393453573816,
      "grad_norm": 12.905686378479004,
      "learning_rate": 1.8744670511485475e-05,
      "loss": 0.5596,
      "step": 724
    },
    {
      "epoch": 0.48430193720774883,
      "grad_norm": 0.6289441585540771,
      "learning_rate": 1.874127505397337e-05,
      "loss": 0.0103,
      "step": 725
    },
    {
      "epoch": 0.4849699398797595,
      "grad_norm": 4.906064033508301,
      "learning_rate": 1.8737875318977172e-05,
      "loss": 0.2058,
      "step": 726
    },
    {
      "epoch": 0.48563794255177023,
      "grad_norm": 0.1187804564833641,
      "learning_rate": 1.8734471308160512e-05,
      "loss": 0.0034,
      "step": 727
    },
    {
      "epoch": 0.4863059452237809,
      "grad_norm": 1.647887110710144,
      "learning_rate": 1.8731063023189122e-05,
      "loss": 0.1015,
      "step": 728
    },
    {
      "epoch": 0.48697394789579157,
      "grad_norm": 5.524938583374023,
      "learning_rate": 1.8727650465730827e-05,
      "loss": 0.2332,
      "step": 729
    },
    {
      "epoch": 0.4876419505678023,
      "grad_norm": 0.8528870940208435,
      "learning_rate": 1.8724233637455532e-05,
      "loss": 0.016,
      "step": 730
    },
    {
      "epoch": 0.48830995323981297,
      "grad_norm": 2.3356029987335205,
      "learning_rate": 1.8720812540035246e-05,
      "loss": 0.1738,
      "step": 731
    },
    {
      "epoch": 0.48897795591182364,
      "grad_norm": 1.6074776649475098,
      "learning_rate": 1.8717387175144054e-05,
      "loss": 0.1402,
      "step": 732
    },
    {
      "epoch": 0.48964595858383436,
      "grad_norm": 1.5142662525177002,
      "learning_rate": 1.8713957544458138e-05,
      "loss": 0.0815,
      "step": 733
    },
    {
      "epoch": 0.49031396125584503,
      "grad_norm": 1.8049527406692505,
      "learning_rate": 1.8710523649655764e-05,
      "loss": 0.18,
      "step": 734
    },
    {
      "epoch": 0.4909819639278557,
      "grad_norm": 1.4072595834732056,
      "learning_rate": 1.8707085492417286e-05,
      "loss": 0.0995,
      "step": 735
    },
    {
      "epoch": 0.4916499665998664,
      "grad_norm": 2.557508945465088,
      "learning_rate": 1.8703643074425145e-05,
      "loss": 0.1544,
      "step": 736
    },
    {
      "epoch": 0.4923179692718771,
      "grad_norm": 2.082826614379883,
      "learning_rate": 1.870019639736386e-05,
      "loss": 0.149,
      "step": 737
    },
    {
      "epoch": 0.49298597194388777,
      "grad_norm": 10.757200241088867,
      "learning_rate": 1.8696745462920046e-05,
      "loss": 0.4644,
      "step": 738
    },
    {
      "epoch": 0.49365397461589844,
      "grad_norm": 1.5801231861114502,
      "learning_rate": 1.869329027278239e-05,
      "loss": 0.1231,
      "step": 739
    },
    {
      "epoch": 0.49432197728790916,
      "grad_norm": 2.640793800354004,
      "learning_rate": 1.868983082864166e-05,
      "loss": 0.1337,
      "step": 740
    },
    {
      "epoch": 0.49498997995991983,
      "grad_norm": 7.174450397491455,
      "learning_rate": 1.8686367132190727e-05,
      "loss": 0.2508,
      "step": 741
    },
    {
      "epoch": 0.4956579826319305,
      "grad_norm": 1.6995627880096436,
      "learning_rate": 1.8682899185124513e-05,
      "loss": 0.0566,
      "step": 742
    },
    {
      "epoch": 0.49632598530394123,
      "grad_norm": 6.052439212799072,
      "learning_rate": 1.8679426989140045e-05,
      "loss": 0.1152,
      "step": 743
    },
    {
      "epoch": 0.4969939879759519,
      "grad_norm": 2.390674352645874,
      "learning_rate": 1.8675950545936413e-05,
      "loss": 0.1818,
      "step": 744
    },
    {
      "epoch": 0.49766199064796257,
      "grad_norm": 2.599698781967163,
      "learning_rate": 1.867246985721479e-05,
      "loss": 0.2346,
      "step": 745
    },
    {
      "epoch": 0.4983299933199733,
      "grad_norm": 8.291141510009766,
      "learning_rate": 1.866898492467843e-05,
      "loss": 0.1592,
      "step": 746
    },
    {
      "epoch": 0.49899799599198397,
      "grad_norm": 2.2674379348754883,
      "learning_rate": 1.8665495750032664e-05,
      "loss": 0.148,
      "step": 747
    },
    {
      "epoch": 0.49966599866399464,
      "grad_norm": 3.0882046222686768,
      "learning_rate": 1.8662002334984896e-05,
      "loss": 0.1672,
      "step": 748
    },
    {
      "epoch": 0.5003340013360054,
      "grad_norm": 1.3562750816345215,
      "learning_rate": 1.8658504681244597e-05,
      "loss": 0.1054,
      "step": 749
    },
    {
      "epoch": 0.501002004008016,
      "grad_norm": 2.660212993621826,
      "learning_rate": 1.865500279052333e-05,
      "loss": 0.0428,
      "step": 750
    },
    {
      "epoch": 0.5016700066800267,
      "grad_norm": 15.400014877319336,
      "learning_rate": 1.8651496664534713e-05,
      "loss": 0.4481,
      "step": 751
    },
    {
      "epoch": 0.5023380093520374,
      "grad_norm": 4.910281658172607,
      "learning_rate": 1.8647986304994453e-05,
      "loss": 0.1187,
      "step": 752
    },
    {
      "epoch": 0.503006012024048,
      "grad_norm": 5.2524733543396,
      "learning_rate": 1.8644471713620316e-05,
      "loss": 0.1262,
      "step": 753
    },
    {
      "epoch": 0.5036740146960588,
      "grad_norm": 3.0211517810821533,
      "learning_rate": 1.864095289213214e-05,
      "loss": 0.1448,
      "step": 754
    },
    {
      "epoch": 0.5043420173680695,
      "grad_norm": 2.585996389389038,
      "learning_rate": 1.863742984225185e-05,
      "loss": 0.2261,
      "step": 755
    },
    {
      "epoch": 0.5050100200400801,
      "grad_norm": 6.02390718460083,
      "learning_rate": 1.8633902565703415e-05,
      "loss": 0.293,
      "step": 756
    },
    {
      "epoch": 0.5056780227120908,
      "grad_norm": 3.385441303253174,
      "learning_rate": 1.8630371064212888e-05,
      "loss": 0.0485,
      "step": 757
    },
    {
      "epoch": 0.5063460253841016,
      "grad_norm": 4.709108352661133,
      "learning_rate": 1.8626835339508385e-05,
      "loss": 0.2203,
      "step": 758
    },
    {
      "epoch": 0.5070140280561122,
      "grad_norm": 1.5729559659957886,
      "learning_rate": 1.8623295393320086e-05,
      "loss": 0.0285,
      "step": 759
    },
    {
      "epoch": 0.5076820307281229,
      "grad_norm": 1.4978748559951782,
      "learning_rate": 1.8619751227380245e-05,
      "loss": 0.1373,
      "step": 760
    },
    {
      "epoch": 0.5083500334001336,
      "grad_norm": 1.5115830898284912,
      "learning_rate": 1.8616202843423176e-05,
      "loss": 0.1153,
      "step": 761
    },
    {
      "epoch": 0.5090180360721442,
      "grad_norm": 1.1959556341171265,
      "learning_rate": 1.8612650243185252e-05,
      "loss": 0.0156,
      "step": 762
    },
    {
      "epoch": 0.509686038744155,
      "grad_norm": 0.5590564012527466,
      "learning_rate": 1.8609093428404916e-05,
      "loss": 0.0091,
      "step": 763
    },
    {
      "epoch": 0.5103540414161657,
      "grad_norm": 2.5291008949279785,
      "learning_rate": 1.860553240082267e-05,
      "loss": 0.1527,
      "step": 764
    },
    {
      "epoch": 0.5110220440881763,
      "grad_norm": 0.46275532245635986,
      "learning_rate": 1.8601967162181082e-05,
      "loss": 0.0061,
      "step": 765
    },
    {
      "epoch": 0.511690046760187,
      "grad_norm": 1.0127813816070557,
      "learning_rate": 1.8598397714224778e-05,
      "loss": 0.0174,
      "step": 766
    },
    {
      "epoch": 0.5123580494321978,
      "grad_norm": 1.5996843576431274,
      "learning_rate": 1.859482405870044e-05,
      "loss": 0.03,
      "step": 767
    },
    {
      "epoch": 0.5130260521042084,
      "grad_norm": 2.022871494293213,
      "learning_rate": 1.859124619735681e-05,
      "loss": 0.026,
      "step": 768
    },
    {
      "epoch": 0.5136940547762191,
      "grad_norm": 1.2517858743667603,
      "learning_rate": 1.85876641319447e-05,
      "loss": 0.1231,
      "step": 769
    },
    {
      "epoch": 0.5143620574482298,
      "grad_norm": 3.300530195236206,
      "learning_rate": 1.858407786421696e-05,
      "loss": 0.1238,
      "step": 770
    },
    {
      "epoch": 0.5150300601202404,
      "grad_norm": 2.605337619781494,
      "learning_rate": 1.8580487395928513e-05,
      "loss": 0.1267,
      "step": 771
    },
    {
      "epoch": 0.5156980627922512,
      "grad_norm": 1.5494170188903809,
      "learning_rate": 1.8576892728836323e-05,
      "loss": 0.1435,
      "step": 772
    },
    {
      "epoch": 0.5163660654642619,
      "grad_norm": 0.14532195031642914,
      "learning_rate": 1.8573293864699423e-05,
      "loss": 0.004,
      "step": 773
    },
    {
      "epoch": 0.5170340681362725,
      "grad_norm": 3.576840877532959,
      "learning_rate": 1.8569690805278894e-05,
      "loss": 0.1687,
      "step": 774
    },
    {
      "epoch": 0.5177020708082832,
      "grad_norm": 6.514863967895508,
      "learning_rate": 1.8566083552337857e-05,
      "loss": 0.2078,
      "step": 775
    },
    {
      "epoch": 0.518370073480294,
      "grad_norm": 2.0925042629241943,
      "learning_rate": 1.856247210764151e-05,
      "loss": 0.1312,
      "step": 776
    },
    {
      "epoch": 0.5190380761523046,
      "grad_norm": 1.666502594947815,
      "learning_rate": 1.8558856472957085e-05,
      "loss": 0.1568,
      "step": 777
    },
    {
      "epoch": 0.5197060788243153,
      "grad_norm": 1.2007688283920288,
      "learning_rate": 1.8555236650053863e-05,
      "loss": 0.077,
      "step": 778
    },
    {
      "epoch": 0.520374081496326,
      "grad_norm": 9.819148063659668,
      "learning_rate": 1.8551612640703185e-05,
      "loss": 0.1851,
      "step": 779
    },
    {
      "epoch": 0.5210420841683366,
      "grad_norm": 4.905076026916504,
      "learning_rate": 1.8547984446678436e-05,
      "loss": 0.1562,
      "step": 780
    },
    {
      "epoch": 0.5217100868403474,
      "grad_norm": 1.3033583164215088,
      "learning_rate": 1.854435206975505e-05,
      "loss": 0.0235,
      "step": 781
    },
    {
      "epoch": 0.5223780895123581,
      "grad_norm": 2.056910514831543,
      "learning_rate": 1.8540715511710504e-05,
      "loss": 0.0612,
      "step": 782
    },
    {
      "epoch": 0.5230460921843687,
      "grad_norm": 10.671110153198242,
      "learning_rate": 1.8537074774324318e-05,
      "loss": 0.5534,
      "step": 783
    },
    {
      "epoch": 0.5237140948563794,
      "grad_norm": 2.043834924697876,
      "learning_rate": 1.853342985937807e-05,
      "loss": 0.1481,
      "step": 784
    },
    {
      "epoch": 0.5243820975283902,
      "grad_norm": 17.776294708251953,
      "learning_rate": 1.8529780768655375e-05,
      "loss": 0.5248,
      "step": 785
    },
    {
      "epoch": 0.5250501002004008,
      "grad_norm": 2.721886157989502,
      "learning_rate": 1.8526127503941885e-05,
      "loss": 0.0337,
      "step": 786
    },
    {
      "epoch": 0.5257181028724115,
      "grad_norm": 5.463289260864258,
      "learning_rate": 1.8522470067025303e-05,
      "loss": 0.3741,
      "step": 787
    },
    {
      "epoch": 0.5263861055444222,
      "grad_norm": 5.008302211761475,
      "learning_rate": 1.8518808459695373e-05,
      "loss": 0.1697,
      "step": 788
    },
    {
      "epoch": 0.5270541082164328,
      "grad_norm": 5.434157371520996,
      "learning_rate": 1.8515142683743874e-05,
      "loss": 0.1297,
      "step": 789
    },
    {
      "epoch": 0.5277221108884436,
      "grad_norm": 6.158932685852051,
      "learning_rate": 1.851147274096463e-05,
      "loss": 0.163,
      "step": 790
    },
    {
      "epoch": 0.5283901135604543,
      "grad_norm": 0.970971405506134,
      "learning_rate": 1.8507798633153507e-05,
      "loss": 0.011,
      "step": 791
    },
    {
      "epoch": 0.5290581162324649,
      "grad_norm": 3.427006244659424,
      "learning_rate": 1.85041203621084e-05,
      "loss": 0.1663,
      "step": 792
    },
    {
      "epoch": 0.5297261189044756,
      "grad_norm": 0.6181977987289429,
      "learning_rate": 1.850043792962925e-05,
      "loss": 0.0097,
      "step": 793
    },
    {
      "epoch": 0.5303941215764864,
      "grad_norm": 0.2715003192424774,
      "learning_rate": 1.8496751337518026e-05,
      "loss": 0.0057,
      "step": 794
    },
    {
      "epoch": 0.531062124248497,
      "grad_norm": 1.900480031967163,
      "learning_rate": 1.849306058757874e-05,
      "loss": 0.1005,
      "step": 795
    },
    {
      "epoch": 0.5317301269205077,
      "grad_norm": 0.6965076923370361,
      "learning_rate": 1.848936568161744e-05,
      "loss": 0.0106,
      "step": 796
    },
    {
      "epoch": 0.5323981295925184,
      "grad_norm": 0.06202402338385582,
      "learning_rate": 1.848566662144219e-05,
      "loss": 0.0025,
      "step": 797
    },
    {
      "epoch": 0.533066132264529,
      "grad_norm": 14.318110466003418,
      "learning_rate": 1.8481963408863114e-05,
      "loss": 0.9771,
      "step": 798
    },
    {
      "epoch": 0.5337341349365398,
      "grad_norm": 0.11136875301599503,
      "learning_rate": 1.8478256045692347e-05,
      "loss": 0.0023,
      "step": 799
    },
    {
      "epoch": 0.5344021376085505,
      "grad_norm": 1.6219812631607056,
      "learning_rate": 1.8474544533744064e-05,
      "loss": 0.0263,
      "step": 800
    },
    {
      "epoch": 0.5350701402805611,
      "grad_norm": 0.6247658133506775,
      "learning_rate": 1.847082887483447e-05,
      "loss": 0.0085,
      "step": 801
    },
    {
      "epoch": 0.5357381429525718,
      "grad_norm": 2.922832727432251,
      "learning_rate": 1.8467109070781796e-05,
      "loss": 0.1605,
      "step": 802
    },
    {
      "epoch": 0.5364061456245826,
      "grad_norm": 1.915083885192871,
      "learning_rate": 1.8463385123406303e-05,
      "loss": 0.0919,
      "step": 803
    },
    {
      "epoch": 0.5370741482965932,
      "grad_norm": 10.499109268188477,
      "learning_rate": 1.8459657034530282e-05,
      "loss": 0.3486,
      "step": 804
    },
    {
      "epoch": 0.5377421509686039,
      "grad_norm": 2.096388339996338,
      "learning_rate": 1.845592480597804e-05,
      "loss": 0.0884,
      "step": 805
    },
    {
      "epoch": 0.5384101536406145,
      "grad_norm": 1.7802391052246094,
      "learning_rate": 1.845218843957593e-05,
      "loss": 0.0652,
      "step": 806
    },
    {
      "epoch": 0.5390781563126252,
      "grad_norm": 11.300191879272461,
      "learning_rate": 1.8448447937152306e-05,
      "loss": 0.4809,
      "step": 807
    },
    {
      "epoch": 0.539746158984636,
      "grad_norm": 1.713883876800537,
      "learning_rate": 1.8444703300537567e-05,
      "loss": 0.0996,
      "step": 808
    },
    {
      "epoch": 0.5404141616566466,
      "grad_norm": 13.105504989624023,
      "learning_rate": 1.8440954531564118e-05,
      "loss": 0.3929,
      "step": 809
    },
    {
      "epoch": 0.5410821643286573,
      "grad_norm": 2.3840885162353516,
      "learning_rate": 1.84372016320664e-05,
      "loss": 0.1584,
      "step": 810
    },
    {
      "epoch": 0.541750167000668,
      "grad_norm": 2.7260963916778564,
      "learning_rate": 1.843344460388087e-05,
      "loss": 0.041,
      "step": 811
    },
    {
      "epoch": 0.5424181696726786,
      "grad_norm": 1.5529149770736694,
      "learning_rate": 1.8429683448846002e-05,
      "loss": 0.0528,
      "step": 812
    },
    {
      "epoch": 0.5430861723446894,
      "grad_norm": 6.951623439788818,
      "learning_rate": 1.8425918168802287e-05,
      "loss": 0.3667,
      "step": 813
    },
    {
      "epoch": 0.5437541750167001,
      "grad_norm": 2.9465174674987793,
      "learning_rate": 1.8422148765592246e-05,
      "loss": 0.215,
      "step": 814
    },
    {
      "epoch": 0.5444221776887107,
      "grad_norm": 13.198182106018066,
      "learning_rate": 1.8418375241060408e-05,
      "loss": 0.5814,
      "step": 815
    },
    {
      "epoch": 0.5450901803607214,
      "grad_norm": 2.7374343872070312,
      "learning_rate": 1.8414597597053324e-05,
      "loss": 0.1182,
      "step": 816
    },
    {
      "epoch": 0.5457581830327322,
      "grad_norm": 3.420013427734375,
      "learning_rate": 1.8410815835419554e-05,
      "loss": 0.1934,
      "step": 817
    },
    {
      "epoch": 0.5464261857047428,
      "grad_norm": 9.73257064819336,
      "learning_rate": 1.8407029958009684e-05,
      "loss": 0.3379,
      "step": 818
    },
    {
      "epoch": 0.5470941883767535,
      "grad_norm": 5.521618843078613,
      "learning_rate": 1.8403239966676304e-05,
      "loss": 0.2601,
      "step": 819
    },
    {
      "epoch": 0.5477621910487642,
      "grad_norm": 2.076805591583252,
      "learning_rate": 1.839944586327402e-05,
      "loss": 0.1402,
      "step": 820
    },
    {
      "epoch": 0.5484301937207748,
      "grad_norm": 0.19675104320049286,
      "learning_rate": 1.8395647649659453e-05,
      "loss": 0.0046,
      "step": 821
    },
    {
      "epoch": 0.5490981963927856,
      "grad_norm": 12.574187278747559,
      "learning_rate": 1.8391845327691235e-05,
      "loss": 0.9946,
      "step": 822
    },
    {
      "epoch": 0.5497661990647963,
      "grad_norm": 2.8505403995513916,
      "learning_rate": 1.8388038899230002e-05,
      "loss": 0.1529,
      "step": 823
    },
    {
      "epoch": 0.5504342017368069,
      "grad_norm": 0.7767704725265503,
      "learning_rate": 1.8384228366138407e-05,
      "loss": 0.0121,
      "step": 824
    },
    {
      "epoch": 0.5511022044088176,
      "grad_norm": 4.190296173095703,
      "learning_rate": 1.8380413730281107e-05,
      "loss": 0.2928,
      "step": 825
    },
    {
      "epoch": 0.5517702070808284,
      "grad_norm": 0.15906108915805817,
      "learning_rate": 1.8376594993524768e-05,
      "loss": 0.0029,
      "step": 826
    },
    {
      "epoch": 0.552438209752839,
      "grad_norm": 0.44228774309158325,
      "learning_rate": 1.8372772157738068e-05,
      "loss": 0.0057,
      "step": 827
    },
    {
      "epoch": 0.5531062124248497,
      "grad_norm": 1.9460705518722534,
      "learning_rate": 1.836894522479168e-05,
      "loss": 0.1752,
      "step": 828
    },
    {
      "epoch": 0.5537742150968604,
      "grad_norm": 1.7762279510498047,
      "learning_rate": 1.836511419655829e-05,
      "loss": 0.0246,
      "step": 829
    },
    {
      "epoch": 0.554442217768871,
      "grad_norm": 0.12007497251033783,
      "learning_rate": 1.836127907491259e-05,
      "loss": 0.0027,
      "step": 830
    },
    {
      "epoch": 0.5551102204408818,
      "grad_norm": 1.6032360792160034,
      "learning_rate": 1.8357439861731264e-05,
      "loss": 0.1054,
      "step": 831
    },
    {
      "epoch": 0.5557782231128925,
      "grad_norm": 1.16237473487854,
      "learning_rate": 1.835359655889301e-05,
      "loss": 0.1543,
      "step": 832
    },
    {
      "epoch": 0.5564462257849031,
      "grad_norm": 0.6098255515098572,
      "learning_rate": 1.8349749168278513e-05,
      "loss": 0.0102,
      "step": 833
    },
    {
      "epoch": 0.5571142284569138,
      "grad_norm": 2.567265510559082,
      "learning_rate": 1.834589769177048e-05,
      "loss": 0.1826,
      "step": 834
    },
    {
      "epoch": 0.5577822311289246,
      "grad_norm": 4.74062967300415,
      "learning_rate": 1.8342042131253606e-05,
      "loss": 0.096,
      "step": 835
    },
    {
      "epoch": 0.5584502338009352,
      "grad_norm": 5.866298675537109,
      "learning_rate": 1.833818248861457e-05,
      "loss": 0.213,
      "step": 836
    },
    {
      "epoch": 0.5591182364729459,
      "grad_norm": 3.4650440216064453,
      "learning_rate": 1.8334318765742078e-05,
      "loss": 0.1851,
      "step": 837
    },
    {
      "epoch": 0.5597862391449566,
      "grad_norm": 0.5831348299980164,
      "learning_rate": 1.8330450964526805e-05,
      "loss": 0.0077,
      "step": 838
    },
    {
      "epoch": 0.5604542418169672,
      "grad_norm": 1.015830636024475,
      "learning_rate": 1.8326579086861437e-05,
      "loss": 0.1095,
      "step": 839
    },
    {
      "epoch": 0.561122244488978,
      "grad_norm": 1.5398292541503906,
      "learning_rate": 1.8322703134640652e-05,
      "loss": 0.1389,
      "step": 840
    },
    {
      "epoch": 0.5617902471609887,
      "grad_norm": 2.187391996383667,
      "learning_rate": 1.8318823109761122e-05,
      "loss": 0.1661,
      "step": 841
    },
    {
      "epoch": 0.5624582498329993,
      "grad_norm": 0.5677928328514099,
      "learning_rate": 1.831493901412151e-05,
      "loss": 0.0093,
      "step": 842
    },
    {
      "epoch": 0.56312625250501,
      "grad_norm": 0.8426854610443115,
      "learning_rate": 1.831105084962247e-05,
      "loss": 0.0149,
      "step": 843
    },
    {
      "epoch": 0.5637942551770208,
      "grad_norm": 1.4229402542114258,
      "learning_rate": 1.8307158618166652e-05,
      "loss": 0.0981,
      "step": 844
    },
    {
      "epoch": 0.5644622578490314,
      "grad_norm": 0.3015117347240448,
      "learning_rate": 1.8303262321658692e-05,
      "loss": 0.0049,
      "step": 845
    },
    {
      "epoch": 0.5651302605210421,
      "grad_norm": 1.7029930353164673,
      "learning_rate": 1.8299361962005218e-05,
      "loss": 0.1662,
      "step": 846
    },
    {
      "epoch": 0.5657982631930528,
      "grad_norm": 1.0673903226852417,
      "learning_rate": 1.8295457541114842e-05,
      "loss": 0.0208,
      "step": 847
    },
    {
      "epoch": 0.5664662658650634,
      "grad_norm": 1.6480205059051514,
      "learning_rate": 1.829154906089817e-05,
      "loss": 0.1351,
      "step": 848
    },
    {
      "epoch": 0.5671342685370742,
      "grad_norm": 3.184264898300171,
      "learning_rate": 1.8287636523267786e-05,
      "loss": 0.0634,
      "step": 849
    },
    {
      "epoch": 0.5678022712090849,
      "grad_norm": 5.223080635070801,
      "learning_rate": 1.8283719930138265e-05,
      "loss": 0.2363,
      "step": 850
    },
    {
      "epoch": 0.5684702738810955,
      "grad_norm": 3.1357405185699463,
      "learning_rate": 1.8279799283426167e-05,
      "loss": 0.1783,
      "step": 851
    },
    {
      "epoch": 0.5691382765531062,
      "grad_norm": 1.2925193309783936,
      "learning_rate": 1.8275874585050035e-05,
      "loss": 0.0739,
      "step": 852
    },
    {
      "epoch": 0.569806279225117,
      "grad_norm": 3.3145055770874023,
      "learning_rate": 1.8271945836930392e-05,
      "loss": 0.2052,
      "step": 853
    },
    {
      "epoch": 0.5704742818971276,
      "grad_norm": 2.083012104034424,
      "learning_rate": 1.826801304098974e-05,
      "loss": 0.1433,
      "step": 854
    },
    {
      "epoch": 0.5711422845691383,
      "grad_norm": 2.135866403579712,
      "learning_rate": 1.8264076199152582e-05,
      "loss": 0.1644,
      "step": 855
    },
    {
      "epoch": 0.571810287241149,
      "grad_norm": 3.2895822525024414,
      "learning_rate": 1.8260135313345365e-05,
      "loss": 0.2283,
      "step": 856
    },
    {
      "epoch": 0.5724782899131596,
      "grad_norm": 15.473615646362305,
      "learning_rate": 1.8256190385496545e-05,
      "loss": 0.2006,
      "step": 857
    },
    {
      "epoch": 0.5731462925851704,
      "grad_norm": 2.608598470687866,
      "learning_rate": 1.8252241417536546e-05,
      "loss": 0.0867,
      "step": 858
    },
    {
      "epoch": 0.5738142952571811,
      "grad_norm": 0.6393530964851379,
      "learning_rate": 1.8248288411397767e-05,
      "loss": 0.0099,
      "step": 859
    },
    {
      "epoch": 0.5744822979291917,
      "grad_norm": 1.8679225444793701,
      "learning_rate": 1.8244331369014588e-05,
      "loss": 0.158,
      "step": 860
    },
    {
      "epoch": 0.5751503006012024,
      "grad_norm": 1.9071784019470215,
      "learning_rate": 1.8240370292323356e-05,
      "loss": 0.1496,
      "step": 861
    },
    {
      "epoch": 0.575818303273213,
      "grad_norm": 1.552505373954773,
      "learning_rate": 1.8236405183262403e-05,
      "loss": 0.1566,
      "step": 862
    },
    {
      "epoch": 0.5764863059452238,
      "grad_norm": 8.843587875366211,
      "learning_rate": 1.8232436043772024e-05,
      "loss": 0.3874,
      "step": 863
    },
    {
      "epoch": 0.5771543086172345,
      "grad_norm": 2.7040886878967285,
      "learning_rate": 1.822846287579449e-05,
      "loss": 0.1611,
      "step": 864
    },
    {
      "epoch": 0.5778223112892451,
      "grad_norm": 2.1173665523529053,
      "learning_rate": 1.8224485681274048e-05,
      "loss": 0.1955,
      "step": 865
    },
    {
      "epoch": 0.5784903139612558,
      "grad_norm": 2.3139488697052,
      "learning_rate": 1.8220504462156908e-05,
      "loss": 0.1838,
      "step": 866
    },
    {
      "epoch": 0.5791583166332666,
      "grad_norm": 8.497305870056152,
      "learning_rate": 1.8216519220391254e-05,
      "loss": 0.4445,
      "step": 867
    },
    {
      "epoch": 0.5798263193052772,
      "grad_norm": 1.3309929370880127,
      "learning_rate": 1.8212529957927237e-05,
      "loss": 0.1021,
      "step": 868
    },
    {
      "epoch": 0.5804943219772879,
      "grad_norm": 4.951287746429443,
      "learning_rate": 1.820853667671698e-05,
      "loss": 0.1412,
      "step": 869
    },
    {
      "epoch": 0.5811623246492986,
      "grad_norm": 0.13760453462600708,
      "learning_rate": 1.820453937871456e-05,
      "loss": 0.0031,
      "step": 870
    },
    {
      "epoch": 0.5818303273213092,
      "grad_norm": 1.7074350118637085,
      "learning_rate": 1.8200538065876033e-05,
      "loss": 0.0511,
      "step": 871
    },
    {
      "epoch": 0.58249832999332,
      "grad_norm": 0.509119987487793,
      "learning_rate": 1.8196532740159417e-05,
      "loss": 0.0068,
      "step": 872
    },
    {
      "epoch": 0.5831663326653307,
      "grad_norm": 2.6057286262512207,
      "learning_rate": 1.8192523403524685e-05,
      "loss": 0.0373,
      "step": 873
    },
    {
      "epoch": 0.5838343353373413,
      "grad_norm": 3.524637460708618,
      "learning_rate": 1.8188510057933785e-05,
      "loss": 0.2462,
      "step": 874
    },
    {
      "epoch": 0.584502338009352,
      "grad_norm": 8.846452713012695,
      "learning_rate": 1.8184492705350613e-05,
      "loss": 0.2995,
      "step": 875
    },
    {
      "epoch": 0.5851703406813628,
      "grad_norm": 5.823594093322754,
      "learning_rate": 1.818047134774104e-05,
      "loss": 0.1212,
      "step": 876
    },
    {
      "epoch": 0.5858383433533734,
      "grad_norm": 0.13239502906799316,
      "learning_rate": 1.8176445987072888e-05,
      "loss": 0.0023,
      "step": 877
    },
    {
      "epoch": 0.5865063460253841,
      "grad_norm": 3.693796396255493,
      "learning_rate": 1.8172416625315937e-05,
      "loss": 0.2158,
      "step": 878
    },
    {
      "epoch": 0.5871743486973948,
      "grad_norm": 16.932817459106445,
      "learning_rate": 1.816838326444194e-05,
      "loss": 0.5992,
      "step": 879
    },
    {
      "epoch": 0.5878423513694054,
      "grad_norm": 1.0320310592651367,
      "learning_rate": 1.8164345906424578e-05,
      "loss": 0.1118,
      "step": 880
    },
    {
      "epoch": 0.5885103540414162,
      "grad_norm": 2.431210517883301,
      "learning_rate": 1.8160304553239516e-05,
      "loss": 0.1163,
      "step": 881
    },
    {
      "epoch": 0.5891783567134269,
      "grad_norm": 3.6111762523651123,
      "learning_rate": 1.815625920686436e-05,
      "loss": 0.0509,
      "step": 882
    },
    {
      "epoch": 0.5898463593854375,
      "grad_norm": 0.364579975605011,
      "learning_rate": 1.8152209869278675e-05,
      "loss": 0.0055,
      "step": 883
    },
    {
      "epoch": 0.5905143620574482,
      "grad_norm": 0.7105606198310852,
      "learning_rate": 1.8148156542463975e-05,
      "loss": 0.0093,
      "step": 884
    },
    {
      "epoch": 0.591182364729459,
      "grad_norm": 4.5402936935424805,
      "learning_rate": 1.8144099228403727e-05,
      "loss": 0.1534,
      "step": 885
    },
    {
      "epoch": 0.5918503674014696,
      "grad_norm": 0.4345303773880005,
      "learning_rate": 1.8140037929083352e-05,
      "loss": 0.0076,
      "step": 886
    },
    {
      "epoch": 0.5925183700734803,
      "grad_norm": 0.6826241612434387,
      "learning_rate": 1.813597264649022e-05,
      "loss": 0.0102,
      "step": 887
    },
    {
      "epoch": 0.593186372745491,
      "grad_norm": 6.200272560119629,
      "learning_rate": 1.813190338261365e-05,
      "loss": 0.2093,
      "step": 888
    },
    {
      "epoch": 0.5938543754175016,
      "grad_norm": 2.007964611053467,
      "learning_rate": 1.8127830139444908e-05,
      "loss": 0.1249,
      "step": 889
    },
    {
      "epoch": 0.5945223780895124,
      "grad_norm": 11.76093864440918,
      "learning_rate": 1.8123752918977208e-05,
      "loss": 0.7191,
      "step": 890
    },
    {
      "epoch": 0.5951903807615231,
      "grad_norm": 3.1639180183410645,
      "learning_rate": 1.8119671723205708e-05,
      "loss": 0.1365,
      "step": 891
    },
    {
      "epoch": 0.5958583834335337,
      "grad_norm": 0.08451554924249649,
      "learning_rate": 1.811558655412752e-05,
      "loss": 0.002,
      "step": 892
    },
    {
      "epoch": 0.5965263861055444,
      "grad_norm": 3.302001476287842,
      "learning_rate": 1.8111497413741682e-05,
      "loss": 0.1694,
      "step": 893
    },
    {
      "epoch": 0.5971943887775552,
      "grad_norm": 2.801486015319824,
      "learning_rate": 1.81074043040492e-05,
      "loss": 0.1446,
      "step": 894
    },
    {
      "epoch": 0.5978623914495658,
      "grad_norm": 4.758264064788818,
      "learning_rate": 1.810330722705301e-05,
      "loss": 0.1666,
      "step": 895
    },
    {
      "epoch": 0.5985303941215765,
      "grad_norm": 0.3861987292766571,
      "learning_rate": 1.8099206184757978e-05,
      "loss": 0.0056,
      "step": 896
    },
    {
      "epoch": 0.5991983967935872,
      "grad_norm": 1.9490234851837158,
      "learning_rate": 1.809510117917093e-05,
      "loss": 0.1571,
      "step": 897
    },
    {
      "epoch": 0.5998663994655978,
      "grad_norm": 1.4972866773605347,
      "learning_rate": 1.809099221230062e-05,
      "loss": 0.054,
      "step": 898
    },
    {
      "epoch": 0.6005344021376086,
      "grad_norm": 2.3532660007476807,
      "learning_rate": 1.8086879286157746e-05,
      "loss": 0.1548,
      "step": 899
    },
    {
      "epoch": 0.6012024048096193,
      "grad_norm": 0.11264496296644211,
      "learning_rate": 1.8082762402754936e-05,
      "loss": 0.0027,
      "step": 900
    },
    {
      "epoch": 0.6018704074816299,
      "grad_norm": 0.1303684562444687,
      "learning_rate": 1.807864156410676e-05,
      "loss": 0.0024,
      "step": 901
    },
    {
      "epoch": 0.6025384101536406,
      "grad_norm": 3.5455808639526367,
      "learning_rate": 1.8074516772229728e-05,
      "loss": 0.1972,
      "step": 902
    },
    {
      "epoch": 0.6032064128256514,
      "grad_norm": 4.298855304718018,
      "learning_rate": 1.8070388029142273e-05,
      "loss": 0.1537,
      "step": 903
    },
    {
      "epoch": 0.603874415497662,
      "grad_norm": 0.07162076234817505,
      "learning_rate": 1.806625533686477e-05,
      "loss": 0.0022,
      "step": 904
    },
    {
      "epoch": 0.6045424181696727,
      "grad_norm": 1.2825599908828735,
      "learning_rate": 1.8062118697419526e-05,
      "loss": 0.0184,
      "step": 905
    },
    {
      "epoch": 0.6052104208416834,
      "grad_norm": 2.356123685836792,
      "learning_rate": 1.8057978112830774e-05,
      "loss": 0.082,
      "step": 906
    },
    {
      "epoch": 0.605878423513694,
      "grad_norm": 4.254818439483643,
      "learning_rate": 1.805383358512468e-05,
      "loss": 0.1709,
      "step": 907
    },
    {
      "epoch": 0.6065464261857048,
      "grad_norm": 3.7324271202087402,
      "learning_rate": 1.804968511632935e-05,
      "loss": 0.1326,
      "step": 908
    },
    {
      "epoch": 0.6072144288577155,
      "grad_norm": 2.3373546600341797,
      "learning_rate": 1.80455327084748e-05,
      "loss": 0.0634,
      "step": 909
    },
    {
      "epoch": 0.6078824315297261,
      "grad_norm": 1.3593803644180298,
      "learning_rate": 1.8041376363592986e-05,
      "loss": 0.1051,
      "step": 910
    },
    {
      "epoch": 0.6085504342017368,
      "grad_norm": 1.352769374847412,
      "learning_rate": 1.8037216083717787e-05,
      "loss": 0.0798,
      "step": 911
    },
    {
      "epoch": 0.6092184368737475,
      "grad_norm": 0.6670834422111511,
      "learning_rate": 1.8033051870885007e-05,
      "loss": 0.0106,
      "step": 912
    },
    {
      "epoch": 0.6098864395457582,
      "grad_norm": 1.0577266216278076,
      "learning_rate": 1.8028883727132377e-05,
      "loss": 0.0145,
      "step": 913
    },
    {
      "epoch": 0.6105544422177689,
      "grad_norm": 11.56049633026123,
      "learning_rate": 1.802471165449955e-05,
      "loss": 0.6719,
      "step": 914
    },
    {
      "epoch": 0.6112224448897795,
      "grad_norm": 0.37658581137657166,
      "learning_rate": 1.8020535655028105e-05,
      "loss": 0.0064,
      "step": 915
    },
    {
      "epoch": 0.6118904475617902,
      "grad_norm": 0.3265153169631958,
      "learning_rate": 1.801635573076153e-05,
      "loss": 0.004,
      "step": 916
    },
    {
      "epoch": 0.612558450233801,
      "grad_norm": 3.8200275897979736,
      "learning_rate": 1.8012171883745253e-05,
      "loss": 0.1827,
      "step": 917
    },
    {
      "epoch": 0.6132264529058116,
      "grad_norm": 2.050403594970703,
      "learning_rate": 1.8007984116026604e-05,
      "loss": 0.1221,
      "step": 918
    },
    {
      "epoch": 0.6138944555778223,
      "grad_norm": 5.168027400970459,
      "learning_rate": 1.8003792429654844e-05,
      "loss": 0.1502,
      "step": 919
    },
    {
      "epoch": 0.614562458249833,
      "grad_norm": 13.168620109558105,
      "learning_rate": 1.799959682668114e-05,
      "loss": 0.6886,
      "step": 920
    },
    {
      "epoch": 0.6152304609218436,
      "grad_norm": 0.05775802955031395,
      "learning_rate": 1.7995397309158588e-05,
      "loss": 0.0013,
      "step": 921
    },
    {
      "epoch": 0.6158984635938544,
      "grad_norm": 7.517010688781738,
      "learning_rate": 1.7991193879142193e-05,
      "loss": 0.2031,
      "step": 922
    },
    {
      "epoch": 0.6165664662658651,
      "grad_norm": 3.0761144161224365,
      "learning_rate": 1.7986986538688876e-05,
      "loss": 0.1962,
      "step": 923
    },
    {
      "epoch": 0.6172344689378757,
      "grad_norm": 3.198929786682129,
      "learning_rate": 1.7982775289857465e-05,
      "loss": 0.2306,
      "step": 924
    },
    {
      "epoch": 0.6179024716098864,
      "grad_norm": 6.25688362121582,
      "learning_rate": 1.7978560134708713e-05,
      "loss": 0.1348,
      "step": 925
    },
    {
      "epoch": 0.6185704742818972,
      "grad_norm": 0.1144840344786644,
      "learning_rate": 1.7974341075305275e-05,
      "loss": 0.0024,
      "step": 926
    },
    {
      "epoch": 0.6192384769539078,
      "grad_norm": 8.387288093566895,
      "learning_rate": 1.7970118113711715e-05,
      "loss": 0.3432,
      "step": 927
    },
    {
      "epoch": 0.6199064796259185,
      "grad_norm": 0.15295790135860443,
      "learning_rate": 1.7965891251994523e-05,
      "loss": 0.0032,
      "step": 928
    },
    {
      "epoch": 0.6205744822979292,
      "grad_norm": 0.1452173888683319,
      "learning_rate": 1.796166049222207e-05,
      "loss": 0.0028,
      "step": 929
    },
    {
      "epoch": 0.6212424849699398,
      "grad_norm": 2.8352560997009277,
      "learning_rate": 1.795742583646466e-05,
      "loss": 0.2114,
      "step": 930
    },
    {
      "epoch": 0.6219104876419506,
      "grad_norm": 2.232651948928833,
      "learning_rate": 1.7953187286794487e-05,
      "loss": 0.043,
      "step": 931
    },
    {
      "epoch": 0.6225784903139613,
      "grad_norm": 7.6463799476623535,
      "learning_rate": 1.7948944845285668e-05,
      "loss": 0.1471,
      "step": 932
    },
    {
      "epoch": 0.6232464929859719,
      "grad_norm": 3.468834638595581,
      "learning_rate": 1.79446985140142e-05,
      "loss": 0.1477,
      "step": 933
    },
    {
      "epoch": 0.6239144956579826,
      "grad_norm": 5.907310485839844,
      "learning_rate": 1.7940448295058e-05,
      "loss": 0.2507,
      "step": 934
    },
    {
      "epoch": 0.6245824983299934,
      "grad_norm": 2.7920353412628174,
      "learning_rate": 1.793619419049689e-05,
      "loss": 0.1854,
      "step": 935
    },
    {
      "epoch": 0.625250501002004,
      "grad_norm": 1.6028306484222412,
      "learning_rate": 1.7931936202412582e-05,
      "loss": 0.0809,
      "step": 936
    },
    {
      "epoch": 0.6259185036740147,
      "grad_norm": 2.865605354309082,
      "learning_rate": 1.7927674332888695e-05,
      "loss": 0.1786,
      "step": 937
    },
    {
      "epoch": 0.6265865063460254,
      "grad_norm": 14.285768508911133,
      "learning_rate": 1.7923408584010745e-05,
      "loss": 0.2238,
      "step": 938
    },
    {
      "epoch": 0.627254509018036,
      "grad_norm": 1.7151156663894653,
      "learning_rate": 1.7919138957866155e-05,
      "loss": 0.0195,
      "step": 939
    },
    {
      "epoch": 0.6279225116900468,
      "grad_norm": 0.06793680042028427,
      "learning_rate": 1.7914865456544227e-05,
      "loss": 0.0014,
      "step": 940
    },
    {
      "epoch": 0.6285905143620575,
      "grad_norm": 2.5039098262786865,
      "learning_rate": 1.7910588082136176e-05,
      "loss": 0.1611,
      "step": 941
    },
    {
      "epoch": 0.6292585170340681,
      "grad_norm": 2.9486618041992188,
      "learning_rate": 1.79063068367351e-05,
      "loss": 0.152,
      "step": 942
    },
    {
      "epoch": 0.6299265197060788,
      "grad_norm": 2.490206718444824,
      "learning_rate": 1.790202172243601e-05,
      "loss": 0.1159,
      "step": 943
    },
    {
      "epoch": 0.6305945223780896,
      "grad_norm": 1.331909418106079,
      "learning_rate": 1.789773274133579e-05,
      "loss": 0.0868,
      "step": 944
    },
    {
      "epoch": 0.6312625250501002,
      "grad_norm": 1.7738635540008545,
      "learning_rate": 1.789343989553322e-05,
      "loss": 0.0293,
      "step": 945
    },
    {
      "epoch": 0.6319305277221109,
      "grad_norm": 2.4625580310821533,
      "learning_rate": 1.7889143187128984e-05,
      "loss": 0.1571,
      "step": 946
    },
    {
      "epoch": 0.6325985303941216,
      "grad_norm": 4.0203118324279785,
      "learning_rate": 1.788484261822564e-05,
      "loss": 0.1995,
      "step": 947
    },
    {
      "epoch": 0.6332665330661322,
      "grad_norm": 3.5682623386383057,
      "learning_rate": 1.7880538190927647e-05,
      "loss": 0.2115,
      "step": 948
    },
    {
      "epoch": 0.633934535738143,
      "grad_norm": 7.293247699737549,
      "learning_rate": 1.7876229907341347e-05,
      "loss": 0.3425,
      "step": 949
    },
    {
      "epoch": 0.6346025384101537,
      "grad_norm": 1.1677049398422241,
      "learning_rate": 1.787191776957497e-05,
      "loss": 0.0169,
      "step": 950
    },
    {
      "epoch": 0.6352705410821643,
      "grad_norm": 0.27426546812057495,
      "learning_rate": 1.7867601779738627e-05,
      "loss": 0.0039,
      "step": 951
    },
    {
      "epoch": 0.635938543754175,
      "grad_norm": 1.8270623683929443,
      "learning_rate": 1.7863281939944324e-05,
      "loss": 0.0789,
      "step": 952
    },
    {
      "epoch": 0.6366065464261857,
      "grad_norm": 0.38168978691101074,
      "learning_rate": 1.7858958252305943e-05,
      "loss": 0.0054,
      "step": 953
    },
    {
      "epoch": 0.6372745490981964,
      "grad_norm": 0.9768825173377991,
      "learning_rate": 1.7854630718939254e-05,
      "loss": 0.0165,
      "step": 954
    },
    {
      "epoch": 0.6379425517702071,
      "grad_norm": 2.5474159717559814,
      "learning_rate": 1.78502993419619e-05,
      "loss": 0.149,
      "step": 955
    },
    {
      "epoch": 0.6386105544422178,
      "grad_norm": 0.8901919722557068,
      "learning_rate": 1.7845964123493416e-05,
      "loss": 0.0129,
      "step": 956
    },
    {
      "epoch": 0.6392785571142284,
      "grad_norm": 4.250144958496094,
      "learning_rate": 1.784162506565521e-05,
      "loss": 0.1829,
      "step": 957
    },
    {
      "epoch": 0.6399465597862392,
      "grad_norm": 5.663042068481445,
      "learning_rate": 1.7837282170570576e-05,
      "loss": 0.115,
      "step": 958
    },
    {
      "epoch": 0.6406145624582499,
      "grad_norm": 2.5830230712890625,
      "learning_rate": 1.7832935440364676e-05,
      "loss": 0.192,
      "step": 959
    },
    {
      "epoch": 0.6412825651302605,
      "grad_norm": 7.39528226852417,
      "learning_rate": 1.782858487716455e-05,
      "loss": 0.2062,
      "step": 960
    },
    {
      "epoch": 0.6419505678022712,
      "grad_norm": 1.6491668224334717,
      "learning_rate": 1.7824230483099122e-05,
      "loss": 0.1689,
      "step": 961
    },
    {
      "epoch": 0.642618570474282,
      "grad_norm": 4.3984222412109375,
      "learning_rate": 1.7819872260299186e-05,
      "loss": 0.1037,
      "step": 962
    },
    {
      "epoch": 0.6432865731462926,
      "grad_norm": 11.047115325927734,
      "learning_rate": 1.7815510210897407e-05,
      "loss": 0.2159,
      "step": 963
    },
    {
      "epoch": 0.6439545758183033,
      "grad_norm": 1.891626238822937,
      "learning_rate": 1.781114433702832e-05,
      "loss": 0.0278,
      "step": 964
    },
    {
      "epoch": 0.644622578490314,
      "grad_norm": 4.487310409545898,
      "learning_rate": 1.7806774640828346e-05,
      "loss": 0.0951,
      "step": 965
    },
    {
      "epoch": 0.6452905811623246,
      "grad_norm": 0.18996968865394592,
      "learning_rate": 1.7802401124435757e-05,
      "loss": 0.0029,
      "step": 966
    },
    {
      "epoch": 0.6459585838343354,
      "grad_norm": 1.6041975021362305,
      "learning_rate": 1.779802378999071e-05,
      "loss": 0.1352,
      "step": 967
    },
    {
      "epoch": 0.6466265865063461,
      "grad_norm": 0.17551226913928986,
      "learning_rate": 1.779364263963522e-05,
      "loss": 0.0026,
      "step": 968
    },
    {
      "epoch": 0.6472945891783567,
      "grad_norm": 0.3602471649646759,
      "learning_rate": 1.7789257675513175e-05,
      "loss": 0.0046,
      "step": 969
    },
    {
      "epoch": 0.6479625918503674,
      "grad_norm": 1.4667778015136719,
      "learning_rate": 1.778486889977033e-05,
      "loss": 0.0234,
      "step": 970
    },
    {
      "epoch": 0.648630594522378,
      "grad_norm": 1.488991379737854,
      "learning_rate": 1.77804763145543e-05,
      "loss": 0.019,
      "step": 971
    },
    {
      "epoch": 0.6492985971943888,
      "grad_norm": 6.068126678466797,
      "learning_rate": 1.7776079922014564e-05,
      "loss": 0.1799,
      "step": 972
    },
    {
      "epoch": 0.6499665998663995,
      "grad_norm": 1.8885549306869507,
      "learning_rate": 1.7771679724302475e-05,
      "loss": 0.1757,
      "step": 973
    },
    {
      "epoch": 0.6506346025384101,
      "grad_norm": 2.6518466472625732,
      "learning_rate": 1.7767275723571234e-05,
      "loss": 0.0727,
      "step": 974
    },
    {
      "epoch": 0.6513026052104208,
      "grad_norm": 3.990607500076294,
      "learning_rate": 1.776286792197591e-05,
      "loss": 0.0404,
      "step": 975
    },
    {
      "epoch": 0.6519706078824316,
      "grad_norm": 10.332647323608398,
      "learning_rate": 1.7758456321673432e-05,
      "loss": 0.2077,
      "step": 976
    },
    {
      "epoch": 0.6526386105544422,
      "grad_norm": 11.84178638458252,
      "learning_rate": 1.7754040924822592e-05,
      "loss": 0.4394,
      "step": 977
    },
    {
      "epoch": 0.6533066132264529,
      "grad_norm": 6.971486568450928,
      "learning_rate": 1.7749621733584025e-05,
      "loss": 0.123,
      "step": 978
    },
    {
      "epoch": 0.6539746158984636,
      "grad_norm": 8.084077835083008,
      "learning_rate": 1.7745198750120237e-05,
      "loss": 0.2172,
      "step": 979
    },
    {
      "epoch": 0.6546426185704742,
      "grad_norm": 0.3278339207172394,
      "learning_rate": 1.7740771976595587e-05,
      "loss": 0.0036,
      "step": 980
    },
    {
      "epoch": 0.655310621242485,
      "grad_norm": 0.5798504948616028,
      "learning_rate": 1.7736341415176286e-05,
      "loss": 0.0102,
      "step": 981
    },
    {
      "epoch": 0.6559786239144957,
      "grad_norm": 2.682821035385132,
      "learning_rate": 1.7731907068030398e-05,
      "loss": 0.091,
      "step": 982
    },
    {
      "epoch": 0.6566466265865063,
      "grad_norm": 2.800410032272339,
      "learning_rate": 1.772746893732784e-05,
      "loss": 0.1628,
      "step": 983
    },
    {
      "epoch": 0.657314629258517,
      "grad_norm": 1.8279945850372314,
      "learning_rate": 1.7723027025240383e-05,
      "loss": 0.1213,
      "step": 984
    },
    {
      "epoch": 0.6579826319305278,
      "grad_norm": 2.5482513904571533,
      "learning_rate": 1.7718581333941647e-05,
      "loss": 0.0883,
      "step": 985
    },
    {
      "epoch": 0.6586506346025384,
      "grad_norm": 1.228732943534851,
      "learning_rate": 1.77141318656071e-05,
      "loss": 0.0123,
      "step": 986
    },
    {
      "epoch": 0.6593186372745491,
      "grad_norm": 2.7748186588287354,
      "learning_rate": 1.770967862241406e-05,
      "loss": 0.1677,
      "step": 987
    },
    {
      "epoch": 0.6599866399465598,
      "grad_norm": 0.9056848287582397,
      "learning_rate": 1.7705221606541695e-05,
      "loss": 0.0109,
      "step": 988
    },
    {
      "epoch": 0.6606546426185704,
      "grad_norm": 2.623117685317993,
      "learning_rate": 1.7700760820171007e-05,
      "loss": 0.125,
      "step": 989
    },
    {
      "epoch": 0.6613226452905812,
      "grad_norm": 6.104881286621094,
      "learning_rate": 1.7696296265484863e-05,
      "loss": 0.2077,
      "step": 990
    },
    {
      "epoch": 0.6619906479625919,
      "grad_norm": 1.6481668949127197,
      "learning_rate": 1.7691827944667954e-05,
      "loss": 0.0165,
      "step": 991
    },
    {
      "epoch": 0.6626586506346025,
      "grad_norm": 4.7791242599487305,
      "learning_rate": 1.7687355859906828e-05,
      "loss": 0.0655,
      "step": 992
    },
    {
      "epoch": 0.6633266533066132,
      "grad_norm": 0.4331074059009552,
      "learning_rate": 1.768288001338986e-05,
      "loss": 0.0053,
      "step": 993
    },
    {
      "epoch": 0.663994655978624,
      "grad_norm": 13.102895736694336,
      "learning_rate": 1.767840040730729e-05,
      "loss": 0.6833,
      "step": 994
    },
    {
      "epoch": 0.6646626586506346,
      "grad_norm": 9.780984878540039,
      "learning_rate": 1.7673917043851174e-05,
      "loss": 0.3018,
      "step": 995
    },
    {
      "epoch": 0.6653306613226453,
      "grad_norm": 3.590764045715332,
      "learning_rate": 1.7669429925215416e-05,
      "loss": 0.1886,
      "step": 996
    },
    {
      "epoch": 0.665998663994656,
      "grad_norm": 3.183216094970703,
      "learning_rate": 1.766493905359576e-05,
      "loss": 0.121,
      "step": 997
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.4804327487945557,
      "learning_rate": 1.766044443118978e-05,
      "loss": 0.1104,
      "step": 998
    },
    {
      "epoch": 0.6673346693386774,
      "grad_norm": 8.6149263381958,
      "learning_rate": 1.7655946060196894e-05,
      "loss": 0.2203,
      "step": 999
    },
    {
      "epoch": 0.6680026720106881,
      "grad_norm": 16.028162002563477,
      "learning_rate": 1.7651443942818346e-05,
      "loss": 0.5958,
      "step": 1000
    },
    {
      "epoch": 0.6686706746826987,
      "grad_norm": 0.9162194132804871,
      "learning_rate": 1.7646938081257222e-05,
      "loss": 0.0101,
      "step": 1001
    },
    {
      "epoch": 0.6693386773547094,
      "grad_norm": 2.6632802486419678,
      "learning_rate": 1.7642428477718426e-05,
      "loss": 0.2133,
      "step": 1002
    },
    {
      "epoch": 0.6700066800267201,
      "grad_norm": 3.7974672317504883,
      "learning_rate": 1.7637915134408713e-05,
      "loss": 0.1337,
      "step": 1003
    },
    {
      "epoch": 0.6706746826987308,
      "grad_norm": 13.350561141967773,
      "learning_rate": 1.7633398053536647e-05,
      "loss": 0.8546,
      "step": 1004
    },
    {
      "epoch": 0.6713426853707415,
      "grad_norm": 3.0974085330963135,
      "learning_rate": 1.7628877237312635e-05,
      "loss": 0.2106,
      "step": 1005
    },
    {
      "epoch": 0.6720106880427522,
      "grad_norm": 11.831666946411133,
      "learning_rate": 1.762435268794891e-05,
      "loss": 0.3389,
      "step": 1006
    },
    {
      "epoch": 0.6726786907147628,
      "grad_norm": 9.023628234863281,
      "learning_rate": 1.7619824407659528e-05,
      "loss": 0.2643,
      "step": 1007
    },
    {
      "epoch": 0.6733466933867736,
      "grad_norm": 0.5931716561317444,
      "learning_rate": 1.7615292398660372e-05,
      "loss": 0.0078,
      "step": 1008
    },
    {
      "epoch": 0.6740146960587843,
      "grad_norm": 2.8866074085235596,
      "learning_rate": 1.761075666316915e-05,
      "loss": 0.1389,
      "step": 1009
    },
    {
      "epoch": 0.6746826987307949,
      "grad_norm": 1.7199103832244873,
      "learning_rate": 1.76062172034054e-05,
      "loss": 0.1448,
      "step": 1010
    },
    {
      "epoch": 0.6753507014028056,
      "grad_norm": 1.1007617712020874,
      "learning_rate": 1.7601674021590463e-05,
      "loss": 0.0133,
      "step": 1011
    },
    {
      "epoch": 0.6760187040748163,
      "grad_norm": 1.4617291688919067,
      "learning_rate": 1.7597127119947524e-05,
      "loss": 0.0601,
      "step": 1012
    },
    {
      "epoch": 0.676686706746827,
      "grad_norm": 3.4278128147125244,
      "learning_rate": 1.7592576500701578e-05,
      "loss": 0.1449,
      "step": 1013
    },
    {
      "epoch": 0.6773547094188377,
      "grad_norm": 0.042389336973428726,
      "learning_rate": 1.758802216607944e-05,
      "loss": 0.0015,
      "step": 1014
    },
    {
      "epoch": 0.6780227120908484,
      "grad_norm": 0.061872925609350204,
      "learning_rate": 1.758346411830974e-05,
      "loss": 0.0016,
      "step": 1015
    },
    {
      "epoch": 0.678690714762859,
      "grad_norm": 2.1954851150512695,
      "learning_rate": 1.757890235962293e-05,
      "loss": 0.1837,
      "step": 1016
    },
    {
      "epoch": 0.6793587174348698,
      "grad_norm": 0.5730565190315247,
      "learning_rate": 1.7574336892251277e-05,
      "loss": 0.0089,
      "step": 1017
    },
    {
      "epoch": 0.6800267201068805,
      "grad_norm": 0.10244378447532654,
      "learning_rate": 1.7569767718428855e-05,
      "loss": 0.0016,
      "step": 1018
    },
    {
      "epoch": 0.6806947227788911,
      "grad_norm": 2.4059293270111084,
      "learning_rate": 1.7565194840391568e-05,
      "loss": 0.0373,
      "step": 1019
    },
    {
      "epoch": 0.6813627254509018,
      "grad_norm": 2.4225666522979736,
      "learning_rate": 1.7560618260377117e-05,
      "loss": 0.1639,
      "step": 1020
    },
    {
      "epoch": 0.6820307281229125,
      "grad_norm": 6.470626354217529,
      "learning_rate": 1.7556037980625022e-05,
      "loss": 0.3718,
      "step": 1021
    },
    {
      "epoch": 0.6826987307949232,
      "grad_norm": 2.5773868560791016,
      "learning_rate": 1.7551454003376613e-05,
      "loss": 0.1471,
      "step": 1022
    },
    {
      "epoch": 0.6833667334669339,
      "grad_norm": 2.6106109619140625,
      "learning_rate": 1.754686633087503e-05,
      "loss": 0.0646,
      "step": 1023
    },
    {
      "epoch": 0.6840347361389446,
      "grad_norm": 0.5535444021224976,
      "learning_rate": 1.7542274965365214e-05,
      "loss": 0.0081,
      "step": 1024
    },
    {
      "epoch": 0.6847027388109552,
      "grad_norm": 2.4798882007598877,
      "learning_rate": 1.7537679909093922e-05,
      "loss": 0.1364,
      "step": 1025
    },
    {
      "epoch": 0.685370741482966,
      "grad_norm": 10.068814277648926,
      "learning_rate": 1.753308116430972e-05,
      "loss": 0.5589,
      "step": 1026
    },
    {
      "epoch": 0.6860387441549766,
      "grad_norm": 1.563554286956787,
      "learning_rate": 1.7528478733262958e-05,
      "loss": 0.1392,
      "step": 1027
    },
    {
      "epoch": 0.6867067468269873,
      "grad_norm": 1.5163218975067139,
      "learning_rate": 1.752387261820582e-05,
      "loss": 0.1231,
      "step": 1028
    },
    {
      "epoch": 0.687374749498998,
      "grad_norm": 12.486818313598633,
      "learning_rate": 1.751926282139227e-05,
      "loss": 0.4751,
      "step": 1029
    },
    {
      "epoch": 0.6880427521710086,
      "grad_norm": 0.056773591786623,
      "learning_rate": 1.751464934507808e-05,
      "loss": 0.0015,
      "step": 1030
    },
    {
      "epoch": 0.6887107548430194,
      "grad_norm": 1.8170981407165527,
      "learning_rate": 1.7510032191520825e-05,
      "loss": 0.1793,
      "step": 1031
    },
    {
      "epoch": 0.6893787575150301,
      "grad_norm": 1.6958308219909668,
      "learning_rate": 1.750541136297988e-05,
      "loss": 0.0901,
      "step": 1032
    },
    {
      "epoch": 0.6900467601870407,
      "grad_norm": 2.4159436225891113,
      "learning_rate": 1.7500786861716414e-05,
      "loss": 0.0954,
      "step": 1033
    },
    {
      "epoch": 0.6907147628590514,
      "grad_norm": 3.200526237487793,
      "learning_rate": 1.7496158689993397e-05,
      "loss": 0.1019,
      "step": 1034
    },
    {
      "epoch": 0.6913827655310621,
      "grad_norm": 2.058443546295166,
      "learning_rate": 1.7491526850075593e-05,
      "loss": 0.136,
      "step": 1035
    },
    {
      "epoch": 0.6920507682030728,
      "grad_norm": 2.382107973098755,
      "learning_rate": 1.748689134422956e-05,
      "loss": 0.1454,
      "step": 1036
    },
    {
      "epoch": 0.6927187708750835,
      "grad_norm": 9.687445640563965,
      "learning_rate": 1.7482252174723658e-05,
      "loss": 0.3104,
      "step": 1037
    },
    {
      "epoch": 0.6933867735470942,
      "grad_norm": 1.886044979095459,
      "learning_rate": 1.7477609343828025e-05,
      "loss": 0.1225,
      "step": 1038
    },
    {
      "epoch": 0.6940547762191048,
      "grad_norm": 3.055203437805176,
      "learning_rate": 1.7472962853814604e-05,
      "loss": 0.124,
      "step": 1039
    },
    {
      "epoch": 0.6947227788911156,
      "grad_norm": 10.241462707519531,
      "learning_rate": 1.7468312706957123e-05,
      "loss": 0.4537,
      "step": 1040
    },
    {
      "epoch": 0.6953907815631263,
      "grad_norm": 8.42179012298584,
      "learning_rate": 1.7463658905531094e-05,
      "loss": 0.3531,
      "step": 1041
    },
    {
      "epoch": 0.6960587842351369,
      "grad_norm": 3.7546005249023438,
      "learning_rate": 1.7459001451813838e-05,
      "loss": 0.2106,
      "step": 1042
    },
    {
      "epoch": 0.6967267869071476,
      "grad_norm": 7.29415225982666,
      "learning_rate": 1.745434034808443e-05,
      "loss": 0.3233,
      "step": 1043
    },
    {
      "epoch": 0.6973947895791583,
      "grad_norm": 6.78860330581665,
      "learning_rate": 1.7449675596623765e-05,
      "loss": 0.1843,
      "step": 1044
    },
    {
      "epoch": 0.698062792251169,
      "grad_norm": 2.9540843963623047,
      "learning_rate": 1.7445007199714505e-05,
      "loss": 0.1228,
      "step": 1045
    },
    {
      "epoch": 0.6987307949231797,
      "grad_norm": 2.91904354095459,
      "learning_rate": 1.7440335159641088e-05,
      "loss": 0.1463,
      "step": 1046
    },
    {
      "epoch": 0.6993987975951904,
      "grad_norm": 0.5188955664634705,
      "learning_rate": 1.7435659478689758e-05,
      "loss": 0.0055,
      "step": 1047
    },
    {
      "epoch": 0.700066800267201,
      "grad_norm": 2.474729299545288,
      "learning_rate": 1.743098015914852e-05,
      "loss": 0.1358,
      "step": 1048
    },
    {
      "epoch": 0.7007348029392118,
      "grad_norm": 1.9749798774719238,
      "learning_rate": 1.742629720330717e-05,
      "loss": 0.1457,
      "step": 1049
    },
    {
      "epoch": 0.7014028056112225,
      "grad_norm": 12.596909523010254,
      "learning_rate": 1.7421610613457283e-05,
      "loss": 0.4914,
      "step": 1050
    },
    {
      "epoch": 0.7020708082832331,
      "grad_norm": 0.30588752031326294,
      "learning_rate": 1.7416920391892208e-05,
      "loss": 0.004,
      "step": 1051
    },
    {
      "epoch": 0.7027388109552438,
      "grad_norm": 3.0337865352630615,
      "learning_rate": 1.7412226540907075e-05,
      "loss": 0.1938,
      "step": 1052
    },
    {
      "epoch": 0.7034068136272545,
      "grad_norm": 4.592350006103516,
      "learning_rate": 1.7407529062798784e-05,
      "loss": 0.2275,
      "step": 1053
    },
    {
      "epoch": 0.7040748162992652,
      "grad_norm": 1.4397743940353394,
      "learning_rate": 1.740282795986602e-05,
      "loss": 0.1191,
      "step": 1054
    },
    {
      "epoch": 0.7047428189712759,
      "grad_norm": 8.385515213012695,
      "learning_rate": 1.739812323440923e-05,
      "loss": 0.4322,
      "step": 1055
    },
    {
      "epoch": 0.7054108216432866,
      "grad_norm": 0.0627957284450531,
      "learning_rate": 1.7393414888730648e-05,
      "loss": 0.0014,
      "step": 1056
    },
    {
      "epoch": 0.7060788243152972,
      "grad_norm": 1.3750543594360352,
      "learning_rate": 1.7388702925134264e-05,
      "loss": 0.1121,
      "step": 1057
    },
    {
      "epoch": 0.706746826987308,
      "grad_norm": 2.032395362854004,
      "learning_rate": 1.738398734592585e-05,
      "loss": 0.11,
      "step": 1058
    },
    {
      "epoch": 0.7074148296593187,
      "grad_norm": 2.7146990299224854,
      "learning_rate": 1.737926815341294e-05,
      "loss": 0.0986,
      "step": 1059
    },
    {
      "epoch": 0.7080828323313293,
      "grad_norm": 4.253706932067871,
      "learning_rate": 1.7374545349904842e-05,
      "loss": 0.2776,
      "step": 1060
    },
    {
      "epoch": 0.70875083500334,
      "grad_norm": 1.7967333793640137,
      "learning_rate": 1.7369818937712622e-05,
      "loss": 0.1366,
      "step": 1061
    },
    {
      "epoch": 0.7094188376753507,
      "grad_norm": 2.6477267742156982,
      "learning_rate": 1.7365088919149124e-05,
      "loss": 0.163,
      "step": 1062
    },
    {
      "epoch": 0.7100868403473614,
      "grad_norm": 3.2797181606292725,
      "learning_rate": 1.736035529652895e-05,
      "loss": 0.1334,
      "step": 1063
    },
    {
      "epoch": 0.7107548430193721,
      "grad_norm": 2.400326728820801,
      "learning_rate": 1.7355618072168464e-05,
      "loss": 0.0461,
      "step": 1064
    },
    {
      "epoch": 0.7114228456913828,
      "grad_norm": 1.1202733516693115,
      "learning_rate": 1.73508772483858e-05,
      "loss": 0.0821,
      "step": 1065
    },
    {
      "epoch": 0.7120908483633934,
      "grad_norm": 2.4101717472076416,
      "learning_rate": 1.734613282750084e-05,
      "loss": 0.1879,
      "step": 1066
    },
    {
      "epoch": 0.7127588510354042,
      "grad_norm": 0.5120932459831238,
      "learning_rate": 1.734138481183524e-05,
      "loss": 0.0073,
      "step": 1067
    },
    {
      "epoch": 0.7134268537074149,
      "grad_norm": 3.7792294025421143,
      "learning_rate": 1.733663320371241e-05,
      "loss": 0.1337,
      "step": 1068
    },
    {
      "epoch": 0.7140948563794255,
      "grad_norm": 6.258969783782959,
      "learning_rate": 1.7331878005457514e-05,
      "loss": 0.256,
      "step": 1069
    },
    {
      "epoch": 0.7147628590514362,
      "grad_norm": 1.1611528396606445,
      "learning_rate": 1.732711921939748e-05,
      "loss": 0.1127,
      "step": 1070
    },
    {
      "epoch": 0.7154308617234469,
      "grad_norm": 2.1557748317718506,
      "learning_rate": 1.7322356847860985e-05,
      "loss": 0.0436,
      "step": 1071
    },
    {
      "epoch": 0.7160988643954576,
      "grad_norm": 4.15982723236084,
      "learning_rate": 1.7317590893178463e-05,
      "loss": 0.1187,
      "step": 1072
    },
    {
      "epoch": 0.7167668670674683,
      "grad_norm": 5.7699995040893555,
      "learning_rate": 1.7312821357682104e-05,
      "loss": 0.1543,
      "step": 1073
    },
    {
      "epoch": 0.717434869739479,
      "grad_norm": 6.385172367095947,
      "learning_rate": 1.730804824370585e-05,
      "loss": 0.2132,
      "step": 1074
    },
    {
      "epoch": 0.7181028724114896,
      "grad_norm": 3.6188457012176514,
      "learning_rate": 1.7303271553585384e-05,
      "loss": 0.2018,
      "step": 1075
    },
    {
      "epoch": 0.7187708750835003,
      "grad_norm": 2.0366861820220947,
      "learning_rate": 1.7298491289658155e-05,
      "loss": 0.1749,
      "step": 1076
    },
    {
      "epoch": 0.7194388777555111,
      "grad_norm": 1.5123246908187866,
      "learning_rate": 1.7293707454263352e-05,
      "loss": 0.1498,
      "step": 1077
    },
    {
      "epoch": 0.7201068804275217,
      "grad_norm": 1.1289324760437012,
      "learning_rate": 1.728892004974191e-05,
      "loss": 0.161,
      "step": 1078
    },
    {
      "epoch": 0.7207748830995324,
      "grad_norm": 1.6073637008666992,
      "learning_rate": 1.7284129078436517e-05,
      "loss": 0.1242,
      "step": 1079
    },
    {
      "epoch": 0.7214428857715431,
      "grad_norm": 3.3147542476654053,
      "learning_rate": 1.7279334542691596e-05,
      "loss": 0.133,
      "step": 1080
    },
    {
      "epoch": 0.7221108884435538,
      "grad_norm": 2.2910571098327637,
      "learning_rate": 1.727453644485333e-05,
      "loss": 0.1642,
      "step": 1081
    },
    {
      "epoch": 0.7227788911155645,
      "grad_norm": 1.137422800064087,
      "learning_rate": 1.7269734787269628e-05,
      "loss": 0.0119,
      "step": 1082
    },
    {
      "epoch": 0.7234468937875751,
      "grad_norm": 0.14112508296966553,
      "learning_rate": 1.726492957229015e-05,
      "loss": 0.0026,
      "step": 1083
    },
    {
      "epoch": 0.7241148964595858,
      "grad_norm": 1.8191864490509033,
      "learning_rate": 1.72601208022663e-05,
      "loss": 0.0979,
      "step": 1084
    },
    {
      "epoch": 0.7247828991315965,
      "grad_norm": 2.5005743503570557,
      "learning_rate": 1.725530847955121e-05,
      "loss": 0.0804,
      "step": 1085
    },
    {
      "epoch": 0.7254509018036072,
      "grad_norm": 4.017331123352051,
      "learning_rate": 1.7250492606499766e-05,
      "loss": 0.2919,
      "step": 1086
    },
    {
      "epoch": 0.7261189044756179,
      "grad_norm": 3.8415675163269043,
      "learning_rate": 1.7245673185468576e-05,
      "loss": 0.2492,
      "step": 1087
    },
    {
      "epoch": 0.7267869071476286,
      "grad_norm": 1.9721908569335938,
      "learning_rate": 1.7240850218815996e-05,
      "loss": 0.1341,
      "step": 1088
    },
    {
      "epoch": 0.7274549098196392,
      "grad_norm": 0.30700331926345825,
      "learning_rate": 1.7236023708902113e-05,
      "loss": 0.0033,
      "step": 1089
    },
    {
      "epoch": 0.72812291249165,
      "grad_norm": 1.8475359678268433,
      "learning_rate": 1.723119365808874e-05,
      "loss": 0.1365,
      "step": 1090
    },
    {
      "epoch": 0.7287909151636607,
      "grad_norm": 0.9495506286621094,
      "learning_rate": 1.722636006873944e-05,
      "loss": 0.0119,
      "step": 1091
    },
    {
      "epoch": 0.7294589178356713,
      "grad_norm": 2.0788450241088867,
      "learning_rate": 1.7221522943219486e-05,
      "loss": 0.1438,
      "step": 1092
    },
    {
      "epoch": 0.730126920507682,
      "grad_norm": 3.7755608558654785,
      "learning_rate": 1.72166822838959e-05,
      "loss": 0.0639,
      "step": 1093
    },
    {
      "epoch": 0.7307949231796927,
      "grad_norm": 3.5270729064941406,
      "learning_rate": 1.7211838093137426e-05,
      "loss": 0.1838,
      "step": 1094
    },
    {
      "epoch": 0.7314629258517034,
      "grad_norm": 0.656732439994812,
      "learning_rate": 1.7206990373314538e-05,
      "loss": 0.0077,
      "step": 1095
    },
    {
      "epoch": 0.7321309285237141,
      "grad_norm": 1.4938822984695435,
      "learning_rate": 1.720213912679943e-05,
      "loss": 0.0767,
      "step": 1096
    },
    {
      "epoch": 0.7327989311957248,
      "grad_norm": 1.805052399635315,
      "learning_rate": 1.7197284355966025e-05,
      "loss": 0.1125,
      "step": 1097
    },
    {
      "epoch": 0.7334669338677354,
      "grad_norm": 13.518486022949219,
      "learning_rate": 1.7192426063189982e-05,
      "loss": 0.4393,
      "step": 1098
    },
    {
      "epoch": 0.7341349365397462,
      "grad_norm": 4.954237937927246,
      "learning_rate": 1.7187564250848664e-05,
      "loss": 0.0858,
      "step": 1099
    },
    {
      "epoch": 0.7348029392117569,
      "grad_norm": 0.6459388136863708,
      "learning_rate": 1.7182698921321174e-05,
      "loss": 0.009,
      "step": 1100
    },
    {
      "epoch": 0.7354709418837675,
      "grad_norm": 0.9366827607154846,
      "learning_rate": 1.717783007698832e-05,
      "loss": 0.012,
      "step": 1101
    },
    {
      "epoch": 0.7361389445557782,
      "grad_norm": 0.32043612003326416,
      "learning_rate": 1.7172957720232646e-05,
      "loss": 0.0043,
      "step": 1102
    },
    {
      "epoch": 0.7368069472277889,
      "grad_norm": 2.5596835613250732,
      "learning_rate": 1.7168081853438404e-05,
      "loss": 0.2141,
      "step": 1103
    },
    {
      "epoch": 0.7374749498997996,
      "grad_norm": 7.9085283279418945,
      "learning_rate": 1.7163202478991566e-05,
      "loss": 0.1659,
      "step": 1104
    },
    {
      "epoch": 0.7381429525718103,
      "grad_norm": 5.024235725402832,
      "learning_rate": 1.715831959927982e-05,
      "loss": 0.1285,
      "step": 1105
    },
    {
      "epoch": 0.738810955243821,
      "grad_norm": 5.436935901641846,
      "learning_rate": 1.715343321669257e-05,
      "loss": 0.1495,
      "step": 1106
    },
    {
      "epoch": 0.7394789579158316,
      "grad_norm": 2.2852556705474854,
      "learning_rate": 1.714854333362094e-05,
      "loss": 0.028,
      "step": 1107
    },
    {
      "epoch": 0.7401469605878424,
      "grad_norm": 2.3424971103668213,
      "learning_rate": 1.7143649952457755e-05,
      "loss": 0.1419,
      "step": 1108
    },
    {
      "epoch": 0.7408149632598531,
      "grad_norm": 1.5168200731277466,
      "learning_rate": 1.713875307559756e-05,
      "loss": 0.1399,
      "step": 1109
    },
    {
      "epoch": 0.7414829659318637,
      "grad_norm": 3.659688711166382,
      "learning_rate": 1.7133852705436612e-05,
      "loss": 0.066,
      "step": 1110
    },
    {
      "epoch": 0.7421509686038744,
      "grad_norm": 8.357828140258789,
      "learning_rate": 1.7128948844372867e-05,
      "loss": 0.2761,
      "step": 1111
    },
    {
      "epoch": 0.7428189712758851,
      "grad_norm": 0.3550347685813904,
      "learning_rate": 1.7124041494806e-05,
      "loss": 0.0062,
      "step": 1112
    },
    {
      "epoch": 0.7434869739478958,
      "grad_norm": 18.24992561340332,
      "learning_rate": 1.71191306591374e-05,
      "loss": 0.658,
      "step": 1113
    },
    {
      "epoch": 0.7441549766199065,
      "grad_norm": 6.8627095222473145,
      "learning_rate": 1.7114216339770133e-05,
      "loss": 0.2355,
      "step": 1114
    },
    {
      "epoch": 0.7448229792919172,
      "grad_norm": 3.6197805404663086,
      "learning_rate": 1.7109298539109e-05,
      "loss": 0.0766,
      "step": 1115
    },
    {
      "epoch": 0.7454909819639278,
      "grad_norm": 14.132431983947754,
      "learning_rate": 1.710437725956049e-05,
      "loss": 0.5452,
      "step": 1116
    },
    {
      "epoch": 0.7461589846359385,
      "grad_norm": 2.547999620437622,
      "learning_rate": 1.7099452503532796e-05,
      "loss": 0.083,
      "step": 1117
    },
    {
      "epoch": 0.7468269873079493,
      "grad_norm": 12.682032585144043,
      "learning_rate": 1.709452427343582e-05,
      "loss": 0.6106,
      "step": 1118
    },
    {
      "epoch": 0.7474949899799599,
      "grad_norm": 1.6533281803131104,
      "learning_rate": 1.7089592571681152e-05,
      "loss": 0.117,
      "step": 1119
    },
    {
      "epoch": 0.7481629926519706,
      "grad_norm": 1.223606824874878,
      "learning_rate": 1.7084657400682093e-05,
      "loss": 0.1175,
      "step": 1120
    },
    {
      "epoch": 0.7488309953239813,
      "grad_norm": 1.8613847494125366,
      "learning_rate": 1.7079718762853628e-05,
      "loss": 0.0977,
      "step": 1121
    },
    {
      "epoch": 0.749498997995992,
      "grad_norm": 0.42405837774276733,
      "learning_rate": 1.7074776660612453e-05,
      "loss": 0.0056,
      "step": 1122
    },
    {
      "epoch": 0.7501670006680027,
      "grad_norm": 2.38380765914917,
      "learning_rate": 1.7069831096376952e-05,
      "loss": 0.1417,
      "step": 1123
    },
    {
      "epoch": 0.7508350033400134,
      "grad_norm": 2.547342538833618,
      "learning_rate": 1.70648820725672e-05,
      "loss": 0.0337,
      "step": 1124
    },
    {
      "epoch": 0.751503006012024,
      "grad_norm": 1.410461664199829,
      "learning_rate": 1.705992959160497e-05,
      "loss": 0.1271,
      "step": 1125
    },
    {
      "epoch": 0.7521710086840347,
      "grad_norm": 10.235061645507812,
      "learning_rate": 1.7054973655913727e-05,
      "loss": 0.3862,
      "step": 1126
    },
    {
      "epoch": 0.7528390113560455,
      "grad_norm": 2.1336498260498047,
      "learning_rate": 1.705001426791862e-05,
      "loss": 0.1637,
      "step": 1127
    },
    {
      "epoch": 0.7535070140280561,
      "grad_norm": 0.49227482080459595,
      "learning_rate": 1.70450514300465e-05,
      "loss": 0.0067,
      "step": 1128
    },
    {
      "epoch": 0.7541750167000668,
      "grad_norm": 1.35280179977417,
      "learning_rate": 1.704008514472589e-05,
      "loss": 0.0193,
      "step": 1129
    },
    {
      "epoch": 0.7548430193720775,
      "grad_norm": 12.792654037475586,
      "learning_rate": 1.7035115414387014e-05,
      "loss": 0.4828,
      "step": 1130
    },
    {
      "epoch": 0.7555110220440882,
      "grad_norm": 2.2905850410461426,
      "learning_rate": 1.7030142241461774e-05,
      "loss": 0.1798,
      "step": 1131
    },
    {
      "epoch": 0.7561790247160989,
      "grad_norm": 2.3493387699127197,
      "learning_rate": 1.7025165628383757e-05,
      "loss": 0.2078,
      "step": 1132
    },
    {
      "epoch": 0.7568470273881096,
      "grad_norm": 1.7903411388397217,
      "learning_rate": 1.702018557758824e-05,
      "loss": 0.1217,
      "step": 1133
    },
    {
      "epoch": 0.7575150300601202,
      "grad_norm": 1.6505824327468872,
      "learning_rate": 1.701520209151217e-05,
      "loss": 0.1042,
      "step": 1134
    },
    {
      "epoch": 0.758183032732131,
      "grad_norm": 2.5796072483062744,
      "learning_rate": 1.7010215172594187e-05,
      "loss": 0.2151,
      "step": 1135
    },
    {
      "epoch": 0.7588510354041417,
      "grad_norm": 6.2257256507873535,
      "learning_rate": 1.700522482327461e-05,
      "loss": 0.2318,
      "step": 1136
    },
    {
      "epoch": 0.7595190380761523,
      "grad_norm": 2.207653760910034,
      "learning_rate": 1.7000231045995422e-05,
      "loss": 0.191,
      "step": 1137
    },
    {
      "epoch": 0.760187040748163,
      "grad_norm": 1.8264472484588623,
      "learning_rate": 1.6995233843200306e-05,
      "loss": 0.1568,
      "step": 1138
    },
    {
      "epoch": 0.7608550434201736,
      "grad_norm": 0.5185510516166687,
      "learning_rate": 1.6990233217334603e-05,
      "loss": 0.0088,
      "step": 1139
    },
    {
      "epoch": 0.7615230460921844,
      "grad_norm": 2.337557315826416,
      "learning_rate": 1.698522917084534e-05,
      "loss": 0.0383,
      "step": 1140
    },
    {
      "epoch": 0.7621910487641951,
      "grad_norm": 2.3376920223236084,
      "learning_rate": 1.6980221706181205e-05,
      "loss": 0.136,
      "step": 1141
    },
    {
      "epoch": 0.7628590514362057,
      "grad_norm": 3.3716704845428467,
      "learning_rate": 1.6975210825792573e-05,
      "loss": 0.0758,
      "step": 1142
    },
    {
      "epoch": 0.7635270541082164,
      "grad_norm": 7.759396553039551,
      "learning_rate": 1.697019653213149e-05,
      "loss": 0.202,
      "step": 1143
    },
    {
      "epoch": 0.7641950567802271,
      "grad_norm": 1.885108232498169,
      "learning_rate": 1.6965178827651656e-05,
      "loss": 0.1856,
      "step": 1144
    },
    {
      "epoch": 0.7648630594522378,
      "grad_norm": 0.2117900550365448,
      "learning_rate": 1.6960157714808458e-05,
      "loss": 0.0031,
      "step": 1145
    },
    {
      "epoch": 0.7655310621242485,
      "grad_norm": 2.0843238830566406,
      "learning_rate": 1.695513319605894e-05,
      "loss": 0.1436,
      "step": 1146
    },
    {
      "epoch": 0.7661990647962592,
      "grad_norm": 0.6326884627342224,
      "learning_rate": 1.6950105273861818e-05,
      "loss": 0.0086,
      "step": 1147
    },
    {
      "epoch": 0.7668670674682698,
      "grad_norm": 4.149136066436768,
      "learning_rate": 1.6945073950677472e-05,
      "loss": 0.1714,
      "step": 1148
    },
    {
      "epoch": 0.7675350701402806,
      "grad_norm": 0.2194111943244934,
      "learning_rate": 1.6940039228967944e-05,
      "loss": 0.0024,
      "step": 1149
    },
    {
      "epoch": 0.7682030728122913,
      "grad_norm": 2.227635383605957,
      "learning_rate": 1.6935001111196946e-05,
      "loss": 0.1005,
      "step": 1150
    },
    {
      "epoch": 0.7688710754843019,
      "grad_norm": 2.8677852153778076,
      "learning_rate": 1.6929959599829848e-05,
      "loss": 0.1926,
      "step": 1151
    },
    {
      "epoch": 0.7695390781563126,
      "grad_norm": 3.7418971061706543,
      "learning_rate": 1.692491469733367e-05,
      "loss": 0.1347,
      "step": 1152
    },
    {
      "epoch": 0.7702070808283233,
      "grad_norm": 0.1768496334552765,
      "learning_rate": 1.691986640617711e-05,
      "loss": 0.0022,
      "step": 1153
    },
    {
      "epoch": 0.770875083500334,
      "grad_norm": 1.1243139505386353,
      "learning_rate": 1.691481472883051e-05,
      "loss": 0.0965,
      "step": 1154
    },
    {
      "epoch": 0.7715430861723447,
      "grad_norm": 1.187026023864746,
      "learning_rate": 1.6909759667765878e-05,
      "loss": 0.0936,
      "step": 1155
    },
    {
      "epoch": 0.7722110888443554,
      "grad_norm": 2.050069808959961,
      "learning_rate": 1.6904701225456874e-05,
      "loss": 0.1798,
      "step": 1156
    },
    {
      "epoch": 0.772879091516366,
      "grad_norm": 0.2866978645324707,
      "learning_rate": 1.6899639404378808e-05,
      "loss": 0.0039,
      "step": 1157
    },
    {
      "epoch": 0.7735470941883767,
      "grad_norm": 11.49840259552002,
      "learning_rate": 1.6894574207008653e-05,
      "loss": 0.6187,
      "step": 1158
    },
    {
      "epoch": 0.7742150968603875,
      "grad_norm": 1.664867639541626,
      "learning_rate": 1.688950563582503e-05,
      "loss": 0.0958,
      "step": 1159
    },
    {
      "epoch": 0.7748830995323981,
      "grad_norm": 6.047621726989746,
      "learning_rate": 1.6884433693308208e-05,
      "loss": 0.2332,
      "step": 1160
    },
    {
      "epoch": 0.7755511022044088,
      "grad_norm": 1.559075117111206,
      "learning_rate": 1.6879358381940103e-05,
      "loss": 0.1854,
      "step": 1161
    },
    {
      "epoch": 0.7762191048764195,
      "grad_norm": 8.01315975189209,
      "learning_rate": 1.687427970420429e-05,
      "loss": 0.2541,
      "step": 1162
    },
    {
      "epoch": 0.7768871075484302,
      "grad_norm": 2.4126362800598145,
      "learning_rate": 1.686919766258599e-05,
      "loss": 0.1933,
      "step": 1163
    },
    {
      "epoch": 0.7775551102204409,
      "grad_norm": 8.14173412322998,
      "learning_rate": 1.6864112259572057e-05,
      "loss": 0.3652,
      "step": 1164
    },
    {
      "epoch": 0.7782231128924516,
      "grad_norm": 2.0817058086395264,
      "learning_rate": 1.6859023497651005e-05,
      "loss": 0.1634,
      "step": 1165
    },
    {
      "epoch": 0.7788911155644622,
      "grad_norm": 0.22104205191135406,
      "learning_rate": 1.685393137931298e-05,
      "loss": 0.0035,
      "step": 1166
    },
    {
      "epoch": 0.779559118236473,
      "grad_norm": 6.447016716003418,
      "learning_rate": 1.6848835907049778e-05,
      "loss": 0.2885,
      "step": 1167
    },
    {
      "epoch": 0.7802271209084837,
      "grad_norm": 1.7419207096099854,
      "learning_rate": 1.6843737083354836e-05,
      "loss": 0.1352,
      "step": 1168
    },
    {
      "epoch": 0.7808951235804943,
      "grad_norm": 1.5167704820632935,
      "learning_rate": 1.683863491072323e-05,
      "loss": 0.0325,
      "step": 1169
    },
    {
      "epoch": 0.781563126252505,
      "grad_norm": 1.71981942653656,
      "learning_rate": 1.683352939165167e-05,
      "loss": 0.1679,
      "step": 1170
    },
    {
      "epoch": 0.7822311289245157,
      "grad_norm": 0.33890143036842346,
      "learning_rate": 1.6828420528638508e-05,
      "loss": 0.0039,
      "step": 1171
    },
    {
      "epoch": 0.7828991315965264,
      "grad_norm": 1.1364288330078125,
      "learning_rate": 1.6823308324183735e-05,
      "loss": 0.1428,
      "step": 1172
    },
    {
      "epoch": 0.7835671342685371,
      "grad_norm": 0.5025447607040405,
      "learning_rate": 1.681819278078897e-05,
      "loss": 0.0053,
      "step": 1173
    },
    {
      "epoch": 0.7842351369405478,
      "grad_norm": 2.195824384689331,
      "learning_rate": 1.6813073900957473e-05,
      "loss": 0.1671,
      "step": 1174
    },
    {
      "epoch": 0.7849031396125584,
      "grad_norm": 11.290332794189453,
      "learning_rate": 1.6807951687194132e-05,
      "loss": 0.4138,
      "step": 1175
    },
    {
      "epoch": 0.7855711422845691,
      "grad_norm": 0.5723622441291809,
      "learning_rate": 1.6802826142005466e-05,
      "loss": 0.0087,
      "step": 1176
    },
    {
      "epoch": 0.7862391449565799,
      "grad_norm": 2.1891257762908936,
      "learning_rate": 1.6797697267899627e-05,
      "loss": 0.1466,
      "step": 1177
    },
    {
      "epoch": 0.7869071476285905,
      "grad_norm": 3.4098455905914307,
      "learning_rate": 1.6792565067386397e-05,
      "loss": 0.1018,
      "step": 1178
    },
    {
      "epoch": 0.7875751503006012,
      "grad_norm": 1.7503256797790527,
      "learning_rate": 1.678742954297718e-05,
      "loss": 0.0458,
      "step": 1179
    },
    {
      "epoch": 0.7882431529726119,
      "grad_norm": 1.3073129653930664,
      "learning_rate": 1.6782290697185012e-05,
      "loss": 0.1586,
      "step": 1180
    },
    {
      "epoch": 0.7889111556446226,
      "grad_norm": 0.5430835485458374,
      "learning_rate": 1.677714853252456e-05,
      "loss": 0.0082,
      "step": 1181
    },
    {
      "epoch": 0.7895791583166333,
      "grad_norm": 2.191699981689453,
      "learning_rate": 1.6772003051512095e-05,
      "loss": 0.161,
      "step": 1182
    },
    {
      "epoch": 0.790247160988644,
      "grad_norm": 1.6060177087783813,
      "learning_rate": 1.6766854256665533e-05,
      "loss": 0.0435,
      "step": 1183
    },
    {
      "epoch": 0.7909151636606546,
      "grad_norm": 2.317457437515259,
      "learning_rate": 1.6761702150504397e-05,
      "loss": 0.1688,
      "step": 1184
    },
    {
      "epoch": 0.7915831663326653,
      "grad_norm": 3.071837902069092,
      "learning_rate": 1.6756546735549832e-05,
      "loss": 0.1534,
      "step": 1185
    },
    {
      "epoch": 0.7922511690046761,
      "grad_norm": 0.4697420299053192,
      "learning_rate": 1.6751388014324615e-05,
      "loss": 0.0052,
      "step": 1186
    },
    {
      "epoch": 0.7929191716766867,
      "grad_norm": 1.8736308813095093,
      "learning_rate": 1.6746225989353128e-05,
      "loss": 0.0892,
      "step": 1187
    },
    {
      "epoch": 0.7935871743486974,
      "grad_norm": 2.303699254989624,
      "learning_rate": 1.674106066316137e-05,
      "loss": 0.1301,
      "step": 1188
    },
    {
      "epoch": 0.7942551770207081,
      "grad_norm": 2.417492151260376,
      "learning_rate": 1.6735892038276963e-05,
      "loss": 0.1163,
      "step": 1189
    },
    {
      "epoch": 0.7949231796927188,
      "grad_norm": 1.8354202508926392,
      "learning_rate": 1.6730720117229137e-05,
      "loss": 0.1289,
      "step": 1190
    },
    {
      "epoch": 0.7955911823647295,
      "grad_norm": 1.0107669830322266,
      "learning_rate": 1.6725544902548735e-05,
      "loss": 0.0177,
      "step": 1191
    },
    {
      "epoch": 0.7962591850367402,
      "grad_norm": 4.204709529876709,
      "learning_rate": 1.6720366396768214e-05,
      "loss": 0.1147,
      "step": 1192
    },
    {
      "epoch": 0.7969271877087508,
      "grad_norm": 1.872874140739441,
      "learning_rate": 1.6715184602421645e-05,
      "loss": 0.1612,
      "step": 1193
    },
    {
      "epoch": 0.7975951903807615,
      "grad_norm": 10.577641487121582,
      "learning_rate": 1.6709999522044696e-05,
      "loss": 0.356,
      "step": 1194
    },
    {
      "epoch": 0.7982631930527722,
      "grad_norm": 2.7864794731140137,
      "learning_rate": 1.6704811158174658e-05,
      "loss": 0.0305,
      "step": 1195
    },
    {
      "epoch": 0.7989311957247829,
      "grad_norm": 1.5534696578979492,
      "learning_rate": 1.669961951335042e-05,
      "loss": 0.1221,
      "step": 1196
    },
    {
      "epoch": 0.7995991983967936,
      "grad_norm": 0.12472677230834961,
      "learning_rate": 1.669442459011248e-05,
      "loss": 0.0019,
      "step": 1197
    },
    {
      "epoch": 0.8002672010688042,
      "grad_norm": 1.9308607578277588,
      "learning_rate": 1.6689226391002935e-05,
      "loss": 0.1,
      "step": 1198
    },
    {
      "epoch": 0.800935203740815,
      "grad_norm": 3.288147211074829,
      "learning_rate": 1.668402491856549e-05,
      "loss": 0.1931,
      "step": 1199
    },
    {
      "epoch": 0.8016032064128257,
      "grad_norm": 2.6684436798095703,
      "learning_rate": 1.6678820175345454e-05,
      "loss": 0.1349,
      "step": 1200
    },
    {
      "epoch": 0.8022712090848363,
      "grad_norm": 2.367077112197876,
      "learning_rate": 1.667361216388973e-05,
      "loss": 0.0937,
      "step": 1201
    },
    {
      "epoch": 0.802939211756847,
      "grad_norm": 1.95701003074646,
      "learning_rate": 1.6668400886746823e-05,
      "loss": 0.1685,
      "step": 1202
    },
    {
      "epoch": 0.8036072144288577,
      "grad_norm": 1.2566372156143188,
      "learning_rate": 1.6663186346466838e-05,
      "loss": 0.0412,
      "step": 1203
    },
    {
      "epoch": 0.8042752171008684,
      "grad_norm": 2.4481914043426514,
      "learning_rate": 1.6657968545601475e-05,
      "loss": 0.1247,
      "step": 1204
    },
    {
      "epoch": 0.8049432197728791,
      "grad_norm": 1.0752068758010864,
      "learning_rate": 1.665274748670403e-05,
      "loss": 0.02,
      "step": 1205
    },
    {
      "epoch": 0.8056112224448898,
      "grad_norm": 5.28615140914917,
      "learning_rate": 1.664752317232939e-05,
      "loss": 0.2031,
      "step": 1206
    },
    {
      "epoch": 0.8062792251169004,
      "grad_norm": 2.1169097423553467,
      "learning_rate": 1.664229560503404e-05,
      "loss": 0.1108,
      "step": 1207
    },
    {
      "epoch": 0.8069472277889111,
      "grad_norm": 14.9950532913208,
      "learning_rate": 1.6637064787376056e-05,
      "loss": 0.611,
      "step": 1208
    },
    {
      "epoch": 0.8076152304609219,
      "grad_norm": 2.537074327468872,
      "learning_rate": 1.6631830721915103e-05,
      "loss": 0.0688,
      "step": 1209
    },
    {
      "epoch": 0.8082832331329325,
      "grad_norm": 3.869852066040039,
      "learning_rate": 1.6626593411212434e-05,
      "loss": 0.2095,
      "step": 1210
    },
    {
      "epoch": 0.8089512358049432,
      "grad_norm": 3.476506233215332,
      "learning_rate": 1.6621352857830895e-05,
      "loss": 0.0371,
      "step": 1211
    },
    {
      "epoch": 0.8096192384769539,
      "grad_norm": 0.6887831687927246,
      "learning_rate": 1.661610906433491e-05,
      "loss": 0.0115,
      "step": 1212
    },
    {
      "epoch": 0.8102872411489646,
      "grad_norm": 0.6879953742027283,
      "learning_rate": 1.66108620332905e-05,
      "loss": 0.0085,
      "step": 1213
    },
    {
      "epoch": 0.8109552438209753,
      "grad_norm": 2.2923412322998047,
      "learning_rate": 1.660561176726526e-05,
      "loss": 0.1731,
      "step": 1214
    },
    {
      "epoch": 0.811623246492986,
      "grad_norm": 1.8771569728851318,
      "learning_rate": 1.6600358268828376e-05,
      "loss": 0.0396,
      "step": 1215
    },
    {
      "epoch": 0.8122912491649966,
      "grad_norm": 0.44773057103157043,
      "learning_rate": 1.659510154055061e-05,
      "loss": 0.0063,
      "step": 1216
    },
    {
      "epoch": 0.8129592518370073,
      "grad_norm": 0.25600528717041016,
      "learning_rate": 1.6589841585004305e-05,
      "loss": 0.0032,
      "step": 1217
    },
    {
      "epoch": 0.8136272545090181,
      "grad_norm": 10.573771476745605,
      "learning_rate": 1.6584578404763388e-05,
      "loss": 0.5419,
      "step": 1218
    },
    {
      "epoch": 0.8142952571810287,
      "grad_norm": 1.597883939743042,
      "learning_rate": 1.657931200240336e-05,
      "loss": 0.1528,
      "step": 1219
    },
    {
      "epoch": 0.8149632598530394,
      "grad_norm": 0.1705174297094345,
      "learning_rate": 1.6574042380501297e-05,
      "loss": 0.0029,
      "step": 1220
    },
    {
      "epoch": 0.8156312625250501,
      "grad_norm": 0.11743343621492386,
      "learning_rate": 1.6568769541635857e-05,
      "loss": 0.002,
      "step": 1221
    },
    {
      "epoch": 0.8162992651970608,
      "grad_norm": 1.823426604270935,
      "learning_rate": 1.656349348838726e-05,
      "loss": 0.1385,
      "step": 1222
    },
    {
      "epoch": 0.8169672678690715,
      "grad_norm": 10.39487075805664,
      "learning_rate": 1.655821422333732e-05,
      "loss": 0.6982,
      "step": 1223
    },
    {
      "epoch": 0.8176352705410822,
      "grad_norm": 7.853170394897461,
      "learning_rate": 1.6552931749069403e-05,
      "loss": 0.2405,
      "step": 1224
    },
    {
      "epoch": 0.8183032732130928,
      "grad_norm": 6.760189533233643,
      "learning_rate": 1.654764606816845e-05,
      "loss": 0.3021,
      "step": 1225
    },
    {
      "epoch": 0.8189712758851035,
      "grad_norm": 6.125988483428955,
      "learning_rate": 1.6542357183220977e-05,
      "loss": 0.2438,
      "step": 1226
    },
    {
      "epoch": 0.8196392785571143,
      "grad_norm": 1.392836093902588,
      "learning_rate": 1.6537065096815065e-05,
      "loss": 0.0963,
      "step": 1227
    },
    {
      "epoch": 0.8203072812291249,
      "grad_norm": 7.072016716003418,
      "learning_rate": 1.6531769811540354e-05,
      "loss": 0.1111,
      "step": 1228
    },
    {
      "epoch": 0.8209752839011356,
      "grad_norm": 1.593176245689392,
      "learning_rate": 1.6526471329988064e-05,
      "loss": 0.1723,
      "step": 1229
    },
    {
      "epoch": 0.8216432865731463,
      "grad_norm": 9.036494255065918,
      "learning_rate": 1.6521169654750968e-05,
      "loss": 0.3257,
      "step": 1230
    },
    {
      "epoch": 0.822311289245157,
      "grad_norm": 2.046050548553467,
      "learning_rate": 1.6515864788423404e-05,
      "loss": 0.181,
      "step": 1231
    },
    {
      "epoch": 0.8229792919171677,
      "grad_norm": 1.8602930307388306,
      "learning_rate": 1.6510556733601274e-05,
      "loss": 0.0295,
      "step": 1232
    },
    {
      "epoch": 0.8236472945891784,
      "grad_norm": 0.2986941337585449,
      "learning_rate": 1.6505245492882044e-05,
      "loss": 0.004,
      "step": 1233
    },
    {
      "epoch": 0.824315297261189,
      "grad_norm": 1.6547298431396484,
      "learning_rate": 1.649993106886472e-05,
      "loss": 0.171,
      "step": 1234
    },
    {
      "epoch": 0.8249832999331997,
      "grad_norm": 1.048560619354248,
      "learning_rate": 1.6494613464149893e-05,
      "loss": 0.1341,
      "step": 1235
    },
    {
      "epoch": 0.8256513026052105,
      "grad_norm": 0.717337429523468,
      "learning_rate": 1.6489292681339696e-05,
      "loss": 0.0102,
      "step": 1236
    },
    {
      "epoch": 0.8263193052772211,
      "grad_norm": 0.29057005047798157,
      "learning_rate": 1.648396872303781e-05,
      "loss": 0.0049,
      "step": 1237
    },
    {
      "epoch": 0.8269873079492318,
      "grad_norm": 0.3637083172798157,
      "learning_rate": 1.6478641591849483e-05,
      "loss": 0.0066,
      "step": 1238
    },
    {
      "epoch": 0.8276553106212425,
      "grad_norm": 3.328251361846924,
      "learning_rate": 1.647331129038151e-05,
      "loss": 0.0765,
      "step": 1239
    },
    {
      "epoch": 0.8283233132932531,
      "grad_norm": 10.58973217010498,
      "learning_rate": 1.6467977821242243e-05,
      "loss": 0.3721,
      "step": 1240
    },
    {
      "epoch": 0.8289913159652639,
      "grad_norm": 4.190792560577393,
      "learning_rate": 1.646264118704157e-05,
      "loss": 0.1769,
      "step": 1241
    },
    {
      "epoch": 0.8296593186372746,
      "grad_norm": 1.5868327617645264,
      "learning_rate": 1.6457301390390945e-05,
      "loss": 0.0772,
      "step": 1242
    },
    {
      "epoch": 0.8303273213092852,
      "grad_norm": 1.8937642574310303,
      "learning_rate": 1.6451958433903357e-05,
      "loss": 0.0204,
      "step": 1243
    },
    {
      "epoch": 0.8309953239812959,
      "grad_norm": 2.5864672660827637,
      "learning_rate": 1.6446612320193347e-05,
      "loss": 0.1305,
      "step": 1244
    },
    {
      "epoch": 0.8316633266533067,
      "grad_norm": 11.175813674926758,
      "learning_rate": 1.6441263051877e-05,
      "loss": 0.4741,
      "step": 1245
    },
    {
      "epoch": 0.8323313293253173,
      "grad_norm": 6.2353997230529785,
      "learning_rate": 1.6435910631571947e-05,
      "loss": 0.1895,
      "step": 1246
    },
    {
      "epoch": 0.832999331997328,
      "grad_norm": 1.3041175603866577,
      "learning_rate": 1.6430555061897355e-05,
      "loss": 0.1381,
      "step": 1247
    },
    {
      "epoch": 0.8336673346693386,
      "grad_norm": 2.148104190826416,
      "learning_rate": 1.6425196345473937e-05,
      "loss": 0.1542,
      "step": 1248
    },
    {
      "epoch": 0.8343353373413493,
      "grad_norm": 11.253426551818848,
      "learning_rate": 1.6419834484923948e-05,
      "loss": 0.5993,
      "step": 1249
    },
    {
      "epoch": 0.8350033400133601,
      "grad_norm": 2.72598934173584,
      "learning_rate": 1.641446948287117e-05,
      "loss": 0.1327,
      "step": 1250
    },
    {
      "epoch": 0.8356713426853707,
      "grad_norm": 3.1908376216888428,
      "learning_rate": 1.6409101341940937e-05,
      "loss": 0.1253,
      "step": 1251
    },
    {
      "epoch": 0.8363393453573814,
      "grad_norm": 0.6764958500862122,
      "learning_rate": 1.6403730064760116e-05,
      "loss": 0.0124,
      "step": 1252
    },
    {
      "epoch": 0.8370073480293921,
      "grad_norm": 1.4905741214752197,
      "learning_rate": 1.6398355653957095e-05,
      "loss": 0.111,
      "step": 1253
    },
    {
      "epoch": 0.8376753507014028,
      "grad_norm": 4.679947853088379,
      "learning_rate": 1.639297811216182e-05,
      "loss": 0.2565,
      "step": 1254
    },
    {
      "epoch": 0.8383433533734135,
      "grad_norm": 2.3121955394744873,
      "learning_rate": 1.638759744200574e-05,
      "loss": 0.1695,
      "step": 1255
    },
    {
      "epoch": 0.8390113560454242,
      "grad_norm": 0.2202616035938263,
      "learning_rate": 1.6382213646121858e-05,
      "loss": 0.0026,
      "step": 1256
    },
    {
      "epoch": 0.8396793587174348,
      "grad_norm": 3.4454891681671143,
      "learning_rate": 1.63768267271447e-05,
      "loss": 0.0652,
      "step": 1257
    },
    {
      "epoch": 0.8403473613894455,
      "grad_norm": 1.5840450525283813,
      "learning_rate": 1.637143668771031e-05,
      "loss": 0.1093,
      "step": 1258
    },
    {
      "epoch": 0.8410153640614563,
      "grad_norm": 4.78593635559082,
      "learning_rate": 1.6366043530456277e-05,
      "loss": 0.2609,
      "step": 1259
    },
    {
      "epoch": 0.8416833667334669,
      "grad_norm": 0.32116004824638367,
      "learning_rate": 1.6360647258021698e-05,
      "loss": 0.0053,
      "step": 1260
    },
    {
      "epoch": 0.8423513694054776,
      "grad_norm": 1.602439284324646,
      "learning_rate": 1.635524787304721e-05,
      "loss": 0.058,
      "step": 1261
    },
    {
      "epoch": 0.8430193720774883,
      "grad_norm": 2.0093812942504883,
      "learning_rate": 1.6349845378174956e-05,
      "loss": 0.134,
      "step": 1262
    },
    {
      "epoch": 0.843687374749499,
      "grad_norm": 3.1408956050872803,
      "learning_rate": 1.6344439776048624e-05,
      "loss": 0.1555,
      "step": 1263
    },
    {
      "epoch": 0.8443553774215097,
      "grad_norm": 0.48628658056259155,
      "learning_rate": 1.63390310693134e-05,
      "loss": 0.0076,
      "step": 1264
    },
    {
      "epoch": 0.8450233800935204,
      "grad_norm": 1.730178952217102,
      "learning_rate": 1.6333619260615996e-05,
      "loss": 0.0776,
      "step": 1265
    },
    {
      "epoch": 0.845691382765531,
      "grad_norm": 2.5876033306121826,
      "learning_rate": 1.6328204352604652e-05,
      "loss": 0.208,
      "step": 1266
    },
    {
      "epoch": 0.8463593854375417,
      "grad_norm": 0.21424134075641632,
      "learning_rate": 1.632278634792911e-05,
      "loss": 0.0032,
      "step": 1267
    },
    {
      "epoch": 0.8470273881095525,
      "grad_norm": 3.201702833175659,
      "learning_rate": 1.631736524924064e-05,
      "loss": 0.0668,
      "step": 1268
    },
    {
      "epoch": 0.8476953907815631,
      "grad_norm": 1.4276162385940552,
      "learning_rate": 1.6311941059192015e-05,
      "loss": 0.025,
      "step": 1269
    },
    {
      "epoch": 0.8483633934535738,
      "grad_norm": 2.242368459701538,
      "learning_rate": 1.6306513780437526e-05,
      "loss": 0.0797,
      "step": 1270
    },
    {
      "epoch": 0.8490313961255845,
      "grad_norm": 1.2291098833084106,
      "learning_rate": 1.630108341563298e-05,
      "loss": 0.0162,
      "step": 1271
    },
    {
      "epoch": 0.8496993987975952,
      "grad_norm": 7.2479400634765625,
      "learning_rate": 1.629564996743569e-05,
      "loss": 0.4536,
      "step": 1272
    },
    {
      "epoch": 0.8503674014696059,
      "grad_norm": 5.829669952392578,
      "learning_rate": 1.629021343850447e-05,
      "loss": 0.298,
      "step": 1273
    },
    {
      "epoch": 0.8510354041416166,
      "grad_norm": 2.0962984561920166,
      "learning_rate": 1.628477383149965e-05,
      "loss": 0.1845,
      "step": 1274
    },
    {
      "epoch": 0.8517034068136272,
      "grad_norm": 4.457149982452393,
      "learning_rate": 1.627933114908307e-05,
      "loss": 0.2345,
      "step": 1275
    },
    {
      "epoch": 0.8523714094856379,
      "grad_norm": 2.438744306564331,
      "learning_rate": 1.6273885393918072e-05,
      "loss": 0.1741,
      "step": 1276
    },
    {
      "epoch": 0.8530394121576487,
      "grad_norm": 1.8817588090896606,
      "learning_rate": 1.626843656866949e-05,
      "loss": 0.0628,
      "step": 1277
    },
    {
      "epoch": 0.8537074148296593,
      "grad_norm": 0.4916905164718628,
      "learning_rate": 1.626298467600368e-05,
      "loss": 0.008,
      "step": 1278
    },
    {
      "epoch": 0.85437541750167,
      "grad_norm": 0.3891969621181488,
      "learning_rate": 1.6257529718588482e-05,
      "loss": 0.0064,
      "step": 1279
    },
    {
      "epoch": 0.8550434201736807,
      "grad_norm": 4.900789737701416,
      "learning_rate": 1.6252071699093246e-05,
      "loss": 0.2713,
      "step": 1280
    },
    {
      "epoch": 0.8557114228456913,
      "grad_norm": 3.5972187519073486,
      "learning_rate": 1.6246610620188815e-05,
      "loss": 0.1702,
      "step": 1281
    },
    {
      "epoch": 0.8563794255177021,
      "grad_norm": 1.8489301204681396,
      "learning_rate": 1.6241146484547537e-05,
      "loss": 0.0275,
      "step": 1282
    },
    {
      "epoch": 0.8570474281897128,
      "grad_norm": 1.2307510375976562,
      "learning_rate": 1.6235679294843238e-05,
      "loss": 0.0804,
      "step": 1283
    },
    {
      "epoch": 0.8577154308617234,
      "grad_norm": 2.2504067420959473,
      "learning_rate": 1.623020905375126e-05,
      "loss": 0.1673,
      "step": 1284
    },
    {
      "epoch": 0.8583834335337341,
      "grad_norm": 0.8083796501159668,
      "learning_rate": 1.6224735763948434e-05,
      "loss": 0.0133,
      "step": 1285
    },
    {
      "epoch": 0.8590514362057449,
      "grad_norm": 4.37002420425415,
      "learning_rate": 1.621925942811306e-05,
      "loss": 0.1115,
      "step": 1286
    },
    {
      "epoch": 0.8597194388777555,
      "grad_norm": 3.096499443054199,
      "learning_rate": 1.6213780048924964e-05,
      "loss": 0.1519,
      "step": 1287
    },
    {
      "epoch": 0.8603874415497662,
      "grad_norm": 2.5251801013946533,
      "learning_rate": 1.620829762906543e-05,
      "loss": 0.0882,
      "step": 1288
    },
    {
      "epoch": 0.8610554442217769,
      "grad_norm": 1.8319275379180908,
      "learning_rate": 1.620281217121725e-05,
      "loss": 0.171,
      "step": 1289
    },
    {
      "epoch": 0.8617234468937875,
      "grad_norm": 2.798524856567383,
      "learning_rate": 1.61973236780647e-05,
      "loss": 0.1445,
      "step": 1290
    },
    {
      "epoch": 0.8623914495657983,
      "grad_norm": 0.4649612009525299,
      "learning_rate": 1.6191832152293523e-05,
      "loss": 0.0054,
      "step": 1291
    },
    {
      "epoch": 0.863059452237809,
      "grad_norm": 1.4251680374145508,
      "learning_rate": 1.6186337596590972e-05,
      "loss": 0.0943,
      "step": 1292
    },
    {
      "epoch": 0.8637274549098196,
      "grad_norm": 4.274324417114258,
      "learning_rate": 1.618084001364577e-05,
      "loss": 0.1868,
      "step": 1293
    },
    {
      "epoch": 0.8643954575818303,
      "grad_norm": 3.136631727218628,
      "learning_rate": 1.6175339406148118e-05,
      "loss": 0.1785,
      "step": 1294
    },
    {
      "epoch": 0.8650634602538411,
      "grad_norm": 5.776413440704346,
      "learning_rate": 1.6169835776789706e-05,
      "loss": 0.2277,
      "step": 1295
    },
    {
      "epoch": 0.8657314629258517,
      "grad_norm": 2.141829490661621,
      "learning_rate": 1.616432912826369e-05,
      "loss": 0.1754,
      "step": 1296
    },
    {
      "epoch": 0.8663994655978624,
      "grad_norm": 0.6134113669395447,
      "learning_rate": 1.6158819463264718e-05,
      "loss": 0.0081,
      "step": 1297
    },
    {
      "epoch": 0.8670674682698731,
      "grad_norm": 3.292785167694092,
      "learning_rate": 1.615330678448891e-05,
      "loss": 0.2246,
      "step": 1298
    },
    {
      "epoch": 0.8677354709418837,
      "grad_norm": 8.577781677246094,
      "learning_rate": 1.614779109463385e-05,
      "loss": 0.2674,
      "step": 1299
    },
    {
      "epoch": 0.8684034736138945,
      "grad_norm": 3.065678358078003,
      "learning_rate": 1.6142272396398612e-05,
      "loss": 0.1699,
      "step": 1300
    },
    {
      "epoch": 0.8690714762859052,
      "grad_norm": 0.051264435052871704,
      "learning_rate": 1.6136750692483727e-05,
      "loss": 0.0009,
      "step": 1301
    },
    {
      "epoch": 0.8697394789579158,
      "grad_norm": 0.25994351506233215,
      "learning_rate": 1.6131225985591207e-05,
      "loss": 0.0036,
      "step": 1302
    },
    {
      "epoch": 0.8704074816299265,
      "grad_norm": 0.36053532361984253,
      "learning_rate": 1.612569827842453e-05,
      "loss": 0.0064,
      "step": 1303
    },
    {
      "epoch": 0.8710754843019372,
      "grad_norm": 1.207548975944519,
      "learning_rate": 1.6120167573688637e-05,
      "loss": 0.1427,
      "step": 1304
    },
    {
      "epoch": 0.8717434869739479,
      "grad_norm": 1.814775824546814,
      "learning_rate": 1.6114633874089955e-05,
      "loss": 0.1272,
      "step": 1305
    },
    {
      "epoch": 0.8724114896459586,
      "grad_norm": 1.1739470958709717,
      "learning_rate": 1.6109097182336347e-05,
      "loss": 0.1064,
      "step": 1306
    },
    {
      "epoch": 0.8730794923179692,
      "grad_norm": 0.3528321087360382,
      "learning_rate": 1.6103557501137165e-05,
      "loss": 0.0052,
      "step": 1307
    },
    {
      "epoch": 0.87374749498998,
      "grad_norm": 5.819278717041016,
      "learning_rate": 1.6098014833203212e-05,
      "loss": 0.2398,
      "step": 1308
    },
    {
      "epoch": 0.8744154976619907,
      "grad_norm": 6.702054023742676,
      "learning_rate": 1.6092469181246752e-05,
      "loss": 0.261,
      "step": 1309
    },
    {
      "epoch": 0.8750835003340013,
      "grad_norm": 0.18187299370765686,
      "learning_rate": 1.608692054798152e-05,
      "loss": 0.0025,
      "step": 1310
    },
    {
      "epoch": 0.875751503006012,
      "grad_norm": 2.235818862915039,
      "learning_rate": 1.6081368936122698e-05,
      "loss": 0.1426,
      "step": 1311
    },
    {
      "epoch": 0.8764195056780227,
      "grad_norm": 1.1571389436721802,
      "learning_rate": 1.607581434838693e-05,
      "loss": 0.1097,
      "step": 1312
    },
    {
      "epoch": 0.8770875083500334,
      "grad_norm": 0.39340704679489136,
      "learning_rate": 1.6070256787492312e-05,
      "loss": 0.0048,
      "step": 1313
    },
    {
      "epoch": 0.8777555110220441,
      "grad_norm": 1.9762135744094849,
      "learning_rate": 1.6064696256158408e-05,
      "loss": 0.1039,
      "step": 1314
    },
    {
      "epoch": 0.8784235136940548,
      "grad_norm": 2.4089601039886475,
      "learning_rate": 1.6059132757106218e-05,
      "loss": 0.0518,
      "step": 1315
    },
    {
      "epoch": 0.8790915163660654,
      "grad_norm": 0.2995152771472931,
      "learning_rate": 1.605356629305821e-05,
      "loss": 0.0052,
      "step": 1316
    },
    {
      "epoch": 0.8797595190380761,
      "grad_norm": 1.3680638074874878,
      "learning_rate": 1.604799686673829e-05,
      "loss": 0.0693,
      "step": 1317
    },
    {
      "epoch": 0.8804275217100869,
      "grad_norm": 0.9908285737037659,
      "learning_rate": 1.6042424480871822e-05,
      "loss": 0.0112,
      "step": 1318
    },
    {
      "epoch": 0.8810955243820975,
      "grad_norm": 1.1202009916305542,
      "learning_rate": 1.6036849138185615e-05,
      "loss": 0.1143,
      "step": 1319
    },
    {
      "epoch": 0.8817635270541082,
      "grad_norm": 0.31883904337882996,
      "learning_rate": 1.6031270841407928e-05,
      "loss": 0.0033,
      "step": 1320
    },
    {
      "epoch": 0.8824315297261189,
      "grad_norm": 0.9510502815246582,
      "learning_rate": 1.6025689593268457e-05,
      "loss": 0.0133,
      "step": 1321
    },
    {
      "epoch": 0.8830995323981295,
      "grad_norm": 3.4568872451782227,
      "learning_rate": 1.602010539649835e-05,
      "loss": 0.204,
      "step": 1322
    },
    {
      "epoch": 0.8837675350701403,
      "grad_norm": 2.993105173110962,
      "learning_rate": 1.6014518253830204e-05,
      "loss": 0.1234,
      "step": 1323
    },
    {
      "epoch": 0.884435537742151,
      "grad_norm": 0.3093501329421997,
      "learning_rate": 1.600892816799804e-05,
      "loss": 0.0035,
      "step": 1324
    },
    {
      "epoch": 0.8851035404141616,
      "grad_norm": 8.02148723602295,
      "learning_rate": 1.6003335141737332e-05,
      "loss": 0.247,
      "step": 1325
    },
    {
      "epoch": 0.8857715430861723,
      "grad_norm": 1.7977797985076904,
      "learning_rate": 1.5997739177784986e-05,
      "loss": 0.1063,
      "step": 1326
    },
    {
      "epoch": 0.8864395457581831,
      "grad_norm": 1.5471038818359375,
      "learning_rate": 1.599214027887936e-05,
      "loss": 0.0213,
      "step": 1327
    },
    {
      "epoch": 0.8871075484301937,
      "grad_norm": 0.06055891513824463,
      "learning_rate": 1.5986538447760228e-05,
      "loss": 0.001,
      "step": 1328
    },
    {
      "epoch": 0.8877755511022044,
      "grad_norm": 2.2756266593933105,
      "learning_rate": 1.5980933687168812e-05,
      "loss": 0.1682,
      "step": 1329
    },
    {
      "epoch": 0.8884435537742151,
      "grad_norm": 7.635619163513184,
      "learning_rate": 1.5975325999847758e-05,
      "loss": 0.1451,
      "step": 1330
    },
    {
      "epoch": 0.8891115564462257,
      "grad_norm": 3.0092217922210693,
      "learning_rate": 1.596971538854116e-05,
      "loss": 0.1504,
      "step": 1331
    },
    {
      "epoch": 0.8897795591182365,
      "grad_norm": 4.014025688171387,
      "learning_rate": 1.5964101855994527e-05,
      "loss": 0.236,
      "step": 1332
    },
    {
      "epoch": 0.8904475617902472,
      "grad_norm": 3.4854490756988525,
      "learning_rate": 1.5958485404954806e-05,
      "loss": 0.1839,
      "step": 1333
    },
    {
      "epoch": 0.8911155644622578,
      "grad_norm": 8.531368255615234,
      "learning_rate": 1.5952866038170362e-05,
      "loss": 0.2174,
      "step": 1334
    },
    {
      "epoch": 0.8917835671342685,
      "grad_norm": 4.871253490447998,
      "learning_rate": 1.5947243758391007e-05,
      "loss": 0.287,
      "step": 1335
    },
    {
      "epoch": 0.8924515698062793,
      "grad_norm": 0.12561599910259247,
      "learning_rate": 1.5941618568367953e-05,
      "loss": 0.0017,
      "step": 1336
    },
    {
      "epoch": 0.8931195724782899,
      "grad_norm": 14.034276962280273,
      "learning_rate": 1.5935990470853856e-05,
      "loss": 0.5806,
      "step": 1337
    },
    {
      "epoch": 0.8937875751503006,
      "grad_norm": 0.843168318271637,
      "learning_rate": 1.593035946860279e-05,
      "loss": 0.0144,
      "step": 1338
    },
    {
      "epoch": 0.8944555778223113,
      "grad_norm": 0.7976597547531128,
      "learning_rate": 1.592472556437024e-05,
      "loss": 0.0091,
      "step": 1339
    },
    {
      "epoch": 0.895123580494322,
      "grad_norm": 0.7162695527076721,
      "learning_rate": 1.5919088760913127e-05,
      "loss": 0.0108,
      "step": 1340
    },
    {
      "epoch": 0.8957915831663327,
      "grad_norm": 0.905584990978241,
      "learning_rate": 1.5913449060989777e-05,
      "loss": 0.0086,
      "step": 1341
    },
    {
      "epoch": 0.8964595858383434,
      "grad_norm": 3.911975622177124,
      "learning_rate": 1.590780646735994e-05,
      "loss": 0.1325,
      "step": 1342
    },
    {
      "epoch": 0.897127588510354,
      "grad_norm": 0.07975305616855621,
      "learning_rate": 1.5902160982784785e-05,
      "loss": 0.0011,
      "step": 1343
    },
    {
      "epoch": 0.8977955911823647,
      "grad_norm": 1.2311490774154663,
      "learning_rate": 1.589651261002689e-05,
      "loss": 0.1002,
      "step": 1344
    },
    {
      "epoch": 0.8984635938543755,
      "grad_norm": 0.22829051315784454,
      "learning_rate": 1.5890861351850243e-05,
      "loss": 0.0026,
      "step": 1345
    },
    {
      "epoch": 0.8991315965263861,
      "grad_norm": 3.1899702548980713,
      "learning_rate": 1.588520721102026e-05,
      "loss": 0.136,
      "step": 1346
    },
    {
      "epoch": 0.8997995991983968,
      "grad_norm": 9.02575969696045,
      "learning_rate": 1.587955019030375e-05,
      "loss": 0.084,
      "step": 1347
    },
    {
      "epoch": 0.9004676018704075,
      "grad_norm": 7.575737953186035,
      "learning_rate": 1.5873890292468933e-05,
      "loss": 0.3109,
      "step": 1348
    },
    {
      "epoch": 0.9011356045424181,
      "grad_norm": 0.10085764527320862,
      "learning_rate": 1.586822752028545e-05,
      "loss": 0.0018,
      "step": 1349
    },
    {
      "epoch": 0.9018036072144289,
      "grad_norm": 1.0509551763534546,
      "learning_rate": 1.5862561876524337e-05,
      "loss": 0.013,
      "step": 1350
    },
    {
      "epoch": 0.9024716098864396,
      "grad_norm": 3.2822775840759277,
      "learning_rate": 1.5856893363958045e-05,
      "loss": 0.1127,
      "step": 1351
    },
    {
      "epoch": 0.9031396125584502,
      "grad_norm": 4.6910295486450195,
      "learning_rate": 1.5851221985360413e-05,
      "loss": 0.1216,
      "step": 1352
    },
    {
      "epoch": 0.9038076152304609,
      "grad_norm": 2.651163101196289,
      "learning_rate": 1.5845547743506694e-05,
      "loss": 0.1107,
      "step": 1353
    },
    {
      "epoch": 0.9044756179024717,
      "grad_norm": 3.5558955669403076,
      "learning_rate": 1.583987064117354e-05,
      "loss": 0.1864,
      "step": 1354
    },
    {
      "epoch": 0.9051436205744823,
      "grad_norm": 0.24961800873279572,
      "learning_rate": 1.5834190681139015e-05,
      "loss": 0.0033,
      "step": 1355
    },
    {
      "epoch": 0.905811623246493,
      "grad_norm": 4.106276512145996,
      "learning_rate": 1.582850786618255e-05,
      "loss": 0.1008,
      "step": 1356
    },
    {
      "epoch": 0.9064796259185037,
      "grad_norm": 1.7230422496795654,
      "learning_rate": 1.5822822199085005e-05,
      "loss": 0.0235,
      "step": 1357
    },
    {
      "epoch": 0.9071476285905143,
      "grad_norm": 4.095830917358398,
      "learning_rate": 1.5817133682628618e-05,
      "loss": 0.1668,
      "step": 1358
    },
    {
      "epoch": 0.9078156312625251,
      "grad_norm": 8.536227226257324,
      "learning_rate": 1.5811442319597028e-05,
      "loss": 0.3471,
      "step": 1359
    },
    {
      "epoch": 0.9084836339345357,
      "grad_norm": 1.8373616933822632,
      "learning_rate": 1.5805748112775266e-05,
      "loss": 0.0186,
      "step": 1360
    },
    {
      "epoch": 0.9091516366065464,
      "grad_norm": 14.476831436157227,
      "learning_rate": 1.5800051064949752e-05,
      "loss": 0.3269,
      "step": 1361
    },
    {
      "epoch": 0.9098196392785571,
      "grad_norm": 0.10905583947896957,
      "learning_rate": 1.5794351178908295e-05,
      "loss": 0.0018,
      "step": 1362
    },
    {
      "epoch": 0.9104876419505677,
      "grad_norm": 1.4109066724777222,
      "learning_rate": 1.57886484574401e-05,
      "loss": 0.1589,
      "step": 1363
    },
    {
      "epoch": 0.9111556446225785,
      "grad_norm": 7.673099040985107,
      "learning_rate": 1.5782942903335755e-05,
      "loss": 0.2591,
      "step": 1364
    },
    {
      "epoch": 0.9118236472945892,
      "grad_norm": 0.07524128258228302,
      "learning_rate": 1.5777234519387235e-05,
      "loss": 0.0013,
      "step": 1365
    },
    {
      "epoch": 0.9124916499665998,
      "grad_norm": 8.272115707397461,
      "learning_rate": 1.5771523308387897e-05,
      "loss": 0.2253,
      "step": 1366
    },
    {
      "epoch": 0.9131596526386105,
      "grad_norm": 0.06604199856519699,
      "learning_rate": 1.5765809273132488e-05,
      "loss": 0.001,
      "step": 1367
    },
    {
      "epoch": 0.9138276553106213,
      "grad_norm": 0.15434381365776062,
      "learning_rate": 1.5760092416417124e-05,
      "loss": 0.0019,
      "step": 1368
    },
    {
      "epoch": 0.9144956579826319,
      "grad_norm": 0.32475247979164124,
      "learning_rate": 1.575437274103932e-05,
      "loss": 0.0041,
      "step": 1369
    },
    {
      "epoch": 0.9151636606546426,
      "grad_norm": 2.2939841747283936,
      "learning_rate": 1.5748650249797955e-05,
      "loss": 0.1459,
      "step": 1370
    },
    {
      "epoch": 0.9158316633266533,
      "grad_norm": 2.773616075515747,
      "learning_rate": 1.5742924945493297e-05,
      "loss": 0.1269,
      "step": 1371
    },
    {
      "epoch": 0.916499665998664,
      "grad_norm": 0.5778864622116089,
      "learning_rate": 1.5737196830926976e-05,
      "loss": 0.0077,
      "step": 1372
    },
    {
      "epoch": 0.9171676686706747,
      "grad_norm": 4.994695663452148,
      "learning_rate": 1.5731465908902017e-05,
      "loss": 0.1666,
      "step": 1373
    },
    {
      "epoch": 0.9178356713426854,
      "grad_norm": 0.21150946617126465,
      "learning_rate": 1.57257321822228e-05,
      "loss": 0.0023,
      "step": 1374
    },
    {
      "epoch": 0.918503674014696,
      "grad_norm": 2.4478342533111572,
      "learning_rate": 1.5719995653695087e-05,
      "loss": 0.1651,
      "step": 1375
    },
    {
      "epoch": 0.9191716766867067,
      "grad_norm": 6.915299892425537,
      "learning_rate": 1.571425632612601e-05,
      "loss": 0.1826,
      "step": 1376
    },
    {
      "epoch": 0.9198396793587175,
      "grad_norm": 0.12015143036842346,
      "learning_rate": 1.5708514202324074e-05,
      "loss": 0.0014,
      "step": 1377
    },
    {
      "epoch": 0.9205076820307281,
      "grad_norm": 2.2154629230499268,
      "learning_rate": 1.5702769285099147e-05,
      "loss": 0.075,
      "step": 1378
    },
    {
      "epoch": 0.9211756847027388,
      "grad_norm": 6.8190436363220215,
      "learning_rate": 1.569702157726246e-05,
      "loss": 0.235,
      "step": 1379
    },
    {
      "epoch": 0.9218436873747495,
      "grad_norm": 0.09173706918954849,
      "learning_rate": 1.569127108162662e-05,
      "loss": 0.001,
      "step": 1380
    },
    {
      "epoch": 0.9225116900467601,
      "grad_norm": 2.550787925720215,
      "learning_rate": 1.5685517801005598e-05,
      "loss": 0.1316,
      "step": 1381
    },
    {
      "epoch": 0.9231796927187709,
      "grad_norm": 4.922097682952881,
      "learning_rate": 1.5679761738214714e-05,
      "loss": 0.2379,
      "step": 1382
    },
    {
      "epoch": 0.9238476953907816,
      "grad_norm": 0.2717319428920746,
      "learning_rate": 1.567400289607066e-05,
      "loss": 0.0025,
      "step": 1383
    },
    {
      "epoch": 0.9245156980627922,
      "grad_norm": 18.72948455810547,
      "learning_rate": 1.5668241277391492e-05,
      "loss": 0.4663,
      "step": 1384
    },
    {
      "epoch": 0.9251837007348029,
      "grad_norm": 0.06225886940956116,
      "learning_rate": 1.5662476884996617e-05,
      "loss": 0.0008,
      "step": 1385
    },
    {
      "epoch": 0.9258517034068137,
      "grad_norm": 3.1941750049591064,
      "learning_rate": 1.56567097217068e-05,
      "loss": 0.2224,
      "step": 1386
    },
    {
      "epoch": 0.9265197060788243,
      "grad_norm": 2.397325277328491,
      "learning_rate": 1.5650939790344166e-05,
      "loss": 0.1698,
      "step": 1387
    },
    {
      "epoch": 0.927187708750835,
      "grad_norm": 0.7242582440376282,
      "learning_rate": 1.564516709373219e-05,
      "loss": 0.006,
      "step": 1388
    },
    {
      "epoch": 0.9278557114228457,
      "grad_norm": 1.6839003562927246,
      "learning_rate": 1.56393916346957e-05,
      "loss": 0.0822,
      "step": 1389
    },
    {
      "epoch": 0.9285237140948563,
      "grad_norm": 1.478785514831543,
      "learning_rate": 1.5633613416060884e-05,
      "loss": 0.1662,
      "step": 1390
    },
    {
      "epoch": 0.9291917167668671,
      "grad_norm": 7.781088352203369,
      "learning_rate": 1.562783244065527e-05,
      "loss": 0.2673,
      "step": 1391
    },
    {
      "epoch": 0.9298597194388778,
      "grad_norm": 2.326606512069702,
      "learning_rate": 1.5622048711307744e-05,
      "loss": 0.1282,
      "step": 1392
    },
    {
      "epoch": 0.9305277221108884,
      "grad_norm": 2.0879530906677246,
      "learning_rate": 1.5616262230848527e-05,
      "loss": 0.0948,
      "step": 1393
    },
    {
      "epoch": 0.9311957247828991,
      "grad_norm": 1.9986590147018433,
      "learning_rate": 1.5610473002109202e-05,
      "loss": 0.1274,
      "step": 1394
    },
    {
      "epoch": 0.9318637274549099,
      "grad_norm": 21.798789978027344,
      "learning_rate": 1.5604681027922686e-05,
      "loss": 0.9256,
      "step": 1395
    },
    {
      "epoch": 0.9325317301269205,
      "grad_norm": 8.599531173706055,
      "learning_rate": 1.559888631112324e-05,
      "loss": 0.3611,
      "step": 1396
    },
    {
      "epoch": 0.9331997327989312,
      "grad_norm": 4.784231185913086,
      "learning_rate": 1.5593088854546474e-05,
      "loss": 0.2555,
      "step": 1397
    },
    {
      "epoch": 0.9338677354709419,
      "grad_norm": 2.295400857925415,
      "learning_rate": 1.5587288661029333e-05,
      "loss": 0.1296,
      "step": 1398
    },
    {
      "epoch": 0.9345357381429525,
      "grad_norm": 1.3991419076919556,
      "learning_rate": 1.55814857334101e-05,
      "loss": 0.0199,
      "step": 1399
    },
    {
      "epoch": 0.9352037408149633,
      "grad_norm": 0.12130805850028992,
      "learning_rate": 1.5575680074528406e-05,
      "loss": 0.0015,
      "step": 1400
    },
    {
      "epoch": 0.935871743486974,
      "grad_norm": 5.889462471008301,
      "learning_rate": 1.5569871687225198e-05,
      "loss": 0.2758,
      "step": 1401
    },
    {
      "epoch": 0.9365397461589846,
      "grad_norm": 0.2635367810726166,
      "learning_rate": 1.5564060574342785e-05,
      "loss": 0.0035,
      "step": 1402
    },
    {
      "epoch": 0.9372077488309953,
      "grad_norm": 0.03680087998509407,
      "learning_rate": 1.5558246738724788e-05,
      "loss": 0.0008,
      "step": 1403
    },
    {
      "epoch": 0.9378757515030061,
      "grad_norm": 0.09799843281507492,
      "learning_rate": 1.5552430183216173e-05,
      "loss": 0.0015,
      "step": 1404
    },
    {
      "epoch": 0.9385437541750167,
      "grad_norm": 4.409011363983154,
      "learning_rate": 1.5546610910663226e-05,
      "loss": 0.1666,
      "step": 1405
    },
    {
      "epoch": 0.9392117568470274,
      "grad_norm": 2.787745952606201,
      "learning_rate": 1.5540788923913573e-05,
      "loss": 0.1642,
      "step": 1406
    },
    {
      "epoch": 0.9398797595190381,
      "grad_norm": 2.2168166637420654,
      "learning_rate": 1.5534964225816166e-05,
      "loss": 0.02,
      "step": 1407
    },
    {
      "epoch": 0.9405477621910487,
      "grad_norm": 2.0381200313568115,
      "learning_rate": 1.552913681922128e-05,
      "loss": 0.1563,
      "step": 1408
    },
    {
      "epoch": 0.9412157648630595,
      "grad_norm": 3.9984350204467773,
      "learning_rate": 1.5523306706980516e-05,
      "loss": 0.1754,
      "step": 1409
    },
    {
      "epoch": 0.9418837675350702,
      "grad_norm": 1.5034465789794922,
      "learning_rate": 1.55174738919468e-05,
      "loss": 0.1394,
      "step": 1410
    },
    {
      "epoch": 0.9425517702070808,
      "grad_norm": 2.958197593688965,
      "learning_rate": 1.5511638376974378e-05,
      "loss": 0.1671,
      "step": 1411
    },
    {
      "epoch": 0.9432197728790915,
      "grad_norm": 0.1669229418039322,
      "learning_rate": 1.5505800164918826e-05,
      "loss": 0.0022,
      "step": 1412
    },
    {
      "epoch": 0.9438877755511023,
      "grad_norm": 4.564793586730957,
      "learning_rate": 1.5499959258637033e-05,
      "loss": 0.2371,
      "step": 1413
    },
    {
      "epoch": 0.9445557782231129,
      "grad_norm": 2.2497987747192383,
      "learning_rate": 1.5494115660987204e-05,
      "loss": 0.1588,
      "step": 1414
    },
    {
      "epoch": 0.9452237808951236,
      "grad_norm": 1.3336079120635986,
      "learning_rate": 1.5488269374828865e-05,
      "loss": 0.1301,
      "step": 1415
    },
    {
      "epoch": 0.9458917835671342,
      "grad_norm": 1.795838475227356,
      "learning_rate": 1.5482420403022858e-05,
      "loss": 0.1212,
      "step": 1416
    },
    {
      "epoch": 0.9465597862391449,
      "grad_norm": 0.05026973411440849,
      "learning_rate": 1.5476568748431335e-05,
      "loss": 0.0013,
      "step": 1417
    },
    {
      "epoch": 0.9472277889111557,
      "grad_norm": 2.6707403659820557,
      "learning_rate": 1.547071441391777e-05,
      "loss": 0.1926,
      "step": 1418
    },
    {
      "epoch": 0.9478957915831663,
      "grad_norm": 2.000725030899048,
      "learning_rate": 1.5464857402346936e-05,
      "loss": 0.1508,
      "step": 1419
    },
    {
      "epoch": 0.948563794255177,
      "grad_norm": 0.1352572739124298,
      "learning_rate": 1.5458997716584924e-05,
      "loss": 0.0016,
      "step": 1420
    },
    {
      "epoch": 0.9492317969271877,
      "grad_norm": 2.407068967819214,
      "learning_rate": 1.545313535949913e-05,
      "loss": 0.1565,
      "step": 1421
    },
    {
      "epoch": 0.9498997995991983,
      "grad_norm": 2.4264698028564453,
      "learning_rate": 1.5447270333958265e-05,
      "loss": 0.1509,
      "step": 1422
    },
    {
      "epoch": 0.9505678022712091,
      "grad_norm": 1.8850340843200684,
      "learning_rate": 1.5441402642832338e-05,
      "loss": 0.1423,
      "step": 1423
    },
    {
      "epoch": 0.9512358049432198,
      "grad_norm": 1.5284347534179688,
      "learning_rate": 1.5435532288992655e-05,
      "loss": 0.109,
      "step": 1424
    },
    {
      "epoch": 0.9519038076152304,
      "grad_norm": 2.462796449661255,
      "learning_rate": 1.5429659275311847e-05,
      "loss": 0.1563,
      "step": 1425
    },
    {
      "epoch": 0.9525718102872411,
      "grad_norm": 2.5002217292785645,
      "learning_rate": 1.542378360466383e-05,
      "loss": 0.2035,
      "step": 1426
    },
    {
      "epoch": 0.9532398129592519,
      "grad_norm": 0.2211715281009674,
      "learning_rate": 1.5417905279923817e-05,
      "loss": 0.0024,
      "step": 1427
    },
    {
      "epoch": 0.9539078156312625,
      "grad_norm": 1.0459309816360474,
      "learning_rate": 1.541202430396833e-05,
      "loss": 0.0088,
      "step": 1428
    },
    {
      "epoch": 0.9545758183032732,
      "grad_norm": 8.47717571258545,
      "learning_rate": 1.540614067967519e-05,
      "loss": 0.3205,
      "step": 1429
    },
    {
      "epoch": 0.9552438209752839,
      "grad_norm": 2.263587236404419,
      "learning_rate": 1.5400254409923505e-05,
      "loss": 0.1361,
      "step": 1430
    },
    {
      "epoch": 0.9559118236472945,
      "grad_norm": 9.39055061340332,
      "learning_rate": 1.5394365497593683e-05,
      "loss": 0.3949,
      "step": 1431
    },
    {
      "epoch": 0.9565798263193053,
      "grad_norm": 2.1242332458496094,
      "learning_rate": 1.5388473945567415e-05,
      "loss": 0.1254,
      "step": 1432
    },
    {
      "epoch": 0.957247828991316,
      "grad_norm": 3.979557752609253,
      "learning_rate": 1.538257975672771e-05,
      "loss": 0.0904,
      "step": 1433
    },
    {
      "epoch": 0.9579158316633266,
      "grad_norm": 1.6620615720748901,
      "learning_rate": 1.537668293395883e-05,
      "loss": 0.14,
      "step": 1434
    },
    {
      "epoch": 0.9585838343353373,
      "grad_norm": 0.047445569187402725,
      "learning_rate": 1.5370783480146364e-05,
      "loss": 0.0009,
      "step": 1435
    },
    {
      "epoch": 0.9592518370073481,
      "grad_norm": 1.5262857675552368,
      "learning_rate": 1.5364881398177155e-05,
      "loss": 0.1588,
      "step": 1436
    },
    {
      "epoch": 0.9599198396793587,
      "grad_norm": 1.8236488103866577,
      "learning_rate": 1.5358976690939355e-05,
      "loss": 0.1248,
      "step": 1437
    },
    {
      "epoch": 0.9605878423513694,
      "grad_norm": 2.0631532669067383,
      "learning_rate": 1.5353069361322387e-05,
      "loss": 0.0361,
      "step": 1438
    },
    {
      "epoch": 0.9612558450233801,
      "grad_norm": 3.4015183448791504,
      "learning_rate": 1.534715941221697e-05,
      "loss": 0.0658,
      "step": 1439
    },
    {
      "epoch": 0.9619238476953907,
      "grad_norm": 0.19910824298858643,
      "learning_rate": 1.5341246846515096e-05,
      "loss": 0.003,
      "step": 1440
    },
    {
      "epoch": 0.9625918503674015,
      "grad_norm": 2.8200490474700928,
      "learning_rate": 1.5335331667110037e-05,
      "loss": 0.2006,
      "step": 1441
    },
    {
      "epoch": 0.9632598530394122,
      "grad_norm": 2.9970977306365967,
      "learning_rate": 1.5329413876896346e-05,
      "loss": 0.2142,
      "step": 1442
    },
    {
      "epoch": 0.9639278557114228,
      "grad_norm": 4.819565773010254,
      "learning_rate": 1.532349347876985e-05,
      "loss": 0.2075,
      "step": 1443
    },
    {
      "epoch": 0.9645958583834335,
      "grad_norm": 2.2798502445220947,
      "learning_rate": 1.5317570475627667e-05,
      "loss": 0.1154,
      "step": 1444
    },
    {
      "epoch": 0.9652638610554443,
      "grad_norm": 2.0227792263031006,
      "learning_rate": 1.531164487036817e-05,
      "loss": 0.1143,
      "step": 1445
    },
    {
      "epoch": 0.9659318637274549,
      "grad_norm": 1.6026405096054077,
      "learning_rate": 1.530571666589102e-05,
      "loss": 0.0174,
      "step": 1446
    },
    {
      "epoch": 0.9665998663994656,
      "grad_norm": 8.956644058227539,
      "learning_rate": 1.5299785865097136e-05,
      "loss": 0.3123,
      "step": 1447
    },
    {
      "epoch": 0.9672678690714763,
      "grad_norm": 0.266593873500824,
      "learning_rate": 1.529385247088872e-05,
      "loss": 0.0032,
      "step": 1448
    },
    {
      "epoch": 0.9679358717434869,
      "grad_norm": 2.422560453414917,
      "learning_rate": 1.528791648616924e-05,
      "loss": 0.1682,
      "step": 1449
    },
    {
      "epoch": 0.9686038744154977,
      "grad_norm": 0.09254491329193115,
      "learning_rate": 1.528197791384343e-05,
      "loss": 0.0012,
      "step": 1450
    },
    {
      "epoch": 0.9692718770875084,
      "grad_norm": 2.6062400341033936,
      "learning_rate": 1.5276036756817287e-05,
      "loss": 0.1756,
      "step": 1451
    },
    {
      "epoch": 0.969939879759519,
      "grad_norm": 1.2745205163955688,
      "learning_rate": 1.5270093017998077e-05,
      "loss": 0.1209,
      "step": 1452
    },
    {
      "epoch": 0.9706078824315297,
      "grad_norm": 0.8564271330833435,
      "learning_rate": 1.5264146700294333e-05,
      "loss": 0.013,
      "step": 1453
    },
    {
      "epoch": 0.9712758851035405,
      "grad_norm": 1.5268243551254272,
      "learning_rate": 1.5258197806615838e-05,
      "loss": 0.152,
      "step": 1454
    },
    {
      "epoch": 0.9719438877755511,
      "grad_norm": 2.0271730422973633,
      "learning_rate": 1.5252246339873646e-05,
      "loss": 0.0421,
      "step": 1455
    },
    {
      "epoch": 0.9726118904475618,
      "grad_norm": 2.483884572982788,
      "learning_rate": 1.5246292302980075e-05,
      "loss": 0.1928,
      "step": 1456
    },
    {
      "epoch": 0.9732798931195725,
      "grad_norm": 2.116872549057007,
      "learning_rate": 1.5240335698848683e-05,
      "loss": 0.0642,
      "step": 1457
    },
    {
      "epoch": 0.9739478957915831,
      "grad_norm": 1.9767403602600098,
      "learning_rate": 1.5234376530394297e-05,
      "loss": 0.1683,
      "step": 1458
    },
    {
      "epoch": 0.9746158984635939,
      "grad_norm": 2.5709469318389893,
      "learning_rate": 1.5228414800532996e-05,
      "loss": 0.1082,
      "step": 1459
    },
    {
      "epoch": 0.9752839011356046,
      "grad_norm": 2.6835174560546875,
      "learning_rate": 1.5222450512182114e-05,
      "loss": 0.169,
      "step": 1460
    },
    {
      "epoch": 0.9759519038076152,
      "grad_norm": 1.48556649684906,
      "learning_rate": 1.5216483668260234e-05,
      "loss": 0.1614,
      "step": 1461
    },
    {
      "epoch": 0.9766199064796259,
      "grad_norm": 0.22226588428020477,
      "learning_rate": 1.5210514271687191e-05,
      "loss": 0.0037,
      "step": 1462
    },
    {
      "epoch": 0.9772879091516367,
      "grad_norm": 0.926532506942749,
      "learning_rate": 1.5204542325384066e-05,
      "loss": 0.0188,
      "step": 1463
    },
    {
      "epoch": 0.9779559118236473,
      "grad_norm": 13.857398986816406,
      "learning_rate": 1.5198567832273198e-05,
      "loss": 1.0896,
      "step": 1464
    },
    {
      "epoch": 0.978623914495658,
      "grad_norm": 0.1794932633638382,
      "learning_rate": 1.5192590795278157e-05,
      "loss": 0.0027,
      "step": 1465
    },
    {
      "epoch": 0.9792919171676687,
      "grad_norm": 1.5926048755645752,
      "learning_rate": 1.5186611217323775e-05,
      "loss": 0.0305,
      "step": 1466
    },
    {
      "epoch": 0.9799599198396793,
      "grad_norm": 4.460566997528076,
      "learning_rate": 1.5180629101336109e-05,
      "loss": 0.2591,
      "step": 1467
    },
    {
      "epoch": 0.9806279225116901,
      "grad_norm": 0.6748675107955933,
      "learning_rate": 1.5174644450242468e-05,
      "loss": 0.0108,
      "step": 1468
    },
    {
      "epoch": 0.9812959251837008,
      "grad_norm": 3.565025806427002,
      "learning_rate": 1.5168657266971409e-05,
      "loss": 0.2117,
      "step": 1469
    },
    {
      "epoch": 0.9819639278557114,
      "grad_norm": 0.30466821789741516,
      "learning_rate": 1.5162667554452713e-05,
      "loss": 0.0039,
      "step": 1470
    },
    {
      "epoch": 0.9826319305277221,
      "grad_norm": 4.106979846954346,
      "learning_rate": 1.5156675315617407e-05,
      "loss": 0.2234,
      "step": 1471
    },
    {
      "epoch": 0.9832999331997327,
      "grad_norm": 2.0374364852905273,
      "learning_rate": 1.515068055339775e-05,
      "loss": 0.0882,
      "step": 1472
    },
    {
      "epoch": 0.9839679358717435,
      "grad_norm": 0.15206031501293182,
      "learning_rate": 1.5144683270727245e-05,
      "loss": 0.0029,
      "step": 1473
    },
    {
      "epoch": 0.9846359385437542,
      "grad_norm": 9.523031234741211,
      "learning_rate": 1.5138683470540615e-05,
      "loss": 0.4648,
      "step": 1474
    },
    {
      "epoch": 0.9853039412157648,
      "grad_norm": 0.11532561480998993,
      "learning_rate": 1.5132681155773828e-05,
      "loss": 0.0018,
      "step": 1475
    },
    {
      "epoch": 0.9859719438877755,
      "grad_norm": 7.548294544219971,
      "learning_rate": 1.5126676329364072e-05,
      "loss": 0.118,
      "step": 1476
    },
    {
      "epoch": 0.9866399465597863,
      "grad_norm": 6.19639253616333,
      "learning_rate": 1.512066899424977e-05,
      "loss": 0.2698,
      "step": 1477
    },
    {
      "epoch": 0.9873079492317969,
      "grad_norm": 0.025260210037231445,
      "learning_rate": 1.5114659153370567e-05,
      "loss": 0.0007,
      "step": 1478
    },
    {
      "epoch": 0.9879759519038076,
      "grad_norm": 11.644917488098145,
      "learning_rate": 1.510864680966735e-05,
      "loss": 0.4157,
      "step": 1479
    },
    {
      "epoch": 0.9886439545758183,
      "grad_norm": 2.3432745933532715,
      "learning_rate": 1.5102631966082205e-05,
      "loss": 0.0818,
      "step": 1480
    },
    {
      "epoch": 0.9893119572478289,
      "grad_norm": 2.5330746173858643,
      "learning_rate": 1.5096614625558462e-05,
      "loss": 0.159,
      "step": 1481
    },
    {
      "epoch": 0.9899799599198397,
      "grad_norm": 2.2154016494750977,
      "learning_rate": 1.5090594791040662e-05,
      "loss": 0.1628,
      "step": 1482
    },
    {
      "epoch": 0.9906479625918504,
      "grad_norm": 14.603469848632812,
      "learning_rate": 1.5084572465474576e-05,
      "loss": 0.2898,
      "step": 1483
    },
    {
      "epoch": 0.991315965263861,
      "grad_norm": 0.09177525341510773,
      "learning_rate": 1.507854765180719e-05,
      "loss": 0.0013,
      "step": 1484
    },
    {
      "epoch": 0.9919839679358717,
      "grad_norm": 1.7893015146255493,
      "learning_rate": 1.5072520352986696e-05,
      "loss": 0.1462,
      "step": 1485
    },
    {
      "epoch": 0.9926519706078825,
      "grad_norm": 1.2182813882827759,
      "learning_rate": 1.506649057196252e-05,
      "loss": 0.022,
      "step": 1486
    },
    {
      "epoch": 0.9933199732798931,
      "grad_norm": 2.175779342651367,
      "learning_rate": 1.5060458311685295e-05,
      "loss": 0.178,
      "step": 1487
    },
    {
      "epoch": 0.9939879759519038,
      "grad_norm": 0.364665150642395,
      "learning_rate": 1.5054423575106862e-05,
      "loss": 0.0059,
      "step": 1488
    },
    {
      "epoch": 0.9946559786239145,
      "grad_norm": 1.3691531419754028,
      "learning_rate": 1.5048386365180286e-05,
      "loss": 0.1457,
      "step": 1489
    },
    {
      "epoch": 0.9953239812959251,
      "grad_norm": 2.6526341438293457,
      "learning_rate": 1.5042346684859823e-05,
      "loss": 0.2,
      "step": 1490
    },
    {
      "epoch": 0.9959919839679359,
      "grad_norm": 1.14614737033844,
      "learning_rate": 1.5036304537100962e-05,
      "loss": 0.1187,
      "step": 1491
    },
    {
      "epoch": 0.9966599866399466,
      "grad_norm": 1.4739816188812256,
      "learning_rate": 1.5030259924860385e-05,
      "loss": 0.1654,
      "step": 1492
    },
    {
      "epoch": 0.9973279893119572,
      "grad_norm": 3.1309008598327637,
      "learning_rate": 1.5024212851095977e-05,
      "loss": 0.017,
      "step": 1493
    },
    {
      "epoch": 0.9979959919839679,
      "grad_norm": 0.2742685079574585,
      "learning_rate": 1.5018163318766835e-05,
      "loss": 0.0039,
      "step": 1494
    },
    {
      "epoch": 0.9986639946559787,
      "grad_norm": 1.461193323135376,
      "learning_rate": 1.501211133083326e-05,
      "loss": 0.0236,
      "step": 1495
    },
    {
      "epoch": 0.9993319973279893,
      "grad_norm": 0.08968589454889297,
      "learning_rate": 1.500605689025675e-05,
      "loss": 0.0018,
      "step": 1496
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7810759544372559,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.127,
      "step": 1497
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.46706586826347307,
      "eval_loss": 0.1316756308078766,
      "eval_runtime": 167.5064,
      "eval_samples_per_second": 0.997,
      "eval_steps_per_second": 0.997,
      "step": 1497
    },
    {
      "epoch": 1.0006680026720107,
      "grad_norm": 1.7132701873779297,
      "learning_rate": 1.4993940663026917e-05,
      "loss": 0.1201,
      "step": 1498
    },
    {
      "epoch": 1.0013360053440215,
      "grad_norm": 0.3746369183063507,
      "learning_rate": 1.4987878882302592e-05,
      "loss": 0.0053,
      "step": 1499
    },
    {
      "epoch": 1.002004008016032,
      "grad_norm": 4.271317481994629,
      "learning_rate": 1.4981814660793314e-05,
      "loss": 0.2591,
      "step": 1500
    },
    {
      "epoch": 1.0026720106880427,
      "grad_norm": 0.2397828996181488,
      "learning_rate": 1.4975748001466574e-05,
      "loss": 0.0037,
      "step": 1501
    },
    {
      "epoch": 1.0033400133600534,
      "grad_norm": 7.564994812011719,
      "learning_rate": 1.496967890729105e-05,
      "loss": 0.2991,
      "step": 1502
    },
    {
      "epoch": 1.0040080160320641,
      "grad_norm": 8.140181541442871,
      "learning_rate": 1.4963607381236608e-05,
      "loss": 0.3605,
      "step": 1503
    },
    {
      "epoch": 1.0046760187040749,
      "grad_norm": 1.1825355291366577,
      "learning_rate": 1.4957533426274314e-05,
      "loss": 0.0802,
      "step": 1504
    },
    {
      "epoch": 1.0053440213760856,
      "grad_norm": 8.217246055603027,
      "learning_rate": 1.4951457045376412e-05,
      "loss": 0.2234,
      "step": 1505
    },
    {
      "epoch": 1.006012024048096,
      "grad_norm": 0.18488556146621704,
      "learning_rate": 1.4945378241516345e-05,
      "loss": 0.0028,
      "step": 1506
    },
    {
      "epoch": 1.0066800267201068,
      "grad_norm": 3.3010430335998535,
      "learning_rate": 1.4939297017668726e-05,
      "loss": 0.1962,
      "step": 1507
    },
    {
      "epoch": 1.0073480293921175,
      "grad_norm": 2.8019802570343018,
      "learning_rate": 1.4933213376809368e-05,
      "loss": 0.2039,
      "step": 1508
    },
    {
      "epoch": 1.0080160320641283,
      "grad_norm": 4.49795389175415,
      "learning_rate": 1.4927127321915253e-05,
      "loss": 0.1372,
      "step": 1509
    },
    {
      "epoch": 1.008684034736139,
      "grad_norm": 6.254573822021484,
      "learning_rate": 1.4921038855964563e-05,
      "loss": 0.3164,
      "step": 1510
    },
    {
      "epoch": 1.0093520374081497,
      "grad_norm": 3.601227283477783,
      "learning_rate": 1.491494798193663e-05,
      "loss": 0.1132,
      "step": 1511
    },
    {
      "epoch": 1.0100200400801602,
      "grad_norm": 3.515730619430542,
      "learning_rate": 1.4908854702812e-05,
      "loss": 0.239,
      "step": 1512
    },
    {
      "epoch": 1.010688042752171,
      "grad_norm": 4.089770793914795,
      "learning_rate": 1.4902759021572366e-05,
      "loss": 0.2262,
      "step": 1513
    },
    {
      "epoch": 1.0113560454241817,
      "grad_norm": 1.5998140573501587,
      "learning_rate": 1.4896660941200615e-05,
      "loss": 0.0387,
      "step": 1514
    },
    {
      "epoch": 1.0120240480961924,
      "grad_norm": 8.455450057983398,
      "learning_rate": 1.4890560464680796e-05,
      "loss": 0.3637,
      "step": 1515
    },
    {
      "epoch": 1.0126920507682031,
      "grad_norm": 2.315122365951538,
      "learning_rate": 1.4884457594998143e-05,
      "loss": 0.0418,
      "step": 1516
    },
    {
      "epoch": 1.0133600534402138,
      "grad_norm": 2.1585652828216553,
      "learning_rate": 1.4878352335139048e-05,
      "loss": 0.0516,
      "step": 1517
    },
    {
      "epoch": 1.0140280561122244,
      "grad_norm": 1.4283264875411987,
      "learning_rate": 1.4872244688091084e-05,
      "loss": 0.0975,
      "step": 1518
    },
    {
      "epoch": 1.014696058784235,
      "grad_norm": 1.0708248615264893,
      "learning_rate": 1.4866134656842981e-05,
      "loss": 0.0153,
      "step": 1519
    },
    {
      "epoch": 1.0153640614562458,
      "grad_norm": 1.1290231943130493,
      "learning_rate": 1.4860022244384648e-05,
      "loss": 0.1131,
      "step": 1520
    },
    {
      "epoch": 1.0160320641282565,
      "grad_norm": 1.6470234394073486,
      "learning_rate": 1.4853907453707148e-05,
      "loss": 0.0952,
      "step": 1521
    },
    {
      "epoch": 1.0167000668002673,
      "grad_norm": 2.1512575149536133,
      "learning_rate": 1.4847790287802717e-05,
      "loss": 0.1942,
      "step": 1522
    },
    {
      "epoch": 1.017368069472278,
      "grad_norm": 4.752511501312256,
      "learning_rate": 1.4841670749664743e-05,
      "loss": 0.084,
      "step": 1523
    },
    {
      "epoch": 1.0180360721442885,
      "grad_norm": 3.6062211990356445,
      "learning_rate": 1.4835548842287788e-05,
      "loss": 0.1027,
      "step": 1524
    },
    {
      "epoch": 1.0187040748162992,
      "grad_norm": 0.4097593128681183,
      "learning_rate": 1.4829424568667561e-05,
      "loss": 0.0076,
      "step": 1525
    },
    {
      "epoch": 1.01937207748831,
      "grad_norm": 0.8464756011962891,
      "learning_rate": 1.4823297931800933e-05,
      "loss": 0.0123,
      "step": 1526
    },
    {
      "epoch": 1.0200400801603207,
      "grad_norm": 3.6113975048065186,
      "learning_rate": 1.481716893468594e-05,
      "loss": 0.1188,
      "step": 1527
    },
    {
      "epoch": 1.0207080828323314,
      "grad_norm": 3.5920023918151855,
      "learning_rate": 1.4811037580321756e-05,
      "loss": 0.2505,
      "step": 1528
    },
    {
      "epoch": 1.0213760855043421,
      "grad_norm": 0.3924131989479065,
      "learning_rate": 1.4804903871708724e-05,
      "loss": 0.0062,
      "step": 1529
    },
    {
      "epoch": 1.0220440881763526,
      "grad_norm": 0.40331557393074036,
      "learning_rate": 1.4798767811848331e-05,
      "loss": 0.0064,
      "step": 1530
    },
    {
      "epoch": 1.0227120908483633,
      "grad_norm": 0.2981526553630829,
      "learning_rate": 1.4792629403743217e-05,
      "loss": 0.0047,
      "step": 1531
    },
    {
      "epoch": 1.023380093520374,
      "grad_norm": 3.468222141265869,
      "learning_rate": 1.4786488650397173e-05,
      "loss": 0.1176,
      "step": 1532
    },
    {
      "epoch": 1.0240480961923848,
      "grad_norm": 9.503799438476562,
      "learning_rate": 1.4780345554815132e-05,
      "loss": 0.4867,
      "step": 1533
    },
    {
      "epoch": 1.0247160988643955,
      "grad_norm": 1.2194899320602417,
      "learning_rate": 1.4774200120003174e-05,
      "loss": 0.0188,
      "step": 1534
    },
    {
      "epoch": 1.0253841015364062,
      "grad_norm": 0.43177473545074463,
      "learning_rate": 1.4768052348968534e-05,
      "loss": 0.005,
      "step": 1535
    },
    {
      "epoch": 1.0260521042084167,
      "grad_norm": 6.368242263793945,
      "learning_rate": 1.4761902244719574e-05,
      "loss": 0.1561,
      "step": 1536
    },
    {
      "epoch": 1.0267201068804275,
      "grad_norm": 0.6304857134819031,
      "learning_rate": 1.4755749810265818e-05,
      "loss": 0.0102,
      "step": 1537
    },
    {
      "epoch": 1.0273881095524382,
      "grad_norm": 8.827478408813477,
      "learning_rate": 1.4749595048617904e-05,
      "loss": 0.3343,
      "step": 1538
    },
    {
      "epoch": 1.028056112224449,
      "grad_norm": 11.11739730834961,
      "learning_rate": 1.474343796278763e-05,
      "loss": 0.1973,
      "step": 1539
    },
    {
      "epoch": 1.0287241148964597,
      "grad_norm": 0.2263467013835907,
      "learning_rate": 1.4737278555787924e-05,
      "loss": 0.0027,
      "step": 1540
    },
    {
      "epoch": 1.0293921175684704,
      "grad_norm": 0.31610772013664246,
      "learning_rate": 1.4731116830632855e-05,
      "loss": 0.0036,
      "step": 1541
    },
    {
      "epoch": 1.0300601202404809,
      "grad_norm": 2.7467539310455322,
      "learning_rate": 1.4724952790337613e-05,
      "loss": 0.2454,
      "step": 1542
    },
    {
      "epoch": 1.0307281229124916,
      "grad_norm": 5.753192901611328,
      "learning_rate": 1.4718786437918535e-05,
      "loss": 0.2676,
      "step": 1543
    },
    {
      "epoch": 1.0313961255845023,
      "grad_norm": 1.3895920515060425,
      "learning_rate": 1.4712617776393081e-05,
      "loss": 0.1324,
      "step": 1544
    },
    {
      "epoch": 1.032064128256513,
      "grad_norm": 0.46975961327552795,
      "learning_rate": 1.4706446808779851e-05,
      "loss": 0.0065,
      "step": 1545
    },
    {
      "epoch": 1.0327321309285238,
      "grad_norm": 0.31105002760887146,
      "learning_rate": 1.4700273538098556e-05,
      "loss": 0.0034,
      "step": 1546
    },
    {
      "epoch": 1.0334001336005345,
      "grad_norm": 9.910005569458008,
      "learning_rate": 1.4694097967370051e-05,
      "loss": 0.3663,
      "step": 1547
    },
    {
      "epoch": 1.034068136272545,
      "grad_norm": 7.07146692276001,
      "learning_rate": 1.4687920099616311e-05,
      "loss": 0.2274,
      "step": 1548
    },
    {
      "epoch": 1.0347361389445557,
      "grad_norm": 1.2504812479019165,
      "learning_rate": 1.4681739937860428e-05,
      "loss": 0.0175,
      "step": 1549
    },
    {
      "epoch": 1.0354041416165665,
      "grad_norm": 2.12507700920105,
      "learning_rate": 1.4675557485126631e-05,
      "loss": 0.1828,
      "step": 1550
    },
    {
      "epoch": 1.0360721442885772,
      "grad_norm": 3.6737236976623535,
      "learning_rate": 1.4669372744440256e-05,
      "loss": 0.2302,
      "step": 1551
    },
    {
      "epoch": 1.036740146960588,
      "grad_norm": 1.5874004364013672,
      "learning_rate": 1.4663185718827764e-05,
      "loss": 0.1433,
      "step": 1552
    },
    {
      "epoch": 1.0374081496325984,
      "grad_norm": 1.962915301322937,
      "learning_rate": 1.4656996411316732e-05,
      "loss": 0.1835,
      "step": 1553
    },
    {
      "epoch": 1.0380761523046091,
      "grad_norm": 0.12118445336818695,
      "learning_rate": 1.4650804824935866e-05,
      "loss": 0.0015,
      "step": 1554
    },
    {
      "epoch": 1.0387441549766199,
      "grad_norm": 4.267314910888672,
      "learning_rate": 1.4644610962714967e-05,
      "loss": 0.0816,
      "step": 1555
    },
    {
      "epoch": 1.0394121576486306,
      "grad_norm": 3.416576385498047,
      "learning_rate": 1.4638414827684963e-05,
      "loss": 0.2117,
      "step": 1556
    },
    {
      "epoch": 1.0400801603206413,
      "grad_norm": 1.1578534841537476,
      "learning_rate": 1.4632216422877891e-05,
      "loss": 0.0269,
      "step": 1557
    },
    {
      "epoch": 1.040748162992652,
      "grad_norm": 0.8476420044898987,
      "learning_rate": 1.46260157513269e-05,
      "loss": 0.012,
      "step": 1558
    },
    {
      "epoch": 1.0414161656646626,
      "grad_norm": 11.891818046569824,
      "learning_rate": 1.4619812816066246e-05,
      "loss": 0.491,
      "step": 1559
    },
    {
      "epoch": 1.0420841683366733,
      "grad_norm": 0.6441790461540222,
      "learning_rate": 1.4613607620131294e-05,
      "loss": 0.0137,
      "step": 1560
    },
    {
      "epoch": 1.042752171008684,
      "grad_norm": 0.44871029257774353,
      "learning_rate": 1.4607400166558512e-05,
      "loss": 0.0055,
      "step": 1561
    },
    {
      "epoch": 1.0434201736806947,
      "grad_norm": 1.8403478860855103,
      "learning_rate": 1.4601190458385479e-05,
      "loss": 0.125,
      "step": 1562
    },
    {
      "epoch": 1.0440881763527055,
      "grad_norm": 2.5535008907318115,
      "learning_rate": 1.4594978498650876e-05,
      "loss": 0.1071,
      "step": 1563
    },
    {
      "epoch": 1.0447561790247162,
      "grad_norm": 0.605577290058136,
      "learning_rate": 1.4588764290394477e-05,
      "loss": 0.0092,
      "step": 1564
    },
    {
      "epoch": 1.0454241816967267,
      "grad_norm": 3.174940824508667,
      "learning_rate": 1.4582547836657166e-05,
      "loss": 0.0951,
      "step": 1565
    },
    {
      "epoch": 1.0460921843687374,
      "grad_norm": 2.450413703918457,
      "learning_rate": 1.4576329140480925e-05,
      "loss": 0.1471,
      "step": 1566
    },
    {
      "epoch": 1.0467601870407481,
      "grad_norm": 2.4871160984039307,
      "learning_rate": 1.4570108204908828e-05,
      "loss": 0.2139,
      "step": 1567
    },
    {
      "epoch": 1.0474281897127589,
      "grad_norm": 2.278656482696533,
      "learning_rate": 1.4563885032985052e-05,
      "loss": 0.1007,
      "step": 1568
    },
    {
      "epoch": 1.0480961923847696,
      "grad_norm": 0.21639712154865265,
      "learning_rate": 1.4557659627754856e-05,
      "loss": 0.0032,
      "step": 1569
    },
    {
      "epoch": 1.0487641950567803,
      "grad_norm": 1.5906637907028198,
      "learning_rate": 1.455143199226461e-05,
      "loss": 0.1786,
      "step": 1570
    },
    {
      "epoch": 1.0494321977287908,
      "grad_norm": 2.7523186206817627,
      "learning_rate": 1.4545202129561761e-05,
      "loss": 0.1012,
      "step": 1571
    },
    {
      "epoch": 1.0501002004008015,
      "grad_norm": 2.012331008911133,
      "learning_rate": 1.453897004269485e-05,
      "loss": 0.174,
      "step": 1572
    },
    {
      "epoch": 1.0507682030728123,
      "grad_norm": 0.7109083533287048,
      "learning_rate": 1.4532735734713508e-05,
      "loss": 0.0143,
      "step": 1573
    },
    {
      "epoch": 1.051436205744823,
      "grad_norm": 1.7939879894256592,
      "learning_rate": 1.452649920866845e-05,
      "loss": 0.1573,
      "step": 1574
    },
    {
      "epoch": 1.0521042084168337,
      "grad_norm": 3.1152756214141846,
      "learning_rate": 1.452026046761148e-05,
      "loss": 0.1211,
      "step": 1575
    },
    {
      "epoch": 1.0527722110888444,
      "grad_norm": 2.0419199466705322,
      "learning_rate": 1.451401951459548e-05,
      "loss": 0.0746,
      "step": 1576
    },
    {
      "epoch": 1.053440213760855,
      "grad_norm": 15.614058494567871,
      "learning_rate": 1.4507776352674425e-05,
      "loss": 0.3192,
      "step": 1577
    },
    {
      "epoch": 1.0541082164328657,
      "grad_norm": 4.747482776641846,
      "learning_rate": 1.4501530984903359e-05,
      "loss": 0.1337,
      "step": 1578
    },
    {
      "epoch": 1.0547762191048764,
      "grad_norm": 1.6887383460998535,
      "learning_rate": 1.4495283414338413e-05,
      "loss": 0.0278,
      "step": 1579
    },
    {
      "epoch": 1.0554442217768871,
      "grad_norm": 1.2707678079605103,
      "learning_rate": 1.448903364403679e-05,
      "loss": 0.1588,
      "step": 1580
    },
    {
      "epoch": 1.0561122244488979,
      "grad_norm": 2.7913804054260254,
      "learning_rate": 1.4482781677056778e-05,
      "loss": 0.1313,
      "step": 1581
    },
    {
      "epoch": 1.0567802271209086,
      "grad_norm": 2.0538735389709473,
      "learning_rate": 1.4476527516457733e-05,
      "loss": 0.1362,
      "step": 1582
    },
    {
      "epoch": 1.057448229792919,
      "grad_norm": 1.4714338779449463,
      "learning_rate": 1.4470271165300086e-05,
      "loss": 0.1333,
      "step": 1583
    },
    {
      "epoch": 1.0581162324649298,
      "grad_norm": 1.850932002067566,
      "learning_rate": 1.4464012626645336e-05,
      "loss": 0.1259,
      "step": 1584
    },
    {
      "epoch": 1.0587842351369405,
      "grad_norm": 5.500226020812988,
      "learning_rate": 1.4457751903556067e-05,
      "loss": 0.2559,
      "step": 1585
    },
    {
      "epoch": 1.0594522378089513,
      "grad_norm": 1.5339938402175903,
      "learning_rate": 1.4451488999095915e-05,
      "loss": 0.1409,
      "step": 1586
    },
    {
      "epoch": 1.060120240480962,
      "grad_norm": 2.2213962078094482,
      "learning_rate": 1.444522391632959e-05,
      "loss": 0.1506,
      "step": 1587
    },
    {
      "epoch": 1.0607882431529727,
      "grad_norm": 0.37972143292427063,
      "learning_rate": 1.4438956658322866e-05,
      "loss": 0.006,
      "step": 1588
    },
    {
      "epoch": 1.0614562458249832,
      "grad_norm": 1.2405048608779907,
      "learning_rate": 1.4432687228142593e-05,
      "loss": 0.1651,
      "step": 1589
    },
    {
      "epoch": 1.062124248496994,
      "grad_norm": 2.3561148643493652,
      "learning_rate": 1.4426415628856663e-05,
      "loss": 0.1938,
      "step": 1590
    },
    {
      "epoch": 1.0627922511690047,
      "grad_norm": 1.744026780128479,
      "learning_rate": 1.442014186353405e-05,
      "loss": 0.1063,
      "step": 1591
    },
    {
      "epoch": 1.0634602538410154,
      "grad_norm": 3.5950284004211426,
      "learning_rate": 1.4413865935244771e-05,
      "loss": 0.1468,
      "step": 1592
    },
    {
      "epoch": 1.0641282565130261,
      "grad_norm": 1.3793138265609741,
      "learning_rate": 1.4407587847059914e-05,
      "loss": 0.1175,
      "step": 1593
    },
    {
      "epoch": 1.0647962591850368,
      "grad_norm": 1.1210401058197021,
      "learning_rate": 1.440130760205162e-05,
      "loss": 0.1122,
      "step": 1594
    },
    {
      "epoch": 1.0654642618570473,
      "grad_norm": 2.8118233680725098,
      "learning_rate": 1.4395025203293083e-05,
      "loss": 0.1612,
      "step": 1595
    },
    {
      "epoch": 1.066132264529058,
      "grad_norm": 1.131600260734558,
      "learning_rate": 1.4388740653858548e-05,
      "loss": 0.0224,
      "step": 1596
    },
    {
      "epoch": 1.0668002672010688,
      "grad_norm": 1.0539273023605347,
      "learning_rate": 1.4382453956823326e-05,
      "loss": 0.0957,
      "step": 1597
    },
    {
      "epoch": 1.0674682698730795,
      "grad_norm": 2.623711585998535,
      "learning_rate": 1.4376165115263763e-05,
      "loss": 0.1303,
      "step": 1598
    },
    {
      "epoch": 1.0681362725450902,
      "grad_norm": 0.15898850560188293,
      "learning_rate": 1.4369874132257264e-05,
      "loss": 0.0023,
      "step": 1599
    },
    {
      "epoch": 1.0688042752171008,
      "grad_norm": 0.35515862703323364,
      "learning_rate": 1.436358101088228e-05,
      "loss": 0.0056,
      "step": 1600
    },
    {
      "epoch": 1.0694722778891115,
      "grad_norm": 2.9752726554870605,
      "learning_rate": 1.4357285754218302e-05,
      "loss": 0.071,
      "step": 1601
    },
    {
      "epoch": 1.0701402805611222,
      "grad_norm": 1.4217482805252075,
      "learning_rate": 1.4350988365345879e-05,
      "loss": 0.1175,
      "step": 1602
    },
    {
      "epoch": 1.070808283233133,
      "grad_norm": 3.428178310394287,
      "learning_rate": 1.4344688847346592e-05,
      "loss": 0.126,
      "step": 1603
    },
    {
      "epoch": 1.0714762859051437,
      "grad_norm": 1.5243597030639648,
      "learning_rate": 1.433838720330307e-05,
      "loss": 0.1067,
      "step": 1604
    },
    {
      "epoch": 1.0721442885771544,
      "grad_norm": 1.4330832958221436,
      "learning_rate": 1.4332083436298976e-05,
      "loss": 0.0277,
      "step": 1605
    },
    {
      "epoch": 1.072812291249165,
      "grad_norm": 1.1387197971343994,
      "learning_rate": 1.4325777549419017e-05,
      "loss": 0.0741,
      "step": 1606
    },
    {
      "epoch": 1.0734802939211756,
      "grad_norm": 1.4761061668395996,
      "learning_rate": 1.4319469545748941e-05,
      "loss": 0.1234,
      "step": 1607
    },
    {
      "epoch": 1.0741482965931863,
      "grad_norm": 0.4504566788673401,
      "learning_rate": 1.4313159428375522e-05,
      "loss": 0.0068,
      "step": 1608
    },
    {
      "epoch": 1.074816299265197,
      "grad_norm": 2.015432596206665,
      "learning_rate": 1.4306847200386576e-05,
      "loss": 0.1185,
      "step": 1609
    },
    {
      "epoch": 1.0754843019372078,
      "grad_norm": 0.7920273542404175,
      "learning_rate": 1.4300532864870947e-05,
      "loss": 0.014,
      "step": 1610
    },
    {
      "epoch": 1.0761523046092185,
      "grad_norm": 4.801352500915527,
      "learning_rate": 1.4294216424918515e-05,
      "loss": 0.2503,
      "step": 1611
    },
    {
      "epoch": 1.076820307281229,
      "grad_norm": 1.8391530513763428,
      "learning_rate": 1.4287897883620187e-05,
      "loss": 0.0656,
      "step": 1612
    },
    {
      "epoch": 1.0774883099532397,
      "grad_norm": 0.8223113417625427,
      "learning_rate": 1.4281577244067895e-05,
      "loss": 0.0129,
      "step": 1613
    },
    {
      "epoch": 1.0781563126252505,
      "grad_norm": 0.2705785930156708,
      "learning_rate": 1.4275254509354607e-05,
      "loss": 0.0042,
      "step": 1614
    },
    {
      "epoch": 1.0788243152972612,
      "grad_norm": 1.382412314414978,
      "learning_rate": 1.4268929682574307e-05,
      "loss": 0.1045,
      "step": 1615
    },
    {
      "epoch": 1.079492317969272,
      "grad_norm": 1.1384831666946411,
      "learning_rate": 1.4262602766822009e-05,
      "loss": 0.0831,
      "step": 1616
    },
    {
      "epoch": 1.0801603206412826,
      "grad_norm": 1.6669282913208008,
      "learning_rate": 1.4256273765193744e-05,
      "loss": 0.1584,
      "step": 1617
    },
    {
      "epoch": 1.0808283233132934,
      "grad_norm": 0.4401285946369171,
      "learning_rate": 1.4249942680786569e-05,
      "loss": 0.0056,
      "step": 1618
    },
    {
      "epoch": 1.0814963259853039,
      "grad_norm": 0.2065659761428833,
      "learning_rate": 1.4243609516698551e-05,
      "loss": 0.0031,
      "step": 1619
    },
    {
      "epoch": 1.0821643286573146,
      "grad_norm": 2.4572460651397705,
      "learning_rate": 1.4237274276028792e-05,
      "loss": 0.1623,
      "step": 1620
    },
    {
      "epoch": 1.0828323313293253,
      "grad_norm": 1.304983377456665,
      "learning_rate": 1.423093696187739e-05,
      "loss": 0.1037,
      "step": 1621
    },
    {
      "epoch": 1.083500334001336,
      "grad_norm": 2.040060043334961,
      "learning_rate": 1.4224597577345474e-05,
      "loss": 0.1054,
      "step": 1622
    },
    {
      "epoch": 1.0841683366733468,
      "grad_norm": 0.09981106221675873,
      "learning_rate": 1.4218256125535174e-05,
      "loss": 0.0011,
      "step": 1623
    },
    {
      "epoch": 1.0848363393453573,
      "grad_norm": 1.1561199426651,
      "learning_rate": 1.4211912609549637e-05,
      "loss": 0.1099,
      "step": 1624
    },
    {
      "epoch": 1.085504342017368,
      "grad_norm": 0.09140115976333618,
      "learning_rate": 1.4205567032493022e-05,
      "loss": 0.0013,
      "step": 1625
    },
    {
      "epoch": 1.0861723446893787,
      "grad_norm": 14.089606285095215,
      "learning_rate": 1.4199219397470497e-05,
      "loss": 0.4572,
      "step": 1626
    },
    {
      "epoch": 1.0868403473613895,
      "grad_norm": 1.2607449293136597,
      "learning_rate": 1.4192869707588228e-05,
      "loss": 0.1258,
      "step": 1627
    },
    {
      "epoch": 1.0875083500334002,
      "grad_norm": 7.232888698577881,
      "learning_rate": 1.4186517965953392e-05,
      "loss": 0.2952,
      "step": 1628
    },
    {
      "epoch": 1.088176352705411,
      "grad_norm": 2.989908456802368,
      "learning_rate": 1.4180164175674184e-05,
      "loss": 0.1573,
      "step": 1629
    },
    {
      "epoch": 1.0888443553774214,
      "grad_norm": 0.06038884446024895,
      "learning_rate": 1.4173808339859774e-05,
      "loss": 0.0012,
      "step": 1630
    },
    {
      "epoch": 1.0895123580494321,
      "grad_norm": 4.594780445098877,
      "learning_rate": 1.4167450461620353e-05,
      "loss": 0.1921,
      "step": 1631
    },
    {
      "epoch": 1.0901803607214429,
      "grad_norm": 1.5641615390777588,
      "learning_rate": 1.4161090544067109e-05,
      "loss": 0.1546,
      "step": 1632
    },
    {
      "epoch": 1.0908483633934536,
      "grad_norm": 9.324844360351562,
      "learning_rate": 1.415472859031222e-05,
      "loss": 0.3076,
      "step": 1633
    },
    {
      "epoch": 1.0915163660654643,
      "grad_norm": 10.200161933898926,
      "learning_rate": 1.4148364603468867e-05,
      "loss": 0.6987,
      "step": 1634
    },
    {
      "epoch": 1.092184368737475,
      "grad_norm": 4.752192974090576,
      "learning_rate": 1.4141998586651227e-05,
      "loss": 0.2384,
      "step": 1635
    },
    {
      "epoch": 1.0928523714094855,
      "grad_norm": 5.637359619140625,
      "learning_rate": 1.413563054297446e-05,
      "loss": 0.2423,
      "step": 1636
    },
    {
      "epoch": 1.0935203740814963,
      "grad_norm": 7.3712382316589355,
      "learning_rate": 1.4129260475554731e-05,
      "loss": 0.1963,
      "step": 1637
    },
    {
      "epoch": 1.094188376753507,
      "grad_norm": 1.518603801727295,
      "learning_rate": 1.4122888387509193e-05,
      "loss": 0.1234,
      "step": 1638
    },
    {
      "epoch": 1.0948563794255177,
      "grad_norm": 2.331322193145752,
      "learning_rate": 1.4116514281955978e-05,
      "loss": 0.0429,
      "step": 1639
    },
    {
      "epoch": 1.0955243820975284,
      "grad_norm": 0.5952328443527222,
      "learning_rate": 1.4110138162014209e-05,
      "loss": 0.007,
      "step": 1640
    },
    {
      "epoch": 1.0961923847695392,
      "grad_norm": 0.0968869999051094,
      "learning_rate": 1.4103760030804008e-05,
      "loss": 0.0015,
      "step": 1641
    },
    {
      "epoch": 1.0968603874415497,
      "grad_norm": 0.23640048503875732,
      "learning_rate": 1.4097379891446462e-05,
      "loss": 0.0033,
      "step": 1642
    },
    {
      "epoch": 1.0975283901135604,
      "grad_norm": 2.200537919998169,
      "learning_rate": 1.4090997747063654e-05,
      "loss": 0.1361,
      "step": 1643
    },
    {
      "epoch": 1.0981963927855711,
      "grad_norm": 7.042301654815674,
      "learning_rate": 1.4084613600778636e-05,
      "loss": 0.2361,
      "step": 1644
    },
    {
      "epoch": 1.0988643954575819,
      "grad_norm": 1.2370797395706177,
      "learning_rate": 1.4078227455715456e-05,
      "loss": 0.0913,
      "step": 1645
    },
    {
      "epoch": 1.0995323981295926,
      "grad_norm": 3.061725378036499,
      "learning_rate": 1.4071839314999127e-05,
      "loss": 0.1852,
      "step": 1646
    },
    {
      "epoch": 1.1002004008016033,
      "grad_norm": 3.528491973876953,
      "learning_rate": 1.4065449181755644e-05,
      "loss": 0.0389,
      "step": 1647
    },
    {
      "epoch": 1.1008684034736138,
      "grad_norm": 1.5977885723114014,
      "learning_rate": 1.4059057059111971e-05,
      "loss": 0.1306,
      "step": 1648
    },
    {
      "epoch": 1.1015364061456245,
      "grad_norm": 0.23558996617794037,
      "learning_rate": 1.4052662950196056e-05,
      "loss": 0.0038,
      "step": 1649
    },
    {
      "epoch": 1.1022044088176353,
      "grad_norm": 1.9261996746063232,
      "learning_rate": 1.4046266858136812e-05,
      "loss": 0.0214,
      "step": 1650
    },
    {
      "epoch": 1.102872411489646,
      "grad_norm": 1.1343754529953003,
      "learning_rate": 1.4039868786064124e-05,
      "loss": 0.0127,
      "step": 1651
    },
    {
      "epoch": 1.1035404141616567,
      "grad_norm": 1.7912757396697998,
      "learning_rate": 1.403346873710884e-05,
      "loss": 0.0283,
      "step": 1652
    },
    {
      "epoch": 1.1042084168336674,
      "grad_norm": 1.4597433805465698,
      "learning_rate": 1.4027066714402785e-05,
      "loss": 0.1339,
      "step": 1653
    },
    {
      "epoch": 1.104876419505678,
      "grad_norm": 3.2341134548187256,
      "learning_rate": 1.4020662721078749e-05,
      "loss": 0.1469,
      "step": 1654
    },
    {
      "epoch": 1.1055444221776887,
      "grad_norm": 3.005572557449341,
      "learning_rate": 1.4014256760270475e-05,
      "loss": 0.2489,
      "step": 1655
    },
    {
      "epoch": 1.1062124248496994,
      "grad_norm": 1.8564163446426392,
      "learning_rate": 1.4007848835112688e-05,
      "loss": 0.0224,
      "step": 1656
    },
    {
      "epoch": 1.1068804275217101,
      "grad_norm": 0.7462190985679626,
      "learning_rate": 1.400143894874105e-05,
      "loss": 0.0116,
      "step": 1657
    },
    {
      "epoch": 1.1075484301937208,
      "grad_norm": 7.006556034088135,
      "learning_rate": 1.3995027104292207e-05,
      "loss": 0.3426,
      "step": 1658
    },
    {
      "epoch": 1.1082164328657313,
      "grad_norm": 3.4332337379455566,
      "learning_rate": 1.3988613304903744e-05,
      "loss": 0.0705,
      "step": 1659
    },
    {
      "epoch": 1.108884435537742,
      "grad_norm": 1.9767488241195679,
      "learning_rate": 1.3982197553714216e-05,
      "loss": 0.138,
      "step": 1660
    },
    {
      "epoch": 1.1095524382097528,
      "grad_norm": 4.158060550689697,
      "learning_rate": 1.3975779853863123e-05,
      "loss": 0.1378,
      "step": 1661
    },
    {
      "epoch": 1.1102204408817635,
      "grad_norm": 0.16923345625400543,
      "learning_rate": 1.3969360208490927e-05,
      "loss": 0.0023,
      "step": 1662
    },
    {
      "epoch": 1.1108884435537743,
      "grad_norm": 1.8084434270858765,
      "learning_rate": 1.3962938620739034e-05,
      "loss": 0.15,
      "step": 1663
    },
    {
      "epoch": 1.111556446225785,
      "grad_norm": 1.7385070323944092,
      "learning_rate": 1.395651509374981e-05,
      "loss": 0.1246,
      "step": 1664
    },
    {
      "epoch": 1.1122244488977957,
      "grad_norm": 0.19636668264865875,
      "learning_rate": 1.3950089630666564e-05,
      "loss": 0.0023,
      "step": 1665
    },
    {
      "epoch": 1.1128924515698062,
      "grad_norm": 0.4328368902206421,
      "learning_rate": 1.3943662234633548e-05,
      "loss": 0.0052,
      "step": 1666
    },
    {
      "epoch": 1.113560454241817,
      "grad_norm": 0.2639809846878052,
      "learning_rate": 1.3937232908795971e-05,
      "loss": 0.0044,
      "step": 1667
    },
    {
      "epoch": 1.1142284569138277,
      "grad_norm": 2.5944418907165527,
      "learning_rate": 1.3930801656299976e-05,
      "loss": 0.1664,
      "step": 1668
    },
    {
      "epoch": 1.1148964595858384,
      "grad_norm": 2.3292627334594727,
      "learning_rate": 1.3924368480292654e-05,
      "loss": 0.164,
      "step": 1669
    },
    {
      "epoch": 1.115564462257849,
      "grad_norm": 0.15770801901817322,
      "learning_rate": 1.3917933383922038e-05,
      "loss": 0.0023,
      "step": 1670
    },
    {
      "epoch": 1.1162324649298596,
      "grad_norm": 1.5867750644683838,
      "learning_rate": 1.3911496370337097e-05,
      "loss": 0.0285,
      "step": 1671
    },
    {
      "epoch": 1.1169004676018703,
      "grad_norm": 0.556778609752655,
      "learning_rate": 1.3905057442687744e-05,
      "loss": 0.0075,
      "step": 1672
    },
    {
      "epoch": 1.117568470273881,
      "grad_norm": 1.81291925907135,
      "learning_rate": 1.389861660412482e-05,
      "loss": 0.1798,
      "step": 1673
    },
    {
      "epoch": 1.1182364729458918,
      "grad_norm": 2.1083874702453613,
      "learning_rate": 1.3892173857800108e-05,
      "loss": 0.1673,
      "step": 1674
    },
    {
      "epoch": 1.1189044756179025,
      "grad_norm": 3.288027286529541,
      "learning_rate": 1.3885729206866323e-05,
      "loss": 0.0475,
      "step": 1675
    },
    {
      "epoch": 1.1195724782899132,
      "grad_norm": 1.6304515600204468,
      "learning_rate": 1.3879282654477114e-05,
      "loss": 0.191,
      "step": 1676
    },
    {
      "epoch": 1.1202404809619237,
      "grad_norm": 1.9111852645874023,
      "learning_rate": 1.3872834203787054e-05,
      "loss": 0.1161,
      "step": 1677
    },
    {
      "epoch": 1.1209084836339345,
      "grad_norm": 2.090196371078491,
      "learning_rate": 1.386638385795165e-05,
      "loss": 0.0412,
      "step": 1678
    },
    {
      "epoch": 1.1215764863059452,
      "grad_norm": 5.042684078216553,
      "learning_rate": 1.3859931620127336e-05,
      "loss": 0.0995,
      "step": 1679
    },
    {
      "epoch": 1.122244488977956,
      "grad_norm": 12.345820426940918,
      "learning_rate": 1.3853477493471467e-05,
      "loss": 0.3235,
      "step": 1680
    },
    {
      "epoch": 1.1229124916499666,
      "grad_norm": 2.5085535049438477,
      "learning_rate": 1.3847021481142335e-05,
      "loss": 0.0517,
      "step": 1681
    },
    {
      "epoch": 1.1235804943219774,
      "grad_norm": 1.2972456216812134,
      "learning_rate": 1.384056358629914e-05,
      "loss": 0.0167,
      "step": 1682
    },
    {
      "epoch": 1.1242484969939879,
      "grad_norm": 6.014110565185547,
      "learning_rate": 1.3834103812102012e-05,
      "loss": 0.2186,
      "step": 1683
    },
    {
      "epoch": 1.1249164996659986,
      "grad_norm": 3.694370985031128,
      "learning_rate": 1.382764216171199e-05,
      "loss": 0.1875,
      "step": 1684
    },
    {
      "epoch": 1.1255845023380093,
      "grad_norm": 8.713385581970215,
      "learning_rate": 1.3821178638291055e-05,
      "loss": 0.2225,
      "step": 1685
    },
    {
      "epoch": 1.12625250501002,
      "grad_norm": 0.057518139481544495,
      "learning_rate": 1.3814713245002073e-05,
      "loss": 0.0012,
      "step": 1686
    },
    {
      "epoch": 1.1269205076820308,
      "grad_norm": 0.3415384590625763,
      "learning_rate": 1.3808245985008852e-05,
      "loss": 0.0042,
      "step": 1687
    },
    {
      "epoch": 1.1275885103540415,
      "grad_norm": 2.024480104446411,
      "learning_rate": 1.3801776861476092e-05,
      "loss": 0.0871,
      "step": 1688
    },
    {
      "epoch": 1.128256513026052,
      "grad_norm": 2.4415183067321777,
      "learning_rate": 1.3795305877569427e-05,
      "loss": 0.1832,
      "step": 1689
    },
    {
      "epoch": 1.1289245156980627,
      "grad_norm": 0.03904339671134949,
      "learning_rate": 1.3788833036455378e-05,
      "loss": 0.0009,
      "step": 1690
    },
    {
      "epoch": 1.1295925183700735,
      "grad_norm": 2.1744072437286377,
      "learning_rate": 1.3782358341301395e-05,
      "loss": 0.1294,
      "step": 1691
    },
    {
      "epoch": 1.1302605210420842,
      "grad_norm": 4.764275074005127,
      "learning_rate": 1.3775881795275817e-05,
      "loss": 0.2004,
      "step": 1692
    },
    {
      "epoch": 1.130928523714095,
      "grad_norm": 1.6336150169372559,
      "learning_rate": 1.3769403401547907e-05,
      "loss": 0.0891,
      "step": 1693
    },
    {
      "epoch": 1.1315965263861056,
      "grad_norm": 6.907833099365234,
      "learning_rate": 1.3762923163287818e-05,
      "loss": 0.1432,
      "step": 1694
    },
    {
      "epoch": 1.1322645290581161,
      "grad_norm": 3.1012189388275146,
      "learning_rate": 1.3756441083666614e-05,
      "loss": 0.1888,
      "step": 1695
    },
    {
      "epoch": 1.1329325317301269,
      "grad_norm": 10.601176261901855,
      "learning_rate": 1.3749957165856259e-05,
      "loss": 0.5312,
      "step": 1696
    },
    {
      "epoch": 1.1336005344021376,
      "grad_norm": 7.958766937255859,
      "learning_rate": 1.3743471413029608e-05,
      "loss": 0.2737,
      "step": 1697
    },
    {
      "epoch": 1.1342685370741483,
      "grad_norm": 2.010666608810425,
      "learning_rate": 1.3736983828360422e-05,
      "loss": 0.1369,
      "step": 1698
    },
    {
      "epoch": 1.134936539746159,
      "grad_norm": 2.2107129096984863,
      "learning_rate": 1.3730494415023363e-05,
      "loss": 0.0813,
      "step": 1699
    },
    {
      "epoch": 1.1356045424181698,
      "grad_norm": 2.8633487224578857,
      "learning_rate": 1.3724003176193979e-05,
      "loss": 0.147,
      "step": 1700
    },
    {
      "epoch": 1.1362725450901803,
      "grad_norm": 1.764877438545227,
      "learning_rate": 1.3717510115048709e-05,
      "loss": 0.1308,
      "step": 1701
    },
    {
      "epoch": 1.136940547762191,
      "grad_norm": 1.0465227365493774,
      "learning_rate": 1.3711015234764896e-05,
      "loss": 0.1138,
      "step": 1702
    },
    {
      "epoch": 1.1376085504342017,
      "grad_norm": 2.983628988265991,
      "learning_rate": 1.3704518538520757e-05,
      "loss": 0.1293,
      "step": 1703
    },
    {
      "epoch": 1.1382765531062125,
      "grad_norm": 3.6482901573181152,
      "learning_rate": 1.3698020029495417e-05,
      "loss": 0.1633,
      "step": 1704
    },
    {
      "epoch": 1.1389445557782232,
      "grad_norm": 1.4472299814224243,
      "learning_rate": 1.369151971086887e-05,
      "loss": 0.1463,
      "step": 1705
    },
    {
      "epoch": 1.1396125584502337,
      "grad_norm": 2.758291244506836,
      "learning_rate": 1.3685017585822005e-05,
      "loss": 0.1558,
      "step": 1706
    },
    {
      "epoch": 1.1402805611222444,
      "grad_norm": 4.352512836456299,
      "learning_rate": 1.3678513657536595e-05,
      "loss": 0.2016,
      "step": 1707
    },
    {
      "epoch": 1.1409485637942551,
      "grad_norm": 1.765929102897644,
      "learning_rate": 1.3672007929195292e-05,
      "loss": 0.1034,
      "step": 1708
    },
    {
      "epoch": 1.1416165664662659,
      "grad_norm": 0.17731928825378418,
      "learning_rate": 1.366550040398163e-05,
      "loss": 0.0023,
      "step": 1709
    },
    {
      "epoch": 1.1422845691382766,
      "grad_norm": 1.4026572704315186,
      "learning_rate": 1.3658991085080027e-05,
      "loss": 0.1546,
      "step": 1710
    },
    {
      "epoch": 1.1429525718102873,
      "grad_norm": 2.093914270401001,
      "learning_rate": 1.3652479975675765e-05,
      "loss": 0.1074,
      "step": 1711
    },
    {
      "epoch": 1.143620574482298,
      "grad_norm": 0.5133715271949768,
      "learning_rate": 1.3645967078955022e-05,
      "loss": 0.0059,
      "step": 1712
    },
    {
      "epoch": 1.1442885771543085,
      "grad_norm": 6.042745113372803,
      "learning_rate": 1.3639452398104834e-05,
      "loss": 0.2489,
      "step": 1713
    },
    {
      "epoch": 1.1449565798263193,
      "grad_norm": 7.563048839569092,
      "learning_rate": 1.3632935936313119e-05,
      "loss": 0.2531,
      "step": 1714
    },
    {
      "epoch": 1.14562458249833,
      "grad_norm": 5.111445903778076,
      "learning_rate": 1.3626417696768659e-05,
      "loss": 0.1279,
      "step": 1715
    },
    {
      "epoch": 1.1462925851703407,
      "grad_norm": 5.227911472320557,
      "learning_rate": 1.3619897682661117e-05,
      "loss": 0.2369,
      "step": 1716
    },
    {
      "epoch": 1.1469605878423514,
      "grad_norm": 16.390283584594727,
      "learning_rate": 1.3613375897181012e-05,
      "loss": 0.6929,
      "step": 1717
    },
    {
      "epoch": 1.147628590514362,
      "grad_norm": 1.6384800672531128,
      "learning_rate": 1.3606852343519743e-05,
      "loss": 0.1566,
      "step": 1718
    },
    {
      "epoch": 1.1482965931863727,
      "grad_norm": 2.150634527206421,
      "learning_rate": 1.360032702486956e-05,
      "loss": 0.1115,
      "step": 1719
    },
    {
      "epoch": 1.1489645958583834,
      "grad_norm": 2.725055694580078,
      "learning_rate": 1.3593799944423587e-05,
      "loss": 0.1514,
      "step": 1720
    },
    {
      "epoch": 1.1496325985303941,
      "grad_norm": 2.518908977508545,
      "learning_rate": 1.3587271105375805e-05,
      "loss": 0.1969,
      "step": 1721
    },
    {
      "epoch": 1.1503006012024048,
      "grad_norm": 1.6649796962738037,
      "learning_rate": 1.3580740510921065e-05,
      "loss": 0.134,
      "step": 1722
    },
    {
      "epoch": 1.1509686038744156,
      "grad_norm": 2.400996685028076,
      "learning_rate": 1.3574208164255057e-05,
      "loss": 0.1921,
      "step": 1723
    },
    {
      "epoch": 1.1516366065464263,
      "grad_norm": 1.8272759914398193,
      "learning_rate": 1.356767406857435e-05,
      "loss": 0.1202,
      "step": 1724
    },
    {
      "epoch": 1.1523046092184368,
      "grad_norm": 0.3098028302192688,
      "learning_rate": 1.3561138227076355e-05,
      "loss": 0.0046,
      "step": 1725
    },
    {
      "epoch": 1.1529726118904475,
      "grad_norm": 10.18330192565918,
      "learning_rate": 1.3554600642959346e-05,
      "loss": 0.59,
      "step": 1726
    },
    {
      "epoch": 1.1536406145624583,
      "grad_norm": 3.2774651050567627,
      "learning_rate": 1.3548061319422443e-05,
      "loss": 0.151,
      "step": 1727
    },
    {
      "epoch": 1.154308617234469,
      "grad_norm": 1.9979753494262695,
      "learning_rate": 1.3541520259665621e-05,
      "loss": 0.1683,
      "step": 1728
    },
    {
      "epoch": 1.1549766199064797,
      "grad_norm": 1.1845345497131348,
      "learning_rate": 1.3534977466889704e-05,
      "loss": 0.126,
      "step": 1729
    },
    {
      "epoch": 1.1556446225784902,
      "grad_norm": 0.5559751391410828,
      "learning_rate": 1.3528432944296362e-05,
      "loss": 0.0077,
      "step": 1730
    },
    {
      "epoch": 1.156312625250501,
      "grad_norm": 2.1369287967681885,
      "learning_rate": 1.3521886695088115e-05,
      "loss": 0.1097,
      "step": 1731
    },
    {
      "epoch": 1.1569806279225117,
      "grad_norm": 2.4464142322540283,
      "learning_rate": 1.3515338722468322e-05,
      "loss": 0.0439,
      "step": 1732
    },
    {
      "epoch": 1.1576486305945224,
      "grad_norm": 2.550356864929199,
      "learning_rate": 1.3508789029641196e-05,
      "loss": 0.1078,
      "step": 1733
    },
    {
      "epoch": 1.1583166332665331,
      "grad_norm": 2.428516149520874,
      "learning_rate": 1.3502237619811777e-05,
      "loss": 0.1375,
      "step": 1734
    },
    {
      "epoch": 1.1589846359385438,
      "grad_norm": 2.114778995513916,
      "learning_rate": 1.3495684496185963e-05,
      "loss": 0.1796,
      "step": 1735
    },
    {
      "epoch": 1.1596526386105546,
      "grad_norm": 0.40593037009239197,
      "learning_rate": 1.3489129661970472e-05,
      "loss": 0.0049,
      "step": 1736
    },
    {
      "epoch": 1.160320641282565,
      "grad_norm": 3.1703572273254395,
      "learning_rate": 1.3482573120372873e-05,
      "loss": 0.2366,
      "step": 1737
    },
    {
      "epoch": 1.1609886439545758,
      "grad_norm": 1.1351687908172607,
      "learning_rate": 1.3476014874601562e-05,
      "loss": 0.0538,
      "step": 1738
    },
    {
      "epoch": 1.1616566466265865,
      "grad_norm": 2.0855085849761963,
      "learning_rate": 1.3469454927865777e-05,
      "loss": 0.1491,
      "step": 1739
    },
    {
      "epoch": 1.1623246492985972,
      "grad_norm": 2.534186601638794,
      "learning_rate": 1.346289328337558e-05,
      "loss": 0.1157,
      "step": 1740
    },
    {
      "epoch": 1.162992651970608,
      "grad_norm": 1.9334884881973267,
      "learning_rate": 1.3456329944341869e-05,
      "loss": 0.1149,
      "step": 1741
    },
    {
      "epoch": 1.1636606546426185,
      "grad_norm": 1.6176403760910034,
      "learning_rate": 1.344976491397637e-05,
      "loss": 0.028,
      "step": 1742
    },
    {
      "epoch": 1.1643286573146292,
      "grad_norm": 1.5357344150543213,
      "learning_rate": 1.3443198195491633e-05,
      "loss": 0.0215,
      "step": 1743
    },
    {
      "epoch": 1.16499665998664,
      "grad_norm": 0.9921671748161316,
      "learning_rate": 1.3436629792101043e-05,
      "loss": 0.0548,
      "step": 1744
    },
    {
      "epoch": 1.1656646626586507,
      "grad_norm": 4.841264247894287,
      "learning_rate": 1.3430059707018802e-05,
      "loss": 0.1916,
      "step": 1745
    },
    {
      "epoch": 1.1663326653306614,
      "grad_norm": 0.49334296584129333,
      "learning_rate": 1.3423487943459934e-05,
      "loss": 0.0067,
      "step": 1746
    },
    {
      "epoch": 1.167000668002672,
      "grad_norm": 2.300377130508423,
      "learning_rate": 1.3416914504640292e-05,
      "loss": 0.1086,
      "step": 1747
    },
    {
      "epoch": 1.1676686706746826,
      "grad_norm": 1.6083788871765137,
      "learning_rate": 1.3410339393776541e-05,
      "loss": 0.1211,
      "step": 1748
    },
    {
      "epoch": 1.1683366733466933,
      "grad_norm": 1.7312644720077515,
      "learning_rate": 1.3403762614086169e-05,
      "loss": 0.1059,
      "step": 1749
    },
    {
      "epoch": 1.169004676018704,
      "grad_norm": 2.857358932495117,
      "learning_rate": 1.3397184168787473e-05,
      "loss": 0.1144,
      "step": 1750
    },
    {
      "epoch": 1.1696726786907148,
      "grad_norm": 2.692861557006836,
      "learning_rate": 1.3390604061099581e-05,
      "loss": 0.1128,
      "step": 1751
    },
    {
      "epoch": 1.1703406813627255,
      "grad_norm": 2.5138087272644043,
      "learning_rate": 1.3384022294242418e-05,
      "loss": 0.1033,
      "step": 1752
    },
    {
      "epoch": 1.1710086840347362,
      "grad_norm": 1.8744077682495117,
      "learning_rate": 1.3377438871436726e-05,
      "loss": 0.0987,
      "step": 1753
    },
    {
      "epoch": 1.1716766867067467,
      "grad_norm": 1.9267780780792236,
      "learning_rate": 1.3370853795904064e-05,
      "loss": 0.1466,
      "step": 1754
    },
    {
      "epoch": 1.1723446893787575,
      "grad_norm": 0.4702875316143036,
      "learning_rate": 1.3364267070866788e-05,
      "loss": 0.0038,
      "step": 1755
    },
    {
      "epoch": 1.1730126920507682,
      "grad_norm": 6.543980121612549,
      "learning_rate": 1.3357678699548071e-05,
      "loss": 0.166,
      "step": 1756
    },
    {
      "epoch": 1.173680694722779,
      "grad_norm": 1.3098911046981812,
      "learning_rate": 1.3351088685171889e-05,
      "loss": 0.0153,
      "step": 1757
    },
    {
      "epoch": 1.1743486973947896,
      "grad_norm": 3.78564190864563,
      "learning_rate": 1.3344497030963023e-05,
      "loss": 0.2036,
      "step": 1758
    },
    {
      "epoch": 1.1750167000668004,
      "grad_norm": 3.1556124687194824,
      "learning_rate": 1.3337903740147047e-05,
      "loss": 0.0916,
      "step": 1759
    },
    {
      "epoch": 1.1756847027388109,
      "grad_norm": 6.107469081878662,
      "learning_rate": 1.333130881595035e-05,
      "loss": 0.1386,
      "step": 1760
    },
    {
      "epoch": 1.1763527054108216,
      "grad_norm": 0.5329599380493164,
      "learning_rate": 1.3324712261600113e-05,
      "loss": 0.0064,
      "step": 1761
    },
    {
      "epoch": 1.1770207080828323,
      "grad_norm": 1.9943896532058716,
      "learning_rate": 1.3318114080324316e-05,
      "loss": 0.1603,
      "step": 1762
    },
    {
      "epoch": 1.177688710754843,
      "grad_norm": 2.7045652866363525,
      "learning_rate": 1.3311514275351728e-05,
      "loss": 0.15,
      "step": 1763
    },
    {
      "epoch": 1.1783567134268538,
      "grad_norm": 7.568323612213135,
      "learning_rate": 1.3304912849911929e-05,
      "loss": 0.0873,
      "step": 1764
    },
    {
      "epoch": 1.1790247160988643,
      "grad_norm": 0.44823670387268066,
      "learning_rate": 1.3298309807235274e-05,
      "loss": 0.005,
      "step": 1765
    },
    {
      "epoch": 1.179692718770875,
      "grad_norm": 0.1180763766169548,
      "learning_rate": 1.3291705150552924e-05,
      "loss": 0.002,
      "step": 1766
    },
    {
      "epoch": 1.1803607214428857,
      "grad_norm": 14.755428314208984,
      "learning_rate": 1.3285098883096819e-05,
      "loss": 0.6532,
      "step": 1767
    },
    {
      "epoch": 1.1810287241148965,
      "grad_norm": 2.376014471054077,
      "learning_rate": 1.327849100809969e-05,
      "loss": 0.0916,
      "step": 1768
    },
    {
      "epoch": 1.1816967267869072,
      "grad_norm": 1.3996891975402832,
      "learning_rate": 1.3271881528795061e-05,
      "loss": 0.0657,
      "step": 1769
    },
    {
      "epoch": 1.182364729458918,
      "grad_norm": 3.3395981788635254,
      "learning_rate": 1.3265270448417234e-05,
      "loss": 0.126,
      "step": 1770
    },
    {
      "epoch": 1.1830327321309286,
      "grad_norm": 9.430473327636719,
      "learning_rate": 1.3258657770201295e-05,
      "loss": 0.367,
      "step": 1771
    },
    {
      "epoch": 1.1837007348029391,
      "grad_norm": 2.276036024093628,
      "learning_rate": 1.3252043497383116e-05,
      "loss": 0.125,
      "step": 1772
    },
    {
      "epoch": 1.1843687374749499,
      "grad_norm": 5.1944499015808105,
      "learning_rate": 1.3245427633199347e-05,
      "loss": 0.2047,
      "step": 1773
    },
    {
      "epoch": 1.1850367401469606,
      "grad_norm": 1.5853266716003418,
      "learning_rate": 1.3238810180887413e-05,
      "loss": 0.0715,
      "step": 1774
    },
    {
      "epoch": 1.1857047428189713,
      "grad_norm": 2.4620416164398193,
      "learning_rate": 1.3232191143685525e-05,
      "loss": 0.0373,
      "step": 1775
    },
    {
      "epoch": 1.186372745490982,
      "grad_norm": 0.6400215029716492,
      "learning_rate": 1.322557052483266e-05,
      "loss": 0.0081,
      "step": 1776
    },
    {
      "epoch": 1.1870407481629925,
      "grad_norm": 7.209100246429443,
      "learning_rate": 1.3218948327568577e-05,
      "loss": 0.1591,
      "step": 1777
    },
    {
      "epoch": 1.1877087508350033,
      "grad_norm": 1.0418976545333862,
      "learning_rate": 1.3212324555133799e-05,
      "loss": 0.0129,
      "step": 1778
    },
    {
      "epoch": 1.188376753507014,
      "grad_norm": 7.731141090393066,
      "learning_rate": 1.320569921076963e-05,
      "loss": 0.1268,
      "step": 1779
    },
    {
      "epoch": 1.1890447561790247,
      "grad_norm": 0.7075985670089722,
      "learning_rate": 1.3199072297718132e-05,
      "loss": 0.0066,
      "step": 1780
    },
    {
      "epoch": 1.1897127588510354,
      "grad_norm": 2.4330852031707764,
      "learning_rate": 1.3192443819222145e-05,
      "loss": 0.157,
      "step": 1781
    },
    {
      "epoch": 1.1903807615230462,
      "grad_norm": 10.809422492980957,
      "learning_rate": 1.3185813778525265e-05,
      "loss": 0.4151,
      "step": 1782
    },
    {
      "epoch": 1.191048764195057,
      "grad_norm": 9.021320343017578,
      "learning_rate": 1.3179182178871864e-05,
      "loss": 0.1618,
      "step": 1783
    },
    {
      "epoch": 1.1917167668670674,
      "grad_norm": 0.0901668593287468,
      "learning_rate": 1.3172549023507067e-05,
      "loss": 0.0013,
      "step": 1784
    },
    {
      "epoch": 1.1923847695390781,
      "grad_norm": 1.5454000234603882,
      "learning_rate": 1.3165914315676764e-05,
      "loss": 0.0775,
      "step": 1785
    },
    {
      "epoch": 1.1930527722110889,
      "grad_norm": 8.054964065551758,
      "learning_rate": 1.3159278058627605e-05,
      "loss": 0.4231,
      "step": 1786
    },
    {
      "epoch": 1.1937207748830996,
      "grad_norm": 2.6346938610076904,
      "learning_rate": 1.3152640255606999e-05,
      "loss": 0.0464,
      "step": 1787
    },
    {
      "epoch": 1.1943887775551103,
      "grad_norm": 5.3896708488464355,
      "learning_rate": 1.3146000909863106e-05,
      "loss": 0.3954,
      "step": 1788
    },
    {
      "epoch": 1.1950567802271208,
      "grad_norm": 1.0204191207885742,
      "learning_rate": 1.3139360024644854e-05,
      "loss": 0.0113,
      "step": 1789
    },
    {
      "epoch": 1.1957247828991315,
      "grad_norm": 0.11566873639822006,
      "learning_rate": 1.3132717603201903e-05,
      "loss": 0.0014,
      "step": 1790
    },
    {
      "epoch": 1.1963927855711423,
      "grad_norm": 2.8346095085144043,
      "learning_rate": 1.312607364878469e-05,
      "loss": 0.1627,
      "step": 1791
    },
    {
      "epoch": 1.197060788243153,
      "grad_norm": 1.540583848953247,
      "learning_rate": 1.3119428164644379e-05,
      "loss": 0.0173,
      "step": 1792
    },
    {
      "epoch": 1.1977287909151637,
      "grad_norm": 11.588374137878418,
      "learning_rate": 1.3112781154032901e-05,
      "loss": 0.5591,
      "step": 1793
    },
    {
      "epoch": 1.1983967935871744,
      "grad_norm": 4.344937801361084,
      "learning_rate": 1.3106132620202919e-05,
      "loss": 0.2923,
      "step": 1794
    },
    {
      "epoch": 1.1990647962591852,
      "grad_norm": 2.494398593902588,
      "learning_rate": 1.3099482566407853e-05,
      "loss": 0.1062,
      "step": 1795
    },
    {
      "epoch": 1.1997327989311957,
      "grad_norm": 2.545546293258667,
      "learning_rate": 1.3092830995901857e-05,
      "loss": 0.0943,
      "step": 1796
    },
    {
      "epoch": 1.2004008016032064,
      "grad_norm": 0.3729010820388794,
      "learning_rate": 1.308617791193984e-05,
      "loss": 0.0053,
      "step": 1797
    },
    {
      "epoch": 1.2010688042752171,
      "grad_norm": 1.4640507698059082,
      "learning_rate": 1.3079523317777438e-05,
      "loss": 0.0863,
      "step": 1798
    },
    {
      "epoch": 1.2017368069472278,
      "grad_norm": 6.477165222167969,
      "learning_rate": 1.3072867216671034e-05,
      "loss": 0.3803,
      "step": 1799
    },
    {
      "epoch": 1.2024048096192386,
      "grad_norm": 0.2534328103065491,
      "learning_rate": 1.3066209611877748e-05,
      "loss": 0.0024,
      "step": 1800
    },
    {
      "epoch": 1.203072812291249,
      "grad_norm": 4.293600559234619,
      "learning_rate": 1.3059550506655425e-05,
      "loss": 0.219,
      "step": 1801
    },
    {
      "epoch": 1.2037408149632598,
      "grad_norm": 1.7972723245620728,
      "learning_rate": 1.3052889904262667e-05,
      "loss": 0.0764,
      "step": 1802
    },
    {
      "epoch": 1.2044088176352705,
      "grad_norm": 0.20788195729255676,
      "learning_rate": 1.3046227807958785e-05,
      "loss": 0.0033,
      "step": 1803
    },
    {
      "epoch": 1.2050768203072812,
      "grad_norm": 2.2621841430664062,
      "learning_rate": 1.3039564221003835e-05,
      "loss": 0.1572,
      "step": 1804
    },
    {
      "epoch": 1.205744822979292,
      "grad_norm": 3.668426275253296,
      "learning_rate": 1.3032899146658595e-05,
      "loss": 0.1811,
      "step": 1805
    },
    {
      "epoch": 1.2064128256513027,
      "grad_norm": 1.4309322834014893,
      "learning_rate": 1.3026232588184578e-05,
      "loss": 0.0211,
      "step": 1806
    },
    {
      "epoch": 1.2070808283233132,
      "grad_norm": 2.3156089782714844,
      "learning_rate": 1.3019564548844019e-05,
      "loss": 0.1117,
      "step": 1807
    },
    {
      "epoch": 1.207748830995324,
      "grad_norm": 10.60390853881836,
      "learning_rate": 1.3012895031899877e-05,
      "loss": 0.247,
      "step": 1808
    },
    {
      "epoch": 1.2084168336673347,
      "grad_norm": 3.234255313873291,
      "learning_rate": 1.3006224040615833e-05,
      "loss": 0.1328,
      "step": 1809
    },
    {
      "epoch": 1.2090848363393454,
      "grad_norm": 12.679518699645996,
      "learning_rate": 1.2999551578256297e-05,
      "loss": 0.1974,
      "step": 1810
    },
    {
      "epoch": 1.209752839011356,
      "grad_norm": 3.7148537635803223,
      "learning_rate": 1.299287764808639e-05,
      "loss": 0.2958,
      "step": 1811
    },
    {
      "epoch": 1.2104208416833666,
      "grad_norm": 2.273638963699341,
      "learning_rate": 1.2986202253371956e-05,
      "loss": 0.051,
      "step": 1812
    },
    {
      "epoch": 1.2110888443553773,
      "grad_norm": 11.684416770935059,
      "learning_rate": 1.2979525397379551e-05,
      "loss": 0.6519,
      "step": 1813
    },
    {
      "epoch": 1.211756847027388,
      "grad_norm": 2.024646043777466,
      "learning_rate": 1.2972847083376456e-05,
      "loss": 0.14,
      "step": 1814
    },
    {
      "epoch": 1.2124248496993988,
      "grad_norm": 1.159638524055481,
      "learning_rate": 1.2966167314630655e-05,
      "loss": 0.0168,
      "step": 1815
    },
    {
      "epoch": 1.2130928523714095,
      "grad_norm": 1.839646339416504,
      "learning_rate": 1.295948609441085e-05,
      "loss": 0.0799,
      "step": 1816
    },
    {
      "epoch": 1.2137608550434202,
      "grad_norm": 2.025752305984497,
      "learning_rate": 1.2952803425986444e-05,
      "loss": 0.1353,
      "step": 1817
    },
    {
      "epoch": 1.214428857715431,
      "grad_norm": 2.7939159870147705,
      "learning_rate": 1.2946119312627565e-05,
      "loss": 0.03,
      "step": 1818
    },
    {
      "epoch": 1.2150968603874415,
      "grad_norm": 4.281050205230713,
      "learning_rate": 1.2939433757605035e-05,
      "loss": 0.099,
      "step": 1819
    },
    {
      "epoch": 1.2157648630594522,
      "grad_norm": 1.7115601301193237,
      "learning_rate": 1.2932746764190387e-05,
      "loss": 0.0792,
      "step": 1820
    },
    {
      "epoch": 1.216432865731463,
      "grad_norm": 3.0910515785217285,
      "learning_rate": 1.2926058335655852e-05,
      "loss": 0.1869,
      "step": 1821
    },
    {
      "epoch": 1.2171008684034736,
      "grad_norm": 1.4567497968673706,
      "learning_rate": 1.291936847527437e-05,
      "loss": 0.1122,
      "step": 1822
    },
    {
      "epoch": 1.2177688710754844,
      "grad_norm": 1.2799701690673828,
      "learning_rate": 1.2912677186319582e-05,
      "loss": 0.0644,
      "step": 1823
    },
    {
      "epoch": 1.2184368737474949,
      "grad_norm": 7.2781596183776855,
      "learning_rate": 1.2905984472065823e-05,
      "loss": 0.289,
      "step": 1824
    },
    {
      "epoch": 1.2191048764195056,
      "grad_norm": 1.5399824380874634,
      "learning_rate": 1.2899290335788122e-05,
      "loss": 0.1213,
      "step": 1825
    },
    {
      "epoch": 1.2197728790915163,
      "grad_norm": 4.207780838012695,
      "learning_rate": 1.2892594780762217e-05,
      "loss": 0.0583,
      "step": 1826
    },
    {
      "epoch": 1.220440881763527,
      "grad_norm": 0.5987990498542786,
      "learning_rate": 1.2885897810264534e-05,
      "loss": 0.0074,
      "step": 1827
    },
    {
      "epoch": 1.2211088844355378,
      "grad_norm": 8.261184692382812,
      "learning_rate": 1.2879199427572185e-05,
      "loss": 0.3724,
      "step": 1828
    },
    {
      "epoch": 1.2217768871075485,
      "grad_norm": 2.726661205291748,
      "learning_rate": 1.2872499635962975e-05,
      "loss": 0.0582,
      "step": 1829
    },
    {
      "epoch": 1.2224448897795592,
      "grad_norm": 8.664633750915527,
      "learning_rate": 1.2865798438715414e-05,
      "loss": 0.1629,
      "step": 1830
    },
    {
      "epoch": 1.2231128924515697,
      "grad_norm": 0.10335735231637955,
      "learning_rate": 1.285909583910868e-05,
      "loss": 0.0012,
      "step": 1831
    },
    {
      "epoch": 1.2237808951235805,
      "grad_norm": 0.48342278599739075,
      "learning_rate": 1.2852391840422644e-05,
      "loss": 0.0057,
      "step": 1832
    },
    {
      "epoch": 1.2244488977955912,
      "grad_norm": 0.13385406136512756,
      "learning_rate": 1.2845686445937867e-05,
      "loss": 0.0017,
      "step": 1833
    },
    {
      "epoch": 1.225116900467602,
      "grad_norm": 2.828594923019409,
      "learning_rate": 1.2838979658935584e-05,
      "loss": 0.0851,
      "step": 1834
    },
    {
      "epoch": 1.2257849031396126,
      "grad_norm": 3.434767007827759,
      "learning_rate": 1.283227148269772e-05,
      "loss": 0.177,
      "step": 1835
    },
    {
      "epoch": 1.2264529058116231,
      "grad_norm": 8.603550910949707,
      "learning_rate": 1.2825561920506873e-05,
      "loss": 0.1074,
      "step": 1836
    },
    {
      "epoch": 1.2271209084836339,
      "grad_norm": 1.757095217704773,
      "learning_rate": 1.2818850975646327e-05,
      "loss": 0.1126,
      "step": 1837
    },
    {
      "epoch": 1.2277889111556446,
      "grad_norm": 1.610085368156433,
      "learning_rate": 1.281213865140003e-05,
      "loss": 0.0921,
      "step": 1838
    },
    {
      "epoch": 1.2284569138276553,
      "grad_norm": 2.7750158309936523,
      "learning_rate": 1.2805424951052618e-05,
      "loss": 0.0666,
      "step": 1839
    },
    {
      "epoch": 1.229124916499666,
      "grad_norm": 4.638598442077637,
      "learning_rate": 1.279870987788939e-05,
      "loss": 0.0634,
      "step": 1840
    },
    {
      "epoch": 1.2297929191716768,
      "grad_norm": 3.3303709030151367,
      "learning_rate": 1.2791993435196331e-05,
      "loss": 0.1858,
      "step": 1841
    },
    {
      "epoch": 1.2304609218436875,
      "grad_norm": 0.9375535845756531,
      "learning_rate": 1.278527562626008e-05,
      "loss": 0.0499,
      "step": 1842
    },
    {
      "epoch": 1.231128924515698,
      "grad_norm": 3.4807746410369873,
      "learning_rate": 1.2778556454367954e-05,
      "loss": 0.1964,
      "step": 1843
    },
    {
      "epoch": 1.2317969271877087,
      "grad_norm": 5.634031772613525,
      "learning_rate": 1.2771835922807931e-05,
      "loss": 0.256,
      "step": 1844
    },
    {
      "epoch": 1.2324649298597194,
      "grad_norm": 1.6984741687774658,
      "learning_rate": 1.2765114034868664e-05,
      "loss": 0.0354,
      "step": 1845
    },
    {
      "epoch": 1.2331329325317302,
      "grad_norm": 2.500272750854492,
      "learning_rate": 1.2758390793839458e-05,
      "loss": 0.1198,
      "step": 1846
    },
    {
      "epoch": 1.233800935203741,
      "grad_norm": 2.6999785900115967,
      "learning_rate": 1.275166620301029e-05,
      "loss": 0.1851,
      "step": 1847
    },
    {
      "epoch": 1.2344689378757514,
      "grad_norm": 4.256070137023926,
      "learning_rate": 1.2744940265671787e-05,
      "loss": 0.1471,
      "step": 1848
    },
    {
      "epoch": 1.2351369405477621,
      "grad_norm": 3.2652809619903564,
      "learning_rate": 1.2738212985115251e-05,
      "loss": 0.0665,
      "step": 1849
    },
    {
      "epoch": 1.2358049432197729,
      "grad_norm": 5.4972243309021,
      "learning_rate": 1.2731484364632623e-05,
      "loss": 0.3181,
      "step": 1850
    },
    {
      "epoch": 1.2364729458917836,
      "grad_norm": 4.201982021331787,
      "learning_rate": 1.272475440751651e-05,
      "loss": 0.0504,
      "step": 1851
    },
    {
      "epoch": 1.2371409485637943,
      "grad_norm": 2.668693780899048,
      "learning_rate": 1.2718023117060172e-05,
      "loss": 0.1241,
      "step": 1852
    },
    {
      "epoch": 1.237808951235805,
      "grad_norm": 1.7918428182601929,
      "learning_rate": 1.2711290496557523e-05,
      "loss": 0.0203,
      "step": 1853
    },
    {
      "epoch": 1.2384769539078155,
      "grad_norm": 2.5301246643066406,
      "learning_rate": 1.2704556549303124e-05,
      "loss": 0.1494,
      "step": 1854
    },
    {
      "epoch": 1.2391449565798263,
      "grad_norm": 6.984292030334473,
      "learning_rate": 1.2697821278592184e-05,
      "loss": 0.0975,
      "step": 1855
    },
    {
      "epoch": 1.239812959251837,
      "grad_norm": 0.534090518951416,
      "learning_rate": 1.2691084687720565e-05,
      "loss": 0.0063,
      "step": 1856
    },
    {
      "epoch": 1.2404809619238477,
      "grad_norm": 3.5843491554260254,
      "learning_rate": 1.2684346779984771e-05,
      "loss": 0.1774,
      "step": 1857
    },
    {
      "epoch": 1.2411489645958584,
      "grad_norm": 0.5771036744117737,
      "learning_rate": 1.2677607558681952e-05,
      "loss": 0.0068,
      "step": 1858
    },
    {
      "epoch": 1.2418169672678692,
      "grad_norm": 1.7938964366912842,
      "learning_rate": 1.2670867027109903e-05,
      "loss": 0.0735,
      "step": 1859
    },
    {
      "epoch": 1.2424849699398797,
      "grad_norm": 2.9356837272644043,
      "learning_rate": 1.2664125188567055e-05,
      "loss": 0.1365,
      "step": 1860
    },
    {
      "epoch": 1.2431529726118904,
      "grad_norm": 0.6693158149719238,
      "learning_rate": 1.2657382046352481e-05,
      "loss": 0.0077,
      "step": 1861
    },
    {
      "epoch": 1.2438209752839011,
      "grad_norm": 1.0669387578964233,
      "learning_rate": 1.2650637603765898e-05,
      "loss": 0.0116,
      "step": 1862
    },
    {
      "epoch": 1.2444889779559118,
      "grad_norm": 13.902589797973633,
      "learning_rate": 1.2643891864107646e-05,
      "loss": 0.5263,
      "step": 1863
    },
    {
      "epoch": 1.2451569806279226,
      "grad_norm": 0.5019221305847168,
      "learning_rate": 1.2637144830678711e-05,
      "loss": 0.0052,
      "step": 1864
    },
    {
      "epoch": 1.2458249832999333,
      "grad_norm": 2.2909090518951416,
      "learning_rate": 1.2630396506780706e-05,
      "loss": 0.0781,
      "step": 1865
    },
    {
      "epoch": 1.2464929859719438,
      "grad_norm": 4.790821075439453,
      "learning_rate": 1.2623646895715883e-05,
      "loss": 0.1131,
      "step": 1866
    },
    {
      "epoch": 1.2471609886439545,
      "grad_norm": 10.384148597717285,
      "learning_rate": 1.2616896000787109e-05,
      "loss": 0.3622,
      "step": 1867
    },
    {
      "epoch": 1.2478289913159653,
      "grad_norm": 2.239683151245117,
      "learning_rate": 1.2610143825297903e-05,
      "loss": 0.1865,
      "step": 1868
    },
    {
      "epoch": 1.248496993987976,
      "grad_norm": 0.11302264034748077,
      "learning_rate": 1.2603390372552385e-05,
      "loss": 0.0019,
      "step": 1869
    },
    {
      "epoch": 1.2491649966599867,
      "grad_norm": 13.295823097229004,
      "learning_rate": 1.2596635645855315e-05,
      "loss": 0.8797,
      "step": 1870
    },
    {
      "epoch": 1.2498329993319972,
      "grad_norm": 9.839597702026367,
      "learning_rate": 1.2589879648512074e-05,
      "loss": 0.1858,
      "step": 1871
    },
    {
      "epoch": 1.250501002004008,
      "grad_norm": 3.364712953567505,
      "learning_rate": 1.2583122383828665e-05,
      "loss": 0.1258,
      "step": 1872
    },
    {
      "epoch": 1.2511690046760187,
      "grad_norm": 2.6790881156921387,
      "learning_rate": 1.2576363855111708e-05,
      "loss": 0.1397,
      "step": 1873
    },
    {
      "epoch": 1.2518370073480294,
      "grad_norm": 3.265705108642578,
      "learning_rate": 1.2569604065668443e-05,
      "loss": 0.1873,
      "step": 1874
    },
    {
      "epoch": 1.25250501002004,
      "grad_norm": 1.8607667684555054,
      "learning_rate": 1.2562843018806727e-05,
      "loss": 0.0824,
      "step": 1875
    },
    {
      "epoch": 1.2531730126920508,
      "grad_norm": 2.9469223022460938,
      "learning_rate": 1.2556080717835037e-05,
      "loss": 0.1239,
      "step": 1876
    },
    {
      "epoch": 1.2538410153640616,
      "grad_norm": 0.02240050956606865,
      "learning_rate": 1.2549317166062456e-05,
      "loss": 0.0006,
      "step": 1877
    },
    {
      "epoch": 1.254509018036072,
      "grad_norm": 2.741152286529541,
      "learning_rate": 1.2542552366798685e-05,
      "loss": 0.1812,
      "step": 1878
    },
    {
      "epoch": 1.2551770207080828,
      "grad_norm": 8.749763488769531,
      "learning_rate": 1.2535786323354026e-05,
      "loss": 0.3038,
      "step": 1879
    },
    {
      "epoch": 1.2558450233800935,
      "grad_norm": 8.706665992736816,
      "learning_rate": 1.2529019039039403e-05,
      "loss": 0.1216,
      "step": 1880
    },
    {
      "epoch": 1.2565130260521042,
      "grad_norm": 2.724821090698242,
      "learning_rate": 1.2522250517166344e-05,
      "loss": 0.1736,
      "step": 1881
    },
    {
      "epoch": 1.257181028724115,
      "grad_norm": 0.2551867365837097,
      "learning_rate": 1.2515480761046971e-05,
      "loss": 0.0037,
      "step": 1882
    },
    {
      "epoch": 1.2578490313961255,
      "grad_norm": 0.32648175954818726,
      "learning_rate": 1.2508709773994027e-05,
      "loss": 0.0038,
      "step": 1883
    },
    {
      "epoch": 1.2585170340681362,
      "grad_norm": 7.056275844573975,
      "learning_rate": 1.2501937559320842e-05,
      "loss": 0.2544,
      "step": 1884
    },
    {
      "epoch": 1.259185036740147,
      "grad_norm": 0.10728058964014053,
      "learning_rate": 1.2495164120341359e-05,
      "loss": 0.0014,
      "step": 1885
    },
    {
      "epoch": 1.2598530394121576,
      "grad_norm": 3.0455968379974365,
      "learning_rate": 1.2488389460370112e-05,
      "loss": 0.1418,
      "step": 1886
    },
    {
      "epoch": 1.2605210420841684,
      "grad_norm": 2.783923625946045,
      "learning_rate": 1.2481613582722233e-05,
      "loss": 0.2101,
      "step": 1887
    },
    {
      "epoch": 1.261189044756179,
      "grad_norm": 0.48606398701667786,
      "learning_rate": 1.2474836490713457e-05,
      "loss": 0.0067,
      "step": 1888
    },
    {
      "epoch": 1.2618570474281898,
      "grad_norm": 2.4795022010803223,
      "learning_rate": 1.2468058187660106e-05,
      "loss": 0.1241,
      "step": 1889
    },
    {
      "epoch": 1.2625250501002003,
      "grad_norm": 2.6979784965515137,
      "learning_rate": 1.2461278676879099e-05,
      "loss": 0.1693,
      "step": 1890
    },
    {
      "epoch": 1.263193052772211,
      "grad_norm": 1.7497743368148804,
      "learning_rate": 1.245449796168794e-05,
      "loss": 0.0195,
      "step": 1891
    },
    {
      "epoch": 1.2638610554442218,
      "grad_norm": 6.356441497802734,
      "learning_rate": 1.2447716045404727e-05,
      "loss": 0.1168,
      "step": 1892
    },
    {
      "epoch": 1.2645290581162325,
      "grad_norm": 2.7499964237213135,
      "learning_rate": 1.2440932931348149e-05,
      "loss": 0.2204,
      "step": 1893
    },
    {
      "epoch": 1.2651970607882432,
      "grad_norm": 1.8146973848342896,
      "learning_rate": 1.2434148622837471e-05,
      "loss": 0.0734,
      "step": 1894
    },
    {
      "epoch": 1.2658650634602537,
      "grad_norm": 9.65762996673584,
      "learning_rate": 1.2427363123192558e-05,
      "loss": 0.6451,
      "step": 1895
    },
    {
      "epoch": 1.2665330661322645,
      "grad_norm": 2.679277181625366,
      "learning_rate": 1.2420576435733838e-05,
      "loss": 0.1789,
      "step": 1896
    },
    {
      "epoch": 1.2672010688042752,
      "grad_norm": 4.351626396179199,
      "learning_rate": 1.2413788563782338e-05,
      "loss": 0.0819,
      "step": 1897
    },
    {
      "epoch": 1.267869071476286,
      "grad_norm": 1.6878414154052734,
      "learning_rate": 1.2406999510659654e-05,
      "loss": 0.1385,
      "step": 1898
    },
    {
      "epoch": 1.2685370741482966,
      "grad_norm": 11.506653785705566,
      "learning_rate": 1.2400209279687968e-05,
      "loss": 0.4843,
      "step": 1899
    },
    {
      "epoch": 1.2692050768203074,
      "grad_norm": 0.9198651909828186,
      "learning_rate": 1.2393417874190025e-05,
      "loss": 0.0092,
      "step": 1900
    },
    {
      "epoch": 1.269873079492318,
      "grad_norm": 2.5608484745025635,
      "learning_rate": 1.2386625297489165e-05,
      "loss": 0.0206,
      "step": 1901
    },
    {
      "epoch": 1.2705410821643286,
      "grad_norm": 0.2286377251148224,
      "learning_rate": 1.237983155290928e-05,
      "loss": 0.0022,
      "step": 1902
    },
    {
      "epoch": 1.2712090848363393,
      "grad_norm": 0.4171178936958313,
      "learning_rate": 1.2373036643774849e-05,
      "loss": 0.0044,
      "step": 1903
    },
    {
      "epoch": 1.27187708750835,
      "grad_norm": 4.0156168937683105,
      "learning_rate": 1.236624057341091e-05,
      "loss": 0.1038,
      "step": 1904
    },
    {
      "epoch": 1.2725450901803608,
      "grad_norm": 2.508451223373413,
      "learning_rate": 1.2359443345143078e-05,
      "loss": 0.0602,
      "step": 1905
    },
    {
      "epoch": 1.2732130928523713,
      "grad_norm": 2.4183788299560547,
      "learning_rate": 1.2352644962297531e-05,
      "loss": 0.0902,
      "step": 1906
    },
    {
      "epoch": 1.273881095524382,
      "grad_norm": 4.479345798492432,
      "learning_rate": 1.2345845428201009e-05,
      "loss": 0.0591,
      "step": 1907
    },
    {
      "epoch": 1.2745490981963927,
      "grad_norm": 0.9588969945907593,
      "learning_rate": 1.2339044746180826e-05,
      "loss": 0.011,
      "step": 1908
    },
    {
      "epoch": 1.2752171008684035,
      "grad_norm": 0.34448689222335815,
      "learning_rate": 1.2332242919564838e-05,
      "loss": 0.0041,
      "step": 1909
    },
    {
      "epoch": 1.2758851035404142,
      "grad_norm": 1.5059947967529297,
      "learning_rate": 1.2325439951681482e-05,
      "loss": 0.1079,
      "step": 1910
    },
    {
      "epoch": 1.276553106212425,
      "grad_norm": 3.617767572402954,
      "learning_rate": 1.2318635845859739e-05,
      "loss": 0.038,
      "step": 1911
    },
    {
      "epoch": 1.2772211088844356,
      "grad_norm": 9.38280963897705,
      "learning_rate": 1.2311830605429157e-05,
      "loss": 0.2698,
      "step": 1912
    },
    {
      "epoch": 1.2778891115564464,
      "grad_norm": 0.4943173825740814,
      "learning_rate": 1.2305024233719833e-05,
      "loss": 0.0052,
      "step": 1913
    },
    {
      "epoch": 1.2785571142284569,
      "grad_norm": 2.600909471511841,
      "learning_rate": 1.2298216734062419e-05,
      "loss": 0.0302,
      "step": 1914
    },
    {
      "epoch": 1.2792251169004676,
      "grad_norm": 3.337324380874634,
      "learning_rate": 1.2291408109788117e-05,
      "loss": 0.2486,
      "step": 1915
    },
    {
      "epoch": 1.2798931195724783,
      "grad_norm": 0.20466415584087372,
      "learning_rate": 1.2284598364228684e-05,
      "loss": 0.0022,
      "step": 1916
    },
    {
      "epoch": 1.280561122244489,
      "grad_norm": 0.032195646315813065,
      "learning_rate": 1.2277787500716424e-05,
      "loss": 0.0006,
      "step": 1917
    },
    {
      "epoch": 1.2812291249164995,
      "grad_norm": 1.695758581161499,
      "learning_rate": 1.2270975522584185e-05,
      "loss": 0.0756,
      "step": 1918
    },
    {
      "epoch": 1.2818971275885103,
      "grad_norm": 0.40382513403892517,
      "learning_rate": 1.2264162433165363e-05,
      "loss": 0.005,
      "step": 1919
    },
    {
      "epoch": 1.282565130260521,
      "grad_norm": 2.5960140228271484,
      "learning_rate": 1.2257348235793898e-05,
      "loss": 0.1637,
      "step": 1920
    },
    {
      "epoch": 1.2832331329325317,
      "grad_norm": 1.9416383504867554,
      "learning_rate": 1.2250532933804273e-05,
      "loss": 0.1135,
      "step": 1921
    },
    {
      "epoch": 1.2839011356045424,
      "grad_norm": 3.6557843685150146,
      "learning_rate": 1.2243716530531509e-05,
      "loss": 0.2622,
      "step": 1922
    },
    {
      "epoch": 1.2845691382765532,
      "grad_norm": 0.4310590326786041,
      "learning_rate": 1.2236899029311162e-05,
      "loss": 0.0047,
      "step": 1923
    },
    {
      "epoch": 1.285237140948564,
      "grad_norm": 11.529647827148438,
      "learning_rate": 1.2230080433479338e-05,
      "loss": 0.3099,
      "step": 1924
    },
    {
      "epoch": 1.2859051436205746,
      "grad_norm": 1.5383644104003906,
      "learning_rate": 1.2223260746372669e-05,
      "loss": 0.0406,
      "step": 1925
    },
    {
      "epoch": 1.2865731462925851,
      "grad_norm": 0.3107968270778656,
      "learning_rate": 1.2216439971328323e-05,
      "loss": 0.0028,
      "step": 1926
    },
    {
      "epoch": 1.2872411489645958,
      "grad_norm": 0.15902924537658691,
      "learning_rate": 1.2209618111683994e-05,
      "loss": 0.0016,
      "step": 1927
    },
    {
      "epoch": 1.2879091516366066,
      "grad_norm": 2.253561019897461,
      "learning_rate": 1.2202795170777923e-05,
      "loss": 0.1316,
      "step": 1928
    },
    {
      "epoch": 1.2885771543086173,
      "grad_norm": 10.977831840515137,
      "learning_rate": 1.2195971151948865e-05,
      "loss": 0.2674,
      "step": 1929
    },
    {
      "epoch": 1.2892451569806278,
      "grad_norm": 6.479000091552734,
      "learning_rate": 1.2189146058536108e-05,
      "loss": 0.2556,
      "step": 1930
    },
    {
      "epoch": 1.2899131596526385,
      "grad_norm": 2.4905407428741455,
      "learning_rate": 1.2182319893879464e-05,
      "loss": 0.0672,
      "step": 1931
    },
    {
      "epoch": 1.2905811623246493,
      "grad_norm": 3.59051251411438,
      "learning_rate": 1.2175492661319273e-05,
      "loss": 0.0526,
      "step": 1932
    },
    {
      "epoch": 1.29124916499666,
      "grad_norm": 5.471795082092285,
      "learning_rate": 1.2168664364196394e-05,
      "loss": 0.2073,
      "step": 1933
    },
    {
      "epoch": 1.2919171676686707,
      "grad_norm": 1.7959040403366089,
      "learning_rate": 1.2161835005852212e-05,
      "loss": 0.0422,
      "step": 1934
    },
    {
      "epoch": 1.2925851703406814,
      "grad_norm": 3.4365525245666504,
      "learning_rate": 1.2155004589628622e-05,
      "loss": 0.0867,
      "step": 1935
    },
    {
      "epoch": 1.2932531730126922,
      "grad_norm": 0.1342761367559433,
      "learning_rate": 1.2148173118868045e-05,
      "loss": 0.0017,
      "step": 1936
    },
    {
      "epoch": 1.2939211756847027,
      "grad_norm": 0.07721034437417984,
      "learning_rate": 1.2141340596913416e-05,
      "loss": 0.001,
      "step": 1937
    },
    {
      "epoch": 1.2945891783567134,
      "grad_norm": 3.079261302947998,
      "learning_rate": 1.213450702710818e-05,
      "loss": 0.1234,
      "step": 1938
    },
    {
      "epoch": 1.2952571810287241,
      "grad_norm": 3.654555082321167,
      "learning_rate": 1.2127672412796305e-05,
      "loss": 0.1531,
      "step": 1939
    },
    {
      "epoch": 1.2959251837007348,
      "grad_norm": 0.6768221259117126,
      "learning_rate": 1.2120836757322254e-05,
      "loss": 0.0066,
      "step": 1940
    },
    {
      "epoch": 1.2965931863727456,
      "grad_norm": 3.370046377182007,
      "learning_rate": 1.2114000064031018e-05,
      "loss": 0.0417,
      "step": 1941
    },
    {
      "epoch": 1.297261189044756,
      "grad_norm": 2.4655094146728516,
      "learning_rate": 1.2107162336268081e-05,
      "loss": 0.1955,
      "step": 1942
    },
    {
      "epoch": 1.2979291917167668,
      "grad_norm": 4.990944862365723,
      "learning_rate": 1.2100323577379444e-05,
      "loss": 0.2302,
      "step": 1943
    },
    {
      "epoch": 1.2985971943887775,
      "grad_norm": 2.888498306274414,
      "learning_rate": 1.2093483790711604e-05,
      "loss": 0.0427,
      "step": 1944
    },
    {
      "epoch": 1.2992651970607882,
      "grad_norm": 4.54564094543457,
      "learning_rate": 1.2086642979611564e-05,
      "loss": 0.2232,
      "step": 1945
    },
    {
      "epoch": 1.299933199732799,
      "grad_norm": 1.6964352130889893,
      "learning_rate": 1.207980114742683e-05,
      "loss": 0.1282,
      "step": 1946
    },
    {
      "epoch": 1.3006012024048097,
      "grad_norm": 2.7729270458221436,
      "learning_rate": 1.2072958297505411e-05,
      "loss": 0.1971,
      "step": 1947
    },
    {
      "epoch": 1.3012692050768204,
      "grad_norm": 2.5708324909210205,
      "learning_rate": 1.2066114433195802e-05,
      "loss": 0.0781,
      "step": 1948
    },
    {
      "epoch": 1.301937207748831,
      "grad_norm": 5.594278812408447,
      "learning_rate": 1.2059269557847007e-05,
      "loss": 0.2248,
      "step": 1949
    },
    {
      "epoch": 1.3026052104208417,
      "grad_norm": 4.21650505065918,
      "learning_rate": 1.2052423674808513e-05,
      "loss": 0.118,
      "step": 1950
    },
    {
      "epoch": 1.3032732130928524,
      "grad_norm": 0.7486047744750977,
      "learning_rate": 1.2045576787430318e-05,
      "loss": 0.0132,
      "step": 1951
    },
    {
      "epoch": 1.303941215764863,
      "grad_norm": 3.8947668075561523,
      "learning_rate": 1.2038728899062892e-05,
      "loss": 0.1537,
      "step": 1952
    },
    {
      "epoch": 1.3046092184368738,
      "grad_norm": 0.32549071311950684,
      "learning_rate": 1.2031880013057204e-05,
      "loss": 0.0041,
      "step": 1953
    },
    {
      "epoch": 1.3052772211088843,
      "grad_norm": 2.10367488861084,
      "learning_rate": 1.2025030132764713e-05,
      "loss": 0.1188,
      "step": 1954
    },
    {
      "epoch": 1.305945223780895,
      "grad_norm": 0.5730146765708923,
      "learning_rate": 1.2018179261537357e-05,
      "loss": 0.0063,
      "step": 1955
    },
    {
      "epoch": 1.3066132264529058,
      "grad_norm": 4.481100082397461,
      "learning_rate": 1.2011327402727568e-05,
      "loss": 0.0876,
      "step": 1956
    },
    {
      "epoch": 1.3072812291249165,
      "grad_norm": 0.6618708968162537,
      "learning_rate": 1.2004474559688257e-05,
      "loss": 0.01,
      "step": 1957
    },
    {
      "epoch": 1.3079492317969272,
      "grad_norm": 3.066652774810791,
      "learning_rate": 1.1997620735772816e-05,
      "loss": 0.1566,
      "step": 1958
    },
    {
      "epoch": 1.308617234468938,
      "grad_norm": 10.3060941696167,
      "learning_rate": 1.1990765934335115e-05,
      "loss": 0.4386,
      "step": 1959
    },
    {
      "epoch": 1.3092852371409487,
      "grad_norm": 0.7360090613365173,
      "learning_rate": 1.1983910158729508e-05,
      "loss": 0.009,
      "step": 1960
    },
    {
      "epoch": 1.3099532398129592,
      "grad_norm": 14.323484420776367,
      "learning_rate": 1.1977053412310821e-05,
      "loss": 0.2664,
      "step": 1961
    },
    {
      "epoch": 1.31062124248497,
      "grad_norm": 0.6051080226898193,
      "learning_rate": 1.197019569843436e-05,
      "loss": 0.0075,
      "step": 1962
    },
    {
      "epoch": 1.3112892451569806,
      "grad_norm": 9.024106979370117,
      "learning_rate": 1.1963337020455892e-05,
      "loss": 0.1677,
      "step": 1963
    },
    {
      "epoch": 1.3119572478289914,
      "grad_norm": 2.498844623565674,
      "learning_rate": 1.1956477381731678e-05,
      "loss": 0.119,
      "step": 1964
    },
    {
      "epoch": 1.3126252505010019,
      "grad_norm": 0.09872104972600937,
      "learning_rate": 1.1949616785618426e-05,
      "loss": 0.001,
      "step": 1965
    },
    {
      "epoch": 1.3132932531730126,
      "grad_norm": 0.10436980426311493,
      "learning_rate": 1.1942755235473327e-05,
      "loss": 0.0014,
      "step": 1966
    },
    {
      "epoch": 1.3139612558450233,
      "grad_norm": 5.065171718597412,
      "learning_rate": 1.1935892734654028e-05,
      "loss": 0.1641,
      "step": 1967
    },
    {
      "epoch": 1.314629258517034,
      "grad_norm": 1.7596858739852905,
      "learning_rate": 1.1929029286518659e-05,
      "loss": 0.0104,
      "step": 1968
    },
    {
      "epoch": 1.3152972611890448,
      "grad_norm": 3.0424208641052246,
      "learning_rate": 1.1922164894425791e-05,
      "loss": 0.1258,
      "step": 1969
    },
    {
      "epoch": 1.3159652638610555,
      "grad_norm": 2.6154465675354004,
      "learning_rate": 1.191529956173448e-05,
      "loss": 0.1035,
      "step": 1970
    },
    {
      "epoch": 1.3166332665330662,
      "grad_norm": 5.46614408493042,
      "learning_rate": 1.1908433291804217e-05,
      "loss": 0.0577,
      "step": 1971
    },
    {
      "epoch": 1.317301269205077,
      "grad_norm": 3.1529595851898193,
      "learning_rate": 1.1901566087994973e-05,
      "loss": 0.1456,
      "step": 1972
    },
    {
      "epoch": 1.3179692718770875,
      "grad_norm": 2.611229181289673,
      "learning_rate": 1.1894697953667165e-05,
      "loss": 0.109,
      "step": 1973
    },
    {
      "epoch": 1.3186372745490982,
      "grad_norm": 2.3999037742614746,
      "learning_rate": 1.1887828892181673e-05,
      "loss": 0.1022,
      "step": 1974
    },
    {
      "epoch": 1.319305277221109,
      "grad_norm": 0.1598290055990219,
      "learning_rate": 1.188095890689982e-05,
      "loss": 0.0019,
      "step": 1975
    },
    {
      "epoch": 1.3199732798931196,
      "grad_norm": 0.40832871198654175,
      "learning_rate": 1.187408800118339e-05,
      "loss": 0.0029,
      "step": 1976
    },
    {
      "epoch": 1.3206412825651301,
      "grad_norm": 11.067763328552246,
      "learning_rate": 1.1867216178394615e-05,
      "loss": 0.4062,
      "step": 1977
    },
    {
      "epoch": 1.3213092852371409,
      "grad_norm": 3.180058240890503,
      "learning_rate": 1.1860343441896172e-05,
      "loss": 0.234,
      "step": 1978
    },
    {
      "epoch": 1.3219772879091516,
      "grad_norm": 0.10637068748474121,
      "learning_rate": 1.1853469795051192e-05,
      "loss": 0.0012,
      "step": 1979
    },
    {
      "epoch": 1.3226452905811623,
      "grad_norm": 5.2779035568237305,
      "learning_rate": 1.1846595241223246e-05,
      "loss": 0.1486,
      "step": 1980
    },
    {
      "epoch": 1.323313293253173,
      "grad_norm": 1.611592173576355,
      "learning_rate": 1.183971978377635e-05,
      "loss": 0.0119,
      "step": 1981
    },
    {
      "epoch": 1.3239812959251838,
      "grad_norm": 11.006251335144043,
      "learning_rate": 1.1832843426074963e-05,
      "loss": 0.5265,
      "step": 1982
    },
    {
      "epoch": 1.3246492985971945,
      "grad_norm": 2.502718687057495,
      "learning_rate": 1.1825966171483987e-05,
      "loss": 0.1289,
      "step": 1983
    },
    {
      "epoch": 1.325317301269205,
      "grad_norm": 4.502584457397461,
      "learning_rate": 1.1819088023368759e-05,
      "loss": 0.2293,
      "step": 1984
    },
    {
      "epoch": 1.3259853039412157,
      "grad_norm": 5.881569862365723,
      "learning_rate": 1.1812208985095052e-05,
      "loss": 0.0633,
      "step": 1985
    },
    {
      "epoch": 1.3266533066132264,
      "grad_norm": 0.2987879812717438,
      "learning_rate": 1.180532906002908e-05,
      "loss": 0.0027,
      "step": 1986
    },
    {
      "epoch": 1.3273213092852372,
      "grad_norm": 5.826362609863281,
      "learning_rate": 1.179844825153749e-05,
      "loss": 0.1842,
      "step": 1987
    },
    {
      "epoch": 1.327989311957248,
      "grad_norm": 1.9911216497421265,
      "learning_rate": 1.179156656298735e-05,
      "loss": 0.0227,
      "step": 1988
    },
    {
      "epoch": 1.3286573146292584,
      "grad_norm": 0.05017169564962387,
      "learning_rate": 1.1784683997746178e-05,
      "loss": 0.0006,
      "step": 1989
    },
    {
      "epoch": 1.3293253173012691,
      "grad_norm": 12.954030990600586,
      "learning_rate": 1.1777800559181905e-05,
      "loss": 0.1677,
      "step": 1990
    },
    {
      "epoch": 1.3299933199732799,
      "grad_norm": 5.700976371765137,
      "learning_rate": 1.1770916250662899e-05,
      "loss": 0.2797,
      "step": 1991
    },
    {
      "epoch": 1.3306613226452906,
      "grad_norm": 2.631722927093506,
      "learning_rate": 1.1764031075557947e-05,
      "loss": 0.174,
      "step": 1992
    },
    {
      "epoch": 1.3313293253173013,
      "grad_norm": 3.6762406826019287,
      "learning_rate": 1.1757145037236266e-05,
      "loss": 0.0177,
      "step": 1993
    },
    {
      "epoch": 1.331997327989312,
      "grad_norm": 9.802023887634277,
      "learning_rate": 1.1750258139067489e-05,
      "loss": 0.3921,
      "step": 1994
    },
    {
      "epoch": 1.3326653306613228,
      "grad_norm": 1.7908437252044678,
      "learning_rate": 1.1743370384421678e-05,
      "loss": 0.0636,
      "step": 1995
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.934838056564331,
      "learning_rate": 1.1736481776669307e-05,
      "loss": 0.0101,
      "step": 1996
    },
    {
      "epoch": 1.334001336005344,
      "grad_norm": 2.1364612579345703,
      "learning_rate": 1.1729592319181266e-05,
      "loss": 0.1179,
      "step": 1997
    },
    {
      "epoch": 1.3346693386773547,
      "grad_norm": 0.5815781354904175,
      "learning_rate": 1.1722702015328868e-05,
      "loss": 0.0053,
      "step": 1998
    },
    {
      "epoch": 1.3353373413493654,
      "grad_norm": 0.17236892879009247,
      "learning_rate": 1.1715810868483841e-05,
      "loss": 0.0019,
      "step": 1999
    },
    {
      "epoch": 1.3360053440213762,
      "grad_norm": 1.9032458066940308,
      "learning_rate": 1.1708918882018315e-05,
      "loss": 0.0194,
      "step": 2000
    },
    {
      "epoch": 1.3366733466933867,
      "grad_norm": 11.45799732208252,
      "learning_rate": 1.1702026059304841e-05,
      "loss": 0.6054,
      "step": 2001
    },
    {
      "epoch": 1.3373413493653974,
      "grad_norm": 2.904507637023926,
      "learning_rate": 1.1695132403716372e-05,
      "loss": 0.1332,
      "step": 2002
    },
    {
      "epoch": 1.3380093520374081,
      "grad_norm": 0.19088321924209595,
      "learning_rate": 1.1688237918626273e-05,
      "loss": 0.0021,
      "step": 2003
    },
    {
      "epoch": 1.3386773547094188,
      "grad_norm": 4.587161540985107,
      "learning_rate": 1.1681342607408317e-05,
      "loss": 0.1843,
      "step": 2004
    },
    {
      "epoch": 1.3393453573814296,
      "grad_norm": 10.764163970947266,
      "learning_rate": 1.1674446473436674e-05,
      "loss": 0.4517,
      "step": 2005
    },
    {
      "epoch": 1.3400133600534403,
      "grad_norm": 0.03797950595617294,
      "learning_rate": 1.1667549520085921e-05,
      "loss": 0.0006,
      "step": 2006
    },
    {
      "epoch": 1.340681362725451,
      "grad_norm": 12.250236511230469,
      "learning_rate": 1.166065175073104e-05,
      "loss": 0.4933,
      "step": 2007
    },
    {
      "epoch": 1.3413493653974615,
      "grad_norm": 0.39050644636154175,
      "learning_rate": 1.1653753168747406e-05,
      "loss": 0.0036,
      "step": 2008
    },
    {
      "epoch": 1.3420173680694722,
      "grad_norm": 2.4278786182403564,
      "learning_rate": 1.1646853777510789e-05,
      "loss": 0.0531,
      "step": 2009
    },
    {
      "epoch": 1.342685370741483,
      "grad_norm": 0.04029546678066254,
      "learning_rate": 1.1639953580397367e-05,
      "loss": 0.0008,
      "step": 2010
    },
    {
      "epoch": 1.3433533734134937,
      "grad_norm": 1.1313368082046509,
      "learning_rate": 1.16330525807837e-05,
      "loss": 0.0331,
      "step": 2011
    },
    {
      "epoch": 1.3440213760855042,
      "grad_norm": 1.3866331577301025,
      "learning_rate": 1.1626150782046747e-05,
      "loss": 0.0143,
      "step": 2012
    },
    {
      "epoch": 1.344689378757515,
      "grad_norm": 3.6201653480529785,
      "learning_rate": 1.1619248187563855e-05,
      "loss": 0.2045,
      "step": 2013
    },
    {
      "epoch": 1.3453573814295257,
      "grad_norm": 1.9511754512786865,
      "learning_rate": 1.1612344800712769e-05,
      "loss": 0.0514,
      "step": 2014
    },
    {
      "epoch": 1.3460253841015364,
      "grad_norm": 0.19984903931617737,
      "learning_rate": 1.1605440624871606e-05,
      "loss": 0.0022,
      "step": 2015
    },
    {
      "epoch": 1.346693386773547,
      "grad_norm": 0.07781775295734406,
      "learning_rate": 1.1598535663418884e-05,
      "loss": 0.0012,
      "step": 2016
    },
    {
      "epoch": 1.3473613894455578,
      "grad_norm": 1.8353195190429688,
      "learning_rate": 1.1591629919733494e-05,
      "loss": 0.0855,
      "step": 2017
    },
    {
      "epoch": 1.3480293921175686,
      "grad_norm": 4.333816051483154,
      "learning_rate": 1.1584723397194724e-05,
      "loss": 0.1397,
      "step": 2018
    },
    {
      "epoch": 1.3486973947895793,
      "grad_norm": 2.8804545402526855,
      "learning_rate": 1.1577816099182222e-05,
      "loss": 0.1352,
      "step": 2019
    },
    {
      "epoch": 1.3493653974615898,
      "grad_norm": 0.011772853322327137,
      "learning_rate": 1.157090802907604e-05,
      "loss": 0.0004,
      "step": 2020
    },
    {
      "epoch": 1.3500334001336005,
      "grad_norm": 3.913569688796997,
      "learning_rate": 1.1563999190256585e-05,
      "loss": 0.2637,
      "step": 2021
    },
    {
      "epoch": 1.3507014028056112,
      "grad_norm": 3.213763952255249,
      "learning_rate": 1.155708958610466e-05,
      "loss": 0.1388,
      "step": 2022
    },
    {
      "epoch": 1.351369405477622,
      "grad_norm": 1.6020467281341553,
      "learning_rate": 1.155017922000143e-05,
      "loss": 0.0173,
      "step": 2023
    },
    {
      "epoch": 1.3520374081496325,
      "grad_norm": 0.02242942526936531,
      "learning_rate": 1.1543268095328433e-05,
      "loss": 0.0004,
      "step": 2024
    },
    {
      "epoch": 1.3527054108216432,
      "grad_norm": 0.07449879497289658,
      "learning_rate": 1.1536356215467582e-05,
      "loss": 0.001,
      "step": 2025
    },
    {
      "epoch": 1.353373413493654,
      "grad_norm": 3.950805187225342,
      "learning_rate": 1.1529443583801163e-05,
      "loss": 0.1207,
      "step": 2026
    },
    {
      "epoch": 1.3540414161656646,
      "grad_norm": 2.0245602130889893,
      "learning_rate": 1.1522530203711824e-05,
      "loss": 0.1783,
      "step": 2027
    },
    {
      "epoch": 1.3547094188376754,
      "grad_norm": 3.8225886821746826,
      "learning_rate": 1.151561607858258e-05,
      "loss": 0.1505,
      "step": 2028
    },
    {
      "epoch": 1.355377421509686,
      "grad_norm": 3.4385156631469727,
      "learning_rate": 1.1508701211796809e-05,
      "loss": 0.1677,
      "step": 2029
    },
    {
      "epoch": 1.3560454241816968,
      "grad_norm": 5.1103644371032715,
      "learning_rate": 1.150178560673826e-05,
      "loss": 0.2084,
      "step": 2030
    },
    {
      "epoch": 1.3567134268537075,
      "grad_norm": 3.8306057453155518,
      "learning_rate": 1.1494869266791036e-05,
      "loss": 0.23,
      "step": 2031
    },
    {
      "epoch": 1.357381429525718,
      "grad_norm": 3.445841073989868,
      "learning_rate": 1.1487952195339599e-05,
      "loss": 0.1462,
      "step": 2032
    },
    {
      "epoch": 1.3580494321977288,
      "grad_norm": 2.645098924636841,
      "learning_rate": 1.1481034395768772e-05,
      "loss": 0.0569,
      "step": 2033
    },
    {
      "epoch": 1.3587174348697395,
      "grad_norm": 4.126931667327881,
      "learning_rate": 1.1474115871463736e-05,
      "loss": 0.1782,
      "step": 2034
    },
    {
      "epoch": 1.3593854375417502,
      "grad_norm": 0.09784124791622162,
      "learning_rate": 1.1467196625810022e-05,
      "loss": 0.0011,
      "step": 2035
    },
    {
      "epoch": 1.3600534402137607,
      "grad_norm": 6.0595011711120605,
      "learning_rate": 1.1460276662193516e-05,
      "loss": 0.0792,
      "step": 2036
    },
    {
      "epoch": 1.3607214428857715,
      "grad_norm": 4.890544414520264,
      "learning_rate": 1.145335598400046e-05,
      "loss": 0.1044,
      "step": 2037
    },
    {
      "epoch": 1.3613894455577822,
      "grad_norm": 3.63376784324646,
      "learning_rate": 1.1446434594617435e-05,
      "loss": 0.0403,
      "step": 2038
    },
    {
      "epoch": 1.362057448229793,
      "grad_norm": 6.973910808563232,
      "learning_rate": 1.143951249743138e-05,
      "loss": 0.0998,
      "step": 2039
    },
    {
      "epoch": 1.3627254509018036,
      "grad_norm": 3.2326900959014893,
      "learning_rate": 1.1432589695829576e-05,
      "loss": 0.1608,
      "step": 2040
    },
    {
      "epoch": 1.3633934535738144,
      "grad_norm": 10.466724395751953,
      "learning_rate": 1.1425666193199652e-05,
      "loss": 0.2014,
      "step": 2041
    },
    {
      "epoch": 1.364061456245825,
      "grad_norm": 8.333910942077637,
      "learning_rate": 1.141874199292957e-05,
      "loss": 0.3703,
      "step": 2042
    },
    {
      "epoch": 1.3647294589178356,
      "grad_norm": 3.378275156021118,
      "learning_rate": 1.1411817098407647e-05,
      "loss": 0.1282,
      "step": 2043
    },
    {
      "epoch": 1.3653974615898463,
      "grad_norm": 1.75465989112854,
      "learning_rate": 1.1404891513022532e-05,
      "loss": 0.0111,
      "step": 2044
    },
    {
      "epoch": 1.366065464261857,
      "grad_norm": 0.02767154388129711,
      "learning_rate": 1.1397965240163215e-05,
      "loss": 0.0007,
      "step": 2045
    },
    {
      "epoch": 1.3667334669338678,
      "grad_norm": 9.164636611938477,
      "learning_rate": 1.1391038283219017e-05,
      "loss": 0.1223,
      "step": 2046
    },
    {
      "epoch": 1.3674014696058785,
      "grad_norm": 1.0443778038024902,
      "learning_rate": 1.1384110645579604e-05,
      "loss": 0.03,
      "step": 2047
    },
    {
      "epoch": 1.368069472277889,
      "grad_norm": 0.0483354814350605,
      "learning_rate": 1.1377182330634961e-05,
      "loss": 0.0008,
      "step": 2048
    },
    {
      "epoch": 1.3687374749498997,
      "grad_norm": 3.652534008026123,
      "learning_rate": 1.1370253341775424e-05,
      "loss": 0.2038,
      "step": 2049
    },
    {
      "epoch": 1.3694054776219104,
      "grad_norm": 1.5854172706604004,
      "learning_rate": 1.1363323682391631e-05,
      "loss": 0.0776,
      "step": 2050
    },
    {
      "epoch": 1.3700734802939212,
      "grad_norm": 15.961661338806152,
      "learning_rate": 1.1356393355874575e-05,
      "loss": 1.0386,
      "step": 2051
    },
    {
      "epoch": 1.370741482965932,
      "grad_norm": 14.086624145507812,
      "learning_rate": 1.1349462365615563e-05,
      "loss": 0.6308,
      "step": 2052
    },
    {
      "epoch": 1.3714094856379426,
      "grad_norm": 3.370622158050537,
      "learning_rate": 1.1342530715006227e-05,
      "loss": 0.1311,
      "step": 2053
    },
    {
      "epoch": 1.3720774883099534,
      "grad_norm": 10.429689407348633,
      "learning_rate": 1.1335598407438526e-05,
      "loss": 0.1331,
      "step": 2054
    },
    {
      "epoch": 1.3727454909819639,
      "grad_norm": 2.5095245838165283,
      "learning_rate": 1.1328665446304736e-05,
      "loss": 0.061,
      "step": 2055
    },
    {
      "epoch": 1.3734134936539746,
      "grad_norm": 11.433356285095215,
      "learning_rate": 1.1321731834997453e-05,
      "loss": 0.4654,
      "step": 2056
    },
    {
      "epoch": 1.3740814963259853,
      "grad_norm": 0.03931128606200218,
      "learning_rate": 1.1314797576909596e-05,
      "loss": 0.0005,
      "step": 2057
    },
    {
      "epoch": 1.374749498997996,
      "grad_norm": 10.487654685974121,
      "learning_rate": 1.1307862675434397e-05,
      "loss": 0.4276,
      "step": 2058
    },
    {
      "epoch": 1.3754175016700068,
      "grad_norm": 3.001102924346924,
      "learning_rate": 1.1300927133965406e-05,
      "loss": 0.1208,
      "step": 2059
    },
    {
      "epoch": 1.3760855043420173,
      "grad_norm": 5.084828853607178,
      "learning_rate": 1.1293990955896476e-05,
      "loss": 0.2047,
      "step": 2060
    },
    {
      "epoch": 1.376753507014028,
      "grad_norm": 3.8444299697875977,
      "learning_rate": 1.1287054144621784e-05,
      "loss": 0.1224,
      "step": 2061
    },
    {
      "epoch": 1.3774215096860387,
      "grad_norm": 11.468467712402344,
      "learning_rate": 1.1280116703535813e-05,
      "loss": 0.4317,
      "step": 2062
    },
    {
      "epoch": 1.3780895123580494,
      "grad_norm": 10.757438659667969,
      "learning_rate": 1.1273178636033351e-05,
      "loss": 0.4568,
      "step": 2063
    },
    {
      "epoch": 1.3787575150300602,
      "grad_norm": 6.062522888183594,
      "learning_rate": 1.1266239945509496e-05,
      "loss": 0.1871,
      "step": 2064
    },
    {
      "epoch": 1.379425517702071,
      "grad_norm": 1.0546023845672607,
      "learning_rate": 1.1259300635359647e-05,
      "loss": 0.0127,
      "step": 2065
    },
    {
      "epoch": 1.3800935203740816,
      "grad_norm": 2.2935543060302734,
      "learning_rate": 1.125236070897951e-05,
      "loss": 0.1369,
      "step": 2066
    },
    {
      "epoch": 1.3807615230460921,
      "grad_norm": 3.156702995300293,
      "learning_rate": 1.1245420169765093e-05,
      "loss": 0.2078,
      "step": 2067
    },
    {
      "epoch": 1.3814295257181028,
      "grad_norm": 2.2296276092529297,
      "learning_rate": 1.1238479021112703e-05,
      "loss": 0.1052,
      "step": 2068
    },
    {
      "epoch": 1.3820975283901136,
      "grad_norm": 2.399172782897949,
      "learning_rate": 1.1231537266418937e-05,
      "loss": 0.1158,
      "step": 2069
    },
    {
      "epoch": 1.3827655310621243,
      "grad_norm": 0.4141915440559387,
      "learning_rate": 1.1224594909080704e-05,
      "loss": 0.005,
      "step": 2070
    },
    {
      "epoch": 1.3834335337341348,
      "grad_norm": 0.013777295127511024,
      "learning_rate": 1.1217651952495197e-05,
      "loss": 0.0003,
      "step": 2071
    },
    {
      "epoch": 1.3841015364061455,
      "grad_norm": 2.0532193183898926,
      "learning_rate": 1.1210708400059905e-05,
      "loss": 0.1499,
      "step": 2072
    },
    {
      "epoch": 1.3847695390781563,
      "grad_norm": 0.11667437106370926,
      "learning_rate": 1.1203764255172606e-05,
      "loss": 0.0014,
      "step": 2073
    },
    {
      "epoch": 1.385437541750167,
      "grad_norm": 11.114053726196289,
      "learning_rate": 1.1196819521231376e-05,
      "loss": 0.2836,
      "step": 2074
    },
    {
      "epoch": 1.3861055444221777,
      "grad_norm": 2.113840103149414,
      "learning_rate": 1.1189874201634567e-05,
      "loss": 0.1112,
      "step": 2075
    },
    {
      "epoch": 1.3867735470941884,
      "grad_norm": 1.6945379972457886,
      "learning_rate": 1.1182928299780836e-05,
      "loss": 0.1026,
      "step": 2076
    },
    {
      "epoch": 1.3874415497661992,
      "grad_norm": 12.004676818847656,
      "learning_rate": 1.1175981819069099e-05,
      "loss": 0.2888,
      "step": 2077
    },
    {
      "epoch": 1.3881095524382099,
      "grad_norm": 0.9531795978546143,
      "learning_rate": 1.1169034762898578e-05,
      "loss": 0.0108,
      "step": 2078
    },
    {
      "epoch": 1.3887775551102204,
      "grad_norm": 14.653752326965332,
      "learning_rate": 1.1162087134668766e-05,
      "loss": 0.5128,
      "step": 2079
    },
    {
      "epoch": 1.389445557782231,
      "grad_norm": 2.2726376056671143,
      "learning_rate": 1.1155138937779439e-05,
      "loss": 0.1511,
      "step": 2080
    },
    {
      "epoch": 1.3901135604542418,
      "grad_norm": 8.52685546875,
      "learning_rate": 1.1148190175630649e-05,
      "loss": 0.2822,
      "step": 2081
    },
    {
      "epoch": 1.3907815631262526,
      "grad_norm": 0.15942078828811646,
      "learning_rate": 1.1141240851622728e-05,
      "loss": 0.0023,
      "step": 2082
    },
    {
      "epoch": 1.391449565798263,
      "grad_norm": 2.4867019653320312,
      "learning_rate": 1.1134290969156281e-05,
      "loss": 0.1848,
      "step": 2083
    },
    {
      "epoch": 1.3921175684702738,
      "grad_norm": 2.5365211963653564,
      "learning_rate": 1.112734053163218e-05,
      "loss": 0.1539,
      "step": 2084
    },
    {
      "epoch": 1.3927855711422845,
      "grad_norm": 8.260981559753418,
      "learning_rate": 1.1120389542451584e-05,
      "loss": 0.0557,
      "step": 2085
    },
    {
      "epoch": 1.3934535738142952,
      "grad_norm": 0.3504634499549866,
      "learning_rate": 1.1113438005015905e-05,
      "loss": 0.0034,
      "step": 2086
    },
    {
      "epoch": 1.394121576486306,
      "grad_norm": 1.8811036348342896,
      "learning_rate": 1.1106485922726837e-05,
      "loss": 0.1171,
      "step": 2087
    },
    {
      "epoch": 1.3947895791583167,
      "grad_norm": 0.07405876368284225,
      "learning_rate": 1.1099533298986331e-05,
      "loss": 0.0012,
      "step": 2088
    },
    {
      "epoch": 1.3954575818303274,
      "grad_norm": 0.2804931700229645,
      "learning_rate": 1.1092580137196611e-05,
      "loss": 0.0034,
      "step": 2089
    },
    {
      "epoch": 1.3961255845023381,
      "grad_norm": 0.22020648419857025,
      "learning_rate": 1.1085626440760154e-05,
      "loss": 0.0021,
      "step": 2090
    },
    {
      "epoch": 1.3967935871743486,
      "grad_norm": 1.295376181602478,
      "learning_rate": 1.1078672213079706e-05,
      "loss": 0.0195,
      "step": 2091
    },
    {
      "epoch": 1.3974615898463594,
      "grad_norm": 5.683321952819824,
      "learning_rate": 1.1071717457558273e-05,
      "loss": 0.1013,
      "step": 2092
    },
    {
      "epoch": 1.39812959251837,
      "grad_norm": 2.2851457595825195,
      "learning_rate": 1.106476217759912e-05,
      "loss": 0.1151,
      "step": 2093
    },
    {
      "epoch": 1.3987975951903808,
      "grad_norm": 3.6375539302825928,
      "learning_rate": 1.1057806376605762e-05,
      "loss": 0.0765,
      "step": 2094
    },
    {
      "epoch": 1.3994655978623913,
      "grad_norm": 0.2877194583415985,
      "learning_rate": 1.1050850057981976e-05,
      "loss": 0.0034,
      "step": 2095
    },
    {
      "epoch": 1.400133600534402,
      "grad_norm": 3.458773136138916,
      "learning_rate": 1.1043893225131788e-05,
      "loss": 0.1234,
      "step": 2096
    },
    {
      "epoch": 1.4008016032064128,
      "grad_norm": 0.4905601441860199,
      "learning_rate": 1.1036935881459478e-05,
      "loss": 0.0053,
      "step": 2097
    },
    {
      "epoch": 1.4014696058784235,
      "grad_norm": 2.2195446491241455,
      "learning_rate": 1.102997803036958e-05,
      "loss": 0.043,
      "step": 2098
    },
    {
      "epoch": 1.4021376085504342,
      "grad_norm": 0.30863264203071594,
      "learning_rate": 1.1023019675266862e-05,
      "loss": 0.0035,
      "step": 2099
    },
    {
      "epoch": 1.402805611222445,
      "grad_norm": 1.677811861038208,
      "learning_rate": 1.1016060819556354e-05,
      "loss": 0.1069,
      "step": 2100
    },
    {
      "epoch": 1.4034736138944557,
      "grad_norm": 2.259094715118408,
      "learning_rate": 1.1009101466643326e-05,
      "loss": 0.1997,
      "step": 2101
    },
    {
      "epoch": 1.4041416165664662,
      "grad_norm": 2.358438730239868,
      "learning_rate": 1.100214161993329e-05,
      "loss": 0.083,
      "step": 2102
    },
    {
      "epoch": 1.404809619238477,
      "grad_norm": 3.47778582572937,
      "learning_rate": 1.0995181282832e-05,
      "loss": 0.1837,
      "step": 2103
    },
    {
      "epoch": 1.4054776219104876,
      "grad_norm": 1.9898821115493774,
      "learning_rate": 1.0988220458745444e-05,
      "loss": 0.1765,
      "step": 2104
    },
    {
      "epoch": 1.4061456245824984,
      "grad_norm": 2.6697018146514893,
      "learning_rate": 1.0981259151079863e-05,
      "loss": 0.1464,
      "step": 2105
    },
    {
      "epoch": 1.406813627254509,
      "grad_norm": 3.8919427394866943,
      "learning_rate": 1.0974297363241724e-05,
      "loss": 0.0606,
      "step": 2106
    },
    {
      "epoch": 1.4074816299265196,
      "grad_norm": 3.5980849266052246,
      "learning_rate": 1.096733509863773e-05,
      "loss": 0.1829,
      "step": 2107
    },
    {
      "epoch": 1.4081496325985303,
      "grad_norm": 4.068410396575928,
      "learning_rate": 1.0960372360674817e-05,
      "loss": 0.085,
      "step": 2108
    },
    {
      "epoch": 1.408817635270541,
      "grad_norm": 2.1692137718200684,
      "learning_rate": 1.0953409152760153e-05,
      "loss": 0.1055,
      "step": 2109
    },
    {
      "epoch": 1.4094856379425518,
      "grad_norm": 0.3945663869380951,
      "learning_rate": 1.0946445478301142e-05,
      "loss": 0.0032,
      "step": 2110
    },
    {
      "epoch": 1.4101536406145625,
      "grad_norm": 1.9364476203918457,
      "learning_rate": 1.0939481340705407e-05,
      "loss": 0.0527,
      "step": 2111
    },
    {
      "epoch": 1.4108216432865732,
      "grad_norm": 8.068188667297363,
      "learning_rate": 1.0932516743380803e-05,
      "loss": 0.2023,
      "step": 2112
    },
    {
      "epoch": 1.411489645958584,
      "grad_norm": 1.035363793373108,
      "learning_rate": 1.0925551689735407e-05,
      "loss": 0.0125,
      "step": 2113
    },
    {
      "epoch": 1.4121576486305945,
      "grad_norm": 1.614492654800415,
      "learning_rate": 1.0918586183177527e-05,
      "loss": 0.1164,
      "step": 2114
    },
    {
      "epoch": 1.4128256513026052,
      "grad_norm": 0.07146644592285156,
      "learning_rate": 1.0911620227115678e-05,
      "loss": 0.0009,
      "step": 2115
    },
    {
      "epoch": 1.413493653974616,
      "grad_norm": 3.3913135528564453,
      "learning_rate": 1.0904653824958614e-05,
      "loss": 0.2024,
      "step": 2116
    },
    {
      "epoch": 1.4141616566466266,
      "grad_norm": 0.37075915932655334,
      "learning_rate": 1.0897686980115285e-05,
      "loss": 0.0042,
      "step": 2117
    },
    {
      "epoch": 1.4148296593186374,
      "grad_norm": 1.3518844842910767,
      "learning_rate": 1.089071969599488e-05,
      "loss": 0.0165,
      "step": 2118
    },
    {
      "epoch": 1.4154976619906479,
      "grad_norm": 3.1761276721954346,
      "learning_rate": 1.0883751976006787e-05,
      "loss": 0.1323,
      "step": 2119
    },
    {
      "epoch": 1.4161656646626586,
      "grad_norm": 4.716592788696289,
      "learning_rate": 1.0876783823560616e-05,
      "loss": 0.2151,
      "step": 2120
    },
    {
      "epoch": 1.4168336673346693,
      "grad_norm": 1.4872294664382935,
      "learning_rate": 1.0869815242066182e-05,
      "loss": 0.1673,
      "step": 2121
    },
    {
      "epoch": 1.41750167000668,
      "grad_norm": 13.072918891906738,
      "learning_rate": 1.0862846234933517e-05,
      "loss": 0.5104,
      "step": 2122
    },
    {
      "epoch": 1.4181696726786908,
      "grad_norm": 3.0991339683532715,
      "learning_rate": 1.0855876805572854e-05,
      "loss": 0.0877,
      "step": 2123
    },
    {
      "epoch": 1.4188376753507015,
      "grad_norm": 5.964071750640869,
      "learning_rate": 1.0848906957394642e-05,
      "loss": 0.164,
      "step": 2124
    },
    {
      "epoch": 1.4195056780227122,
      "grad_norm": 2.1698858737945557,
      "learning_rate": 1.0841936693809522e-05,
      "loss": 0.1349,
      "step": 2125
    },
    {
      "epoch": 1.4201736806947227,
      "grad_norm": 0.14300251007080078,
      "learning_rate": 1.0834966018228353e-05,
      "loss": 0.0015,
      "step": 2126
    },
    {
      "epoch": 1.4208416833667334,
      "grad_norm": 1.793101191520691,
      "learning_rate": 1.0827994934062178e-05,
      "loss": 0.1446,
      "step": 2127
    },
    {
      "epoch": 1.4215096860387442,
      "grad_norm": 13.50455093383789,
      "learning_rate": 1.0821023444722263e-05,
      "loss": 0.4026,
      "step": 2128
    },
    {
      "epoch": 1.422177688710755,
      "grad_norm": 0.09883542358875275,
      "learning_rate": 1.0814051553620051e-05,
      "loss": 0.001,
      "step": 2129
    },
    {
      "epoch": 1.4228456913827654,
      "grad_norm": 2.919553279876709,
      "learning_rate": 1.080707926416719e-05,
      "loss": 0.1553,
      "step": 2130
    },
    {
      "epoch": 1.4235136940547761,
      "grad_norm": 3.2386045455932617,
      "learning_rate": 1.0800106579775526e-05,
      "loss": 0.0707,
      "step": 2131
    },
    {
      "epoch": 1.4241816967267868,
      "grad_norm": 8.984063148498535,
      "learning_rate": 1.0793133503857093e-05,
      "loss": 0.4004,
      "step": 2132
    },
    {
      "epoch": 1.4248496993987976,
      "grad_norm": 0.8253176212310791,
      "learning_rate": 1.0786160039824122e-05,
      "loss": 0.007,
      "step": 2133
    },
    {
      "epoch": 1.4255177020708083,
      "grad_norm": 3.7888944149017334,
      "learning_rate": 1.0779186191089029e-05,
      "loss": 0.0978,
      "step": 2134
    },
    {
      "epoch": 1.426185704742819,
      "grad_norm": 2.8708810806274414,
      "learning_rate": 1.0772211961064416e-05,
      "loss": 0.1036,
      "step": 2135
    },
    {
      "epoch": 1.4268537074148298,
      "grad_norm": 5.099099159240723,
      "learning_rate": 1.0765237353163079e-05,
      "loss": 0.3084,
      "step": 2136
    },
    {
      "epoch": 1.4275217100868405,
      "grad_norm": 3.1978206634521484,
      "learning_rate": 1.0758262370797996e-05,
      "loss": 0.1154,
      "step": 2137
    },
    {
      "epoch": 1.428189712758851,
      "grad_norm": 0.9377039670944214,
      "learning_rate": 1.0751287017382328e-05,
      "loss": 0.0145,
      "step": 2138
    },
    {
      "epoch": 1.4288577154308617,
      "grad_norm": 2.904958486557007,
      "learning_rate": 1.0744311296329415e-05,
      "loss": 0.0234,
      "step": 2139
    },
    {
      "epoch": 1.4295257181028724,
      "grad_norm": 1.0957242250442505,
      "learning_rate": 1.0737335211052779e-05,
      "loss": 0.0153,
      "step": 2140
    },
    {
      "epoch": 1.4301937207748832,
      "grad_norm": 4.006924629211426,
      "learning_rate": 1.0730358764966124e-05,
      "loss": 0.0364,
      "step": 2141
    },
    {
      "epoch": 1.4308617234468937,
      "grad_norm": 0.3003964424133301,
      "learning_rate": 1.0723381961483325e-05,
      "loss": 0.0028,
      "step": 2142
    },
    {
      "epoch": 1.4315297261189044,
      "grad_norm": 2.978724718093872,
      "learning_rate": 1.0716404804018433e-05,
      "loss": 0.2343,
      "step": 2143
    },
    {
      "epoch": 1.4321977287909151,
      "grad_norm": 3.1271309852600098,
      "learning_rate": 1.070942729598567e-05,
      "loss": 0.0749,
      "step": 2144
    },
    {
      "epoch": 1.4328657314629258,
      "grad_norm": 5.153314590454102,
      "learning_rate": 1.0702449440799439e-05,
      "loss": 0.1198,
      "step": 2145
    },
    {
      "epoch": 1.4335337341349366,
      "grad_norm": 1.292345404624939,
      "learning_rate": 1.06954712418743e-05,
      "loss": 0.0982,
      "step": 2146
    },
    {
      "epoch": 1.4342017368069473,
      "grad_norm": 2.2580344676971436,
      "learning_rate": 1.0688492702624998e-05,
      "loss": 0.1237,
      "step": 2147
    },
    {
      "epoch": 1.434869739478958,
      "grad_norm": 1.619633674621582,
      "learning_rate": 1.0681513826466421e-05,
      "loss": 0.1004,
      "step": 2148
    },
    {
      "epoch": 1.4355377421509685,
      "grad_norm": 4.726366996765137,
      "learning_rate": 1.0674534616813643e-05,
      "loss": 0.0805,
      "step": 2149
    },
    {
      "epoch": 1.4362057448229792,
      "grad_norm": 1.6311575174331665,
      "learning_rate": 1.066755507708189e-05,
      "loss": 0.0523,
      "step": 2150
    },
    {
      "epoch": 1.43687374749499,
      "grad_norm": 0.8271433711051941,
      "learning_rate": 1.066057521068656e-05,
      "loss": 0.0144,
      "step": 2151
    },
    {
      "epoch": 1.4375417501670007,
      "grad_norm": 2.697553873062134,
      "learning_rate": 1.065359502104319e-05,
      "loss": 0.0869,
      "step": 2152
    },
    {
      "epoch": 1.4382097528390114,
      "grad_norm": 3.3946502208709717,
      "learning_rate": 1.0646614511567504e-05,
      "loss": 0.2428,
      "step": 2153
    },
    {
      "epoch": 1.438877755511022,
      "grad_norm": 1.8892813920974731,
      "learning_rate": 1.0639633685675357e-05,
      "loss": 0.1526,
      "step": 2154
    },
    {
      "epoch": 1.4395457581830327,
      "grad_norm": 2.032611131668091,
      "learning_rate": 1.0632652546782774e-05,
      "loss": 0.1028,
      "step": 2155
    },
    {
      "epoch": 1.4402137608550434,
      "grad_norm": 0.028065595775842667,
      "learning_rate": 1.062567109830592e-05,
      "loss": 0.0005,
      "step": 2156
    },
    {
      "epoch": 1.440881763527054,
      "grad_norm": 4.362680435180664,
      "learning_rate": 1.0618689343661133e-05,
      "loss": 0.3232,
      "step": 2157
    },
    {
      "epoch": 1.4415497661990648,
      "grad_norm": 9.831268310546875,
      "learning_rate": 1.061170728626488e-05,
      "loss": 0.4312,
      "step": 2158
    },
    {
      "epoch": 1.4422177688710756,
      "grad_norm": 2.6158626079559326,
      "learning_rate": 1.0604724929533783e-05,
      "loss": 0.1011,
      "step": 2159
    },
    {
      "epoch": 1.4428857715430863,
      "grad_norm": 0.01395554468035698,
      "learning_rate": 1.0597742276884615e-05,
      "loss": 0.0003,
      "step": 2160
    },
    {
      "epoch": 1.4435537742150968,
      "grad_norm": 7.579878807067871,
      "learning_rate": 1.0590759331734289e-05,
      "loss": 0.2548,
      "step": 2161
    },
    {
      "epoch": 1.4442217768871075,
      "grad_norm": 4.962337017059326,
      "learning_rate": 1.0583776097499858e-05,
      "loss": 0.1778,
      "step": 2162
    },
    {
      "epoch": 1.4448897795591182,
      "grad_norm": 3.7161741256713867,
      "learning_rate": 1.0576792577598524e-05,
      "loss": 0.052,
      "step": 2163
    },
    {
      "epoch": 1.445557782231129,
      "grad_norm": 1.0612207651138306,
      "learning_rate": 1.056980877544763e-05,
      "loss": 0.0119,
      "step": 2164
    },
    {
      "epoch": 1.4462257849031397,
      "grad_norm": 12.05540943145752,
      "learning_rate": 1.0562824694464643e-05,
      "loss": 0.5147,
      "step": 2165
    },
    {
      "epoch": 1.4468937875751502,
      "grad_norm": 2.3604276180267334,
      "learning_rate": 1.0555840338067184e-05,
      "loss": 0.1491,
      "step": 2166
    },
    {
      "epoch": 1.447561790247161,
      "grad_norm": 1.7397198677062988,
      "learning_rate": 1.0548855709672996e-05,
      "loss": 0.0332,
      "step": 2167
    },
    {
      "epoch": 1.4482297929191716,
      "grad_norm": 2.7142984867095947,
      "learning_rate": 1.0541870812699962e-05,
      "loss": 0.0913,
      "step": 2168
    },
    {
      "epoch": 1.4488977955911824,
      "grad_norm": 2.0301413536071777,
      "learning_rate": 1.0534885650566095e-05,
      "loss": 0.0774,
      "step": 2169
    },
    {
      "epoch": 1.449565798263193,
      "grad_norm": 0.7326797842979431,
      "learning_rate": 1.0527900226689535e-05,
      "loss": 0.0074,
      "step": 2170
    },
    {
      "epoch": 1.4502338009352038,
      "grad_norm": 0.07346729934215546,
      "learning_rate": 1.0520914544488555e-05,
      "loss": 0.0009,
      "step": 2171
    },
    {
      "epoch": 1.4509018036072145,
      "grad_norm": 5.268146514892578,
      "learning_rate": 1.0513928607381547e-05,
      "loss": 0.2887,
      "step": 2172
    },
    {
      "epoch": 1.451569806279225,
      "grad_norm": 3.826655626296997,
      "learning_rate": 1.0506942418787036e-05,
      "loss": 0.093,
      "step": 2173
    },
    {
      "epoch": 1.4522378089512358,
      "grad_norm": 17.304569244384766,
      "learning_rate": 1.0499955982123667e-05,
      "loss": 0.7696,
      "step": 2174
    },
    {
      "epoch": 1.4529058116232465,
      "grad_norm": 1.3472193479537964,
      "learning_rate": 1.04929693008102e-05,
      "loss": 0.0133,
      "step": 2175
    },
    {
      "epoch": 1.4535738142952572,
      "grad_norm": 5.331701278686523,
      "learning_rate": 1.0485982378265529e-05,
      "loss": 0.1838,
      "step": 2176
    },
    {
      "epoch": 1.4542418169672677,
      "grad_norm": 3.2315425872802734,
      "learning_rate": 1.0478995217908652e-05,
      "loss": 0.1593,
      "step": 2177
    },
    {
      "epoch": 1.4549098196392785,
      "grad_norm": 5.881300449371338,
      "learning_rate": 1.047200782315869e-05,
      "loss": 0.1195,
      "step": 2178
    },
    {
      "epoch": 1.4555778223112892,
      "grad_norm": 5.874512195587158,
      "learning_rate": 1.0465020197434874e-05,
      "loss": 0.2362,
      "step": 2179
    },
    {
      "epoch": 1.4562458249833,
      "grad_norm": 3.575085401535034,
      "learning_rate": 1.0458032344156559e-05,
      "loss": 0.1161,
      "step": 2180
    },
    {
      "epoch": 1.4569138276553106,
      "grad_norm": 1.4282432794570923,
      "learning_rate": 1.04510442667432e-05,
      "loss": 0.0966,
      "step": 2181
    },
    {
      "epoch": 1.4575818303273214,
      "grad_norm": 13.038082122802734,
      "learning_rate": 1.0444055968614367e-05,
      "loss": 0.1585,
      "step": 2182
    },
    {
      "epoch": 1.458249832999332,
      "grad_norm": 2.9918160438537598,
      "learning_rate": 1.043706745318973e-05,
      "loss": 0.1224,
      "step": 2183
    },
    {
      "epoch": 1.4589178356713428,
      "grad_norm": 0.4230785071849823,
      "learning_rate": 1.0430078723889082e-05,
      "loss": 0.0072,
      "step": 2184
    },
    {
      "epoch": 1.4595858383433533,
      "grad_norm": 3.922692060470581,
      "learning_rate": 1.0423089784132306e-05,
      "loss": 0.0482,
      "step": 2185
    },
    {
      "epoch": 1.460253841015364,
      "grad_norm": 1.3317421674728394,
      "learning_rate": 1.041610063733939e-05,
      "loss": 0.0898,
      "step": 2186
    },
    {
      "epoch": 1.4609218436873748,
      "grad_norm": 0.010358555242419243,
      "learning_rate": 1.040911128693043e-05,
      "loss": 0.0003,
      "step": 2187
    },
    {
      "epoch": 1.4615898463593855,
      "grad_norm": 1.835006594657898,
      "learning_rate": 1.0402121736325615e-05,
      "loss": 0.1052,
      "step": 2188
    },
    {
      "epoch": 1.462257849031396,
      "grad_norm": 8.27015495300293,
      "learning_rate": 1.0395131988945238e-05,
      "loss": 0.3026,
      "step": 2189
    },
    {
      "epoch": 1.4629258517034067,
      "grad_norm": 8.562613487243652,
      "learning_rate": 1.0388142048209678e-05,
      "loss": 0.1006,
      "step": 2190
    },
    {
      "epoch": 1.4635938543754174,
      "grad_norm": 11.36538314819336,
      "learning_rate": 1.0381151917539425e-05,
      "loss": 0.7051,
      "step": 2191
    },
    {
      "epoch": 1.4642618570474282,
      "grad_norm": 2.691742181777954,
      "learning_rate": 1.0374161600355043e-05,
      "loss": 0.1074,
      "step": 2192
    },
    {
      "epoch": 1.464929859719439,
      "grad_norm": 2.2896530628204346,
      "learning_rate": 1.0367171100077204e-05,
      "loss": 0.1345,
      "step": 2193
    },
    {
      "epoch": 1.4655978623914496,
      "grad_norm": 4.049286842346191,
      "learning_rate": 1.0360180420126658e-05,
      "loss": 0.0721,
      "step": 2194
    },
    {
      "epoch": 1.4662658650634603,
      "grad_norm": 4.716613292694092,
      "learning_rate": 1.035318956392425e-05,
      "loss": 0.2337,
      "step": 2195
    },
    {
      "epoch": 1.466933867735471,
      "grad_norm": 0.03275877982378006,
      "learning_rate": 1.0346198534890903e-05,
      "loss": 0.0007,
      "step": 2196
    },
    {
      "epoch": 1.4676018704074816,
      "grad_norm": 2.4299063682556152,
      "learning_rate": 1.0339207336447636e-05,
      "loss": 0.1588,
      "step": 2197
    },
    {
      "epoch": 1.4682698730794923,
      "grad_norm": 7.1029863357543945,
      "learning_rate": 1.0332215972015542e-05,
      "loss": 0.2374,
      "step": 2198
    },
    {
      "epoch": 1.468937875751503,
      "grad_norm": 2.772645950317383,
      "learning_rate": 1.0325224445015801e-05,
      "loss": 0.1164,
      "step": 2199
    },
    {
      "epoch": 1.4696058784235138,
      "grad_norm": 2.7123684883117676,
      "learning_rate": 1.0318232758869667e-05,
      "loss": 0.0108,
      "step": 2200
    },
    {
      "epoch": 1.4702738810955243,
      "grad_norm": 0.044461440294981,
      "learning_rate": 1.0311240916998473e-05,
      "loss": 0.0008,
      "step": 2201
    },
    {
      "epoch": 1.470941883767535,
      "grad_norm": 2.50441837310791,
      "learning_rate": 1.030424892282363e-05,
      "loss": 0.1938,
      "step": 2202
    },
    {
      "epoch": 1.4716098864395457,
      "grad_norm": 2.9294309616088867,
      "learning_rate": 1.0297256779766629e-05,
      "loss": 0.0619,
      "step": 2203
    },
    {
      "epoch": 1.4722778891115564,
      "grad_norm": 2.0340278148651123,
      "learning_rate": 1.0290264491249023e-05,
      "loss": 0.0255,
      "step": 2204
    },
    {
      "epoch": 1.4729458917835672,
      "grad_norm": 0.08488436043262482,
      "learning_rate": 1.0283272060692442e-05,
      "loss": 0.0011,
      "step": 2205
    },
    {
      "epoch": 1.4736138944555779,
      "grad_norm": 4.141477108001709,
      "learning_rate": 1.0276279491518584e-05,
      "loss": 0.0835,
      "step": 2206
    },
    {
      "epoch": 1.4742818971275886,
      "grad_norm": 3.7574567794799805,
      "learning_rate": 1.0269286787149217e-05,
      "loss": 0.1962,
      "step": 2207
    },
    {
      "epoch": 1.4749498997995991,
      "grad_norm": 0.07447508722543716,
      "learning_rate": 1.0262293951006175e-05,
      "loss": 0.0009,
      "step": 2208
    },
    {
      "epoch": 1.4756179024716098,
      "grad_norm": 10.266802787780762,
      "learning_rate": 1.0255300986511354e-05,
      "loss": 0.1626,
      "step": 2209
    },
    {
      "epoch": 1.4762859051436206,
      "grad_norm": 6.2258992195129395,
      "learning_rate": 1.0248307897086715e-05,
      "loss": 0.283,
      "step": 2210
    },
    {
      "epoch": 1.4769539078156313,
      "grad_norm": 2.364893913269043,
      "learning_rate": 1.0241314686154275e-05,
      "loss": 0.0958,
      "step": 2211
    },
    {
      "epoch": 1.477621910487642,
      "grad_norm": 0.057234026491642,
      "learning_rate": 1.0234321357136121e-05,
      "loss": 0.0011,
      "step": 2212
    },
    {
      "epoch": 1.4782899131596525,
      "grad_norm": 3.2971689701080322,
      "learning_rate": 1.0227327913454388e-05,
      "loss": 0.1512,
      "step": 2213
    },
    {
      "epoch": 1.4789579158316633,
      "grad_norm": 2.7444119453430176,
      "learning_rate": 1.0220334358531271e-05,
      "loss": 0.0837,
      "step": 2214
    },
    {
      "epoch": 1.479625918503674,
      "grad_norm": 3.749779224395752,
      "learning_rate": 1.0213340695789018e-05,
      "loss": 0.1588,
      "step": 2215
    },
    {
      "epoch": 1.4802939211756847,
      "grad_norm": 1.6654731035232544,
      "learning_rate": 1.0206346928649933e-05,
      "loss": 0.0424,
      "step": 2216
    },
    {
      "epoch": 1.4809619238476954,
      "grad_norm": 5.660732269287109,
      "learning_rate": 1.0199353060536366e-05,
      "loss": 0.1316,
      "step": 2217
    },
    {
      "epoch": 1.4816299265197062,
      "grad_norm": 10.998103141784668,
      "learning_rate": 1.0192359094870723e-05,
      "loss": 0.1524,
      "step": 2218
    },
    {
      "epoch": 1.4822979291917169,
      "grad_norm": 2.9807560443878174,
      "learning_rate": 1.018536503507545e-05,
      "loss": 0.1628,
      "step": 2219
    },
    {
      "epoch": 1.4829659318637274,
      "grad_norm": 2.482088327407837,
      "learning_rate": 1.0178370884573046e-05,
      "loss": 0.0594,
      "step": 2220
    },
    {
      "epoch": 1.483633934535738,
      "grad_norm": 0.7677056193351746,
      "learning_rate": 1.0171376646786049e-05,
      "loss": 0.0069,
      "step": 2221
    },
    {
      "epoch": 1.4843019372077488,
      "grad_norm": 0.14724215865135193,
      "learning_rate": 1.0164382325137047e-05,
      "loss": 0.0014,
      "step": 2222
    },
    {
      "epoch": 1.4849699398797596,
      "grad_norm": 2.4722139835357666,
      "learning_rate": 1.0157387923048659e-05,
      "loss": 0.0869,
      "step": 2223
    },
    {
      "epoch": 1.4856379425517703,
      "grad_norm": 0.2156517654657364,
      "learning_rate": 1.0150393443943552e-05,
      "loss": 0.0019,
      "step": 2224
    },
    {
      "epoch": 1.4863059452237808,
      "grad_norm": 13.028444290161133,
      "learning_rate": 1.0143398891244423e-05,
      "loss": 0.9309,
      "step": 2225
    },
    {
      "epoch": 1.4869739478957915,
      "grad_norm": 0.05952717363834381,
      "learning_rate": 1.0136404268374017e-05,
      "loss": 0.0008,
      "step": 2226
    },
    {
      "epoch": 1.4876419505678022,
      "grad_norm": 1.7623016834259033,
      "learning_rate": 1.0129409578755093e-05,
      "loss": 0.0833,
      "step": 2227
    },
    {
      "epoch": 1.488309953239813,
      "grad_norm": 0.15507788956165314,
      "learning_rate": 1.0122414825810467e-05,
      "loss": 0.0011,
      "step": 2228
    },
    {
      "epoch": 1.4889779559118237,
      "grad_norm": 13.269491195678711,
      "learning_rate": 1.0115420012962968e-05,
      "loss": 0.3702,
      "step": 2229
    },
    {
      "epoch": 1.4896459585838344,
      "grad_norm": 2.6073014736175537,
      "learning_rate": 1.0108425143635468e-05,
      "loss": 0.2776,
      "step": 2230
    },
    {
      "epoch": 1.4903139612558451,
      "grad_norm": 0.15506143867969513,
      "learning_rate": 1.010143022125085e-05,
      "loss": 0.0015,
      "step": 2231
    },
    {
      "epoch": 1.4909819639278556,
      "grad_norm": 1.5360733270645142,
      "learning_rate": 1.0094435249232037e-05,
      "loss": 0.1292,
      "step": 2232
    },
    {
      "epoch": 1.4916499665998664,
      "grad_norm": 9.245074272155762,
      "learning_rate": 1.0087440231001972e-05,
      "loss": 0.4178,
      "step": 2233
    },
    {
      "epoch": 1.492317969271877,
      "grad_norm": 0.01759176515042782,
      "learning_rate": 1.0080445169983614e-05,
      "loss": 0.0005,
      "step": 2234
    },
    {
      "epoch": 1.4929859719438878,
      "grad_norm": 4.223966598510742,
      "learning_rate": 1.007345006959996e-05,
      "loss": 0.0271,
      "step": 2235
    },
    {
      "epoch": 1.4936539746158983,
      "grad_norm": 7.125220775604248,
      "learning_rate": 1.0066454933274003e-05,
      "loss": 0.1273,
      "step": 2236
    },
    {
      "epoch": 1.494321977287909,
      "grad_norm": 2.0484983921051025,
      "learning_rate": 1.0059459764428777e-05,
      "loss": 0.1361,
      "step": 2237
    },
    {
      "epoch": 1.4949899799599198,
      "grad_norm": 6.216364860534668,
      "learning_rate": 1.0052464566487313e-05,
      "loss": 0.4349,
      "step": 2238
    },
    {
      "epoch": 1.4956579826319305,
      "grad_norm": 0.1697765737771988,
      "learning_rate": 1.0045469342872666e-05,
      "loss": 0.0022,
      "step": 2239
    },
    {
      "epoch": 1.4963259853039412,
      "grad_norm": 2.060185194015503,
      "learning_rate": 1.0038474097007901e-05,
      "loss": 0.113,
      "step": 2240
    },
    {
      "epoch": 1.496993987975952,
      "grad_norm": 2.7153327465057373,
      "learning_rate": 1.0031478832316099e-05,
      "loss": 0.2223,
      "step": 2241
    },
    {
      "epoch": 1.4976619906479627,
      "grad_norm": 0.9429636001586914,
      "learning_rate": 1.002448355222034e-05,
      "loss": 0.0985,
      "step": 2242
    },
    {
      "epoch": 1.4983299933199734,
      "grad_norm": 11.868578910827637,
      "learning_rate": 1.0017488260143722e-05,
      "loss": 0.5214,
      "step": 2243
    },
    {
      "epoch": 1.498997995991984,
      "grad_norm": 5.66105318069458,
      "learning_rate": 1.001049295950934e-05,
      "loss": 0.0512,
      "step": 2244
    },
    {
      "epoch": 1.4996659986639946,
      "grad_norm": 0.40648892521858215,
      "learning_rate": 1.00034976537403e-05,
      "loss": 0.005,
      "step": 2245
    },
    {
      "epoch": 1.5003340013360054,
      "grad_norm": 2.017216682434082,
      "learning_rate": 9.996502346259703e-06,
      "loss": 0.1085,
      "step": 2246
    },
    {
      "epoch": 1.5010020040080159,
      "grad_norm": 9.569271087646484,
      "learning_rate": 9.989507040490664e-06,
      "loss": 0.0893,
      "step": 2247
    },
    {
      "epoch": 1.5016700066800266,
      "grad_norm": 2.5160136222839355,
      "learning_rate": 9.98251173985628e-06,
      "loss": 0.1145,
      "step": 2248
    },
    {
      "epoch": 1.5023380093520373,
      "grad_norm": 5.6939263343811035,
      "learning_rate": 9.975516447779661e-06,
      "loss": 0.26,
      "step": 2249
    },
    {
      "epoch": 1.503006012024048,
      "grad_norm": 2.6860873699188232,
      "learning_rate": 9.968521167683906e-06,
      "loss": 0.1814,
      "step": 2250
    },
    {
      "epoch": 1.5036740146960588,
      "grad_norm": 2.3653948307037354,
      "learning_rate": 9.961525902992102e-06,
      "loss": 0.1163,
      "step": 2251
    },
    {
      "epoch": 1.5043420173680695,
      "grad_norm": 5.7541632652282715,
      "learning_rate": 9.954530657127337e-06,
      "loss": 0.1049,
      "step": 2252
    },
    {
      "epoch": 1.5050100200400802,
      "grad_norm": 3.5737392902374268,
      "learning_rate": 9.947535433512692e-06,
      "loss": 0.1738,
      "step": 2253
    },
    {
      "epoch": 1.505678022712091,
      "grad_norm": 2.726158618927002,
      "learning_rate": 9.940540235571227e-06,
      "loss": 0.1156,
      "step": 2254
    },
    {
      "epoch": 1.5063460253841017,
      "grad_norm": 0.02905159443616867,
      "learning_rate": 9.933545066725998e-06,
      "loss": 0.0004,
      "step": 2255
    },
    {
      "epoch": 1.5070140280561122,
      "grad_norm": 1.6879383325576782,
      "learning_rate": 9.926549930400044e-06,
      "loss": 0.1261,
      "step": 2256
    },
    {
      "epoch": 1.507682030728123,
      "grad_norm": 2.7091422080993652,
      "learning_rate": 9.919554830016386e-06,
      "loss": 0.1217,
      "step": 2257
    },
    {
      "epoch": 1.5083500334001336,
      "grad_norm": 6.303859710693359,
      "learning_rate": 9.912559768998031e-06,
      "loss": 0.2482,
      "step": 2258
    },
    {
      "epoch": 1.5090180360721441,
      "grad_norm": 1.882495403289795,
      "learning_rate": 9.905564750767968e-06,
      "loss": 0.0482,
      "step": 2259
    },
    {
      "epoch": 1.5096860387441549,
      "grad_norm": 3.4725852012634277,
      "learning_rate": 9.898569778749153e-06,
      "loss": 0.1786,
      "step": 2260
    },
    {
      "epoch": 1.5103540414161656,
      "grad_norm": 2.2928247451782227,
      "learning_rate": 9.891574856364536e-06,
      "loss": 0.1556,
      "step": 2261
    },
    {
      "epoch": 1.5110220440881763,
      "grad_norm": 3.8882789611816406,
      "learning_rate": 9.884579987037034e-06,
      "loss": 0.1188,
      "step": 2262
    },
    {
      "epoch": 1.511690046760187,
      "grad_norm": 1.8239024877548218,
      "learning_rate": 9.877585174189535e-06,
      "loss": 0.1384,
      "step": 2263
    },
    {
      "epoch": 1.5123580494321978,
      "grad_norm": 0.13166821002960205,
      "learning_rate": 9.870590421244908e-06,
      "loss": 0.0015,
      "step": 2264
    },
    {
      "epoch": 1.5130260521042085,
      "grad_norm": 7.4896087646484375,
      "learning_rate": 9.863595731625988e-06,
      "loss": 0.2213,
      "step": 2265
    },
    {
      "epoch": 1.5136940547762192,
      "grad_norm": 8.33930778503418,
      "learning_rate": 9.856601108755579e-06,
      "loss": 0.1127,
      "step": 2266
    },
    {
      "epoch": 1.51436205744823,
      "grad_norm": 2.223215103149414,
      "learning_rate": 9.84960655605645e-06,
      "loss": 0.1379,
      "step": 2267
    },
    {
      "epoch": 1.5150300601202404,
      "grad_norm": 2.644537925720215,
      "learning_rate": 9.842612076951343e-06,
      "loss": 0.1199,
      "step": 2268
    },
    {
      "epoch": 1.5156980627922512,
      "grad_norm": 0.22712883353233337,
      "learning_rate": 9.835617674862956e-06,
      "loss": 0.0021,
      "step": 2269
    },
    {
      "epoch": 1.516366065464262,
      "grad_norm": 1.343599796295166,
      "learning_rate": 9.828623353213954e-06,
      "loss": 0.0859,
      "step": 2270
    },
    {
      "epoch": 1.5170340681362724,
      "grad_norm": 3.30122709274292,
      "learning_rate": 9.821629115426955e-06,
      "loss": 0.1354,
      "step": 2271
    },
    {
      "epoch": 1.5177020708082831,
      "grad_norm": 3.63834810256958,
      "learning_rate": 9.814634964924554e-06,
      "loss": 0.1219,
      "step": 2272
    },
    {
      "epoch": 1.5183700734802938,
      "grad_norm": 4.134453296661377,
      "learning_rate": 9.80764090512928e-06,
      "loss": 0.1574,
      "step": 2273
    },
    {
      "epoch": 1.5190380761523046,
      "grad_norm": 6.543039798736572,
      "learning_rate": 9.800646939463635e-06,
      "loss": 0.2926,
      "step": 2274
    },
    {
      "epoch": 1.5197060788243153,
      "grad_norm": 2.5266799926757812,
      "learning_rate": 9.793653071350068e-06,
      "loss": 0.1111,
      "step": 2275
    },
    {
      "epoch": 1.520374081496326,
      "grad_norm": 0.9950249791145325,
      "learning_rate": 9.786659304210984e-06,
      "loss": 0.0156,
      "step": 2276
    },
    {
      "epoch": 1.5210420841683367,
      "grad_norm": 2.681833505630493,
      "learning_rate": 9.779665641468734e-06,
      "loss": 0.1161,
      "step": 2277
    },
    {
      "epoch": 1.5217100868403475,
      "grad_norm": 2.453745126724243,
      "learning_rate": 9.772672086545617e-06,
      "loss": 0.0215,
      "step": 2278
    },
    {
      "epoch": 1.5223780895123582,
      "grad_norm": 0.013613386079668999,
      "learning_rate": 9.765678642863882e-06,
      "loss": 0.0003,
      "step": 2279
    },
    {
      "epoch": 1.5230460921843687,
      "grad_norm": 0.2501339614391327,
      "learning_rate": 9.758685313845727e-06,
      "loss": 0.0023,
      "step": 2280
    },
    {
      "epoch": 1.5237140948563794,
      "grad_norm": 1.7912875413894653,
      "learning_rate": 9.751692102913287e-06,
      "loss": 0.1666,
      "step": 2281
    },
    {
      "epoch": 1.5243820975283902,
      "grad_norm": 3.0930871963500977,
      "learning_rate": 9.744699013488648e-06,
      "loss": 0.1125,
      "step": 2282
    },
    {
      "epoch": 1.5250501002004007,
      "grad_norm": 2.8778703212738037,
      "learning_rate": 9.737706048993827e-06,
      "loss": 0.1826,
      "step": 2283
    },
    {
      "epoch": 1.5257181028724114,
      "grad_norm": 1.2685619592666626,
      "learning_rate": 9.730713212850783e-06,
      "loss": 0.0226,
      "step": 2284
    },
    {
      "epoch": 1.5263861055444221,
      "grad_norm": 0.059613313525915146,
      "learning_rate": 9.723720508481418e-06,
      "loss": 0.0008,
      "step": 2285
    },
    {
      "epoch": 1.5270541082164328,
      "grad_norm": 6.600490570068359,
      "learning_rate": 9.716727939307563e-06,
      "loss": 0.3614,
      "step": 2286
    },
    {
      "epoch": 1.5277221108884436,
      "grad_norm": 3.28664493560791,
      "learning_rate": 9.70973550875098e-06,
      "loss": 0.1284,
      "step": 2287
    },
    {
      "epoch": 1.5283901135604543,
      "grad_norm": 0.027344854548573494,
      "learning_rate": 9.702743220233374e-06,
      "loss": 0.0006,
      "step": 2288
    },
    {
      "epoch": 1.529058116232465,
      "grad_norm": 3.569995880126953,
      "learning_rate": 9.695751077176372e-06,
      "loss": 0.1528,
      "step": 2289
    },
    {
      "epoch": 1.5297261189044757,
      "grad_norm": 0.3195408284664154,
      "learning_rate": 9.68875908300153e-06,
      "loss": 0.0044,
      "step": 2290
    },
    {
      "epoch": 1.5303941215764865,
      "grad_norm": 10.79422664642334,
      "learning_rate": 9.681767241130338e-06,
      "loss": 0.2285,
      "step": 2291
    },
    {
      "epoch": 1.531062124248497,
      "grad_norm": 0.31866025924682617,
      "learning_rate": 9.6747755549842e-06,
      "loss": 0.0034,
      "step": 2292
    },
    {
      "epoch": 1.5317301269205077,
      "grad_norm": 3.4374923706054688,
      "learning_rate": 9.667784027984458e-06,
      "loss": 0.1821,
      "step": 2293
    },
    {
      "epoch": 1.5323981295925184,
      "grad_norm": 14.909067153930664,
      "learning_rate": 9.660792663552364e-06,
      "loss": 0.6419,
      "step": 2294
    },
    {
      "epoch": 1.533066132264529,
      "grad_norm": 0.13690152764320374,
      "learning_rate": 9.653801465109102e-06,
      "loss": 0.0018,
      "step": 2295
    },
    {
      "epoch": 1.5337341349365397,
      "grad_norm": 1.7171887159347534,
      "learning_rate": 9.646810436075756e-06,
      "loss": 0.1102,
      "step": 2296
    },
    {
      "epoch": 1.5344021376085504,
      "grad_norm": 2.1356465816497803,
      "learning_rate": 9.639819579873346e-06,
      "loss": 0.1802,
      "step": 2297
    },
    {
      "epoch": 1.535070140280561,
      "grad_norm": 1.3820611238479614,
      "learning_rate": 9.632828899922798e-06,
      "loss": 0.1654,
      "step": 2298
    },
    {
      "epoch": 1.5357381429525718,
      "grad_norm": 0.1840309351682663,
      "learning_rate": 9.625838399644958e-06,
      "loss": 0.002,
      "step": 2299
    },
    {
      "epoch": 1.5364061456245826,
      "grad_norm": 1.595825433731079,
      "learning_rate": 9.618848082460577e-06,
      "loss": 0.0991,
      "step": 2300
    },
    {
      "epoch": 1.5370741482965933,
      "grad_norm": 2.3241899013519287,
      "learning_rate": 9.611857951790322e-06,
      "loss": 0.1521,
      "step": 2301
    },
    {
      "epoch": 1.537742150968604,
      "grad_norm": 2.4744484424591064,
      "learning_rate": 9.604868011054765e-06,
      "loss": 0.2136,
      "step": 2302
    },
    {
      "epoch": 1.5384101536406145,
      "grad_norm": 0.0430782251060009,
      "learning_rate": 9.597878263674389e-06,
      "loss": 0.0006,
      "step": 2303
    },
    {
      "epoch": 1.5390781563126252,
      "grad_norm": 0.026043619960546494,
      "learning_rate": 9.590888713069574e-06,
      "loss": 0.0005,
      "step": 2304
    },
    {
      "epoch": 1.539746158984636,
      "grad_norm": 2.7635302543640137,
      "learning_rate": 9.583899362660614e-06,
      "loss": 0.1034,
      "step": 2305
    },
    {
      "epoch": 1.5404141616566465,
      "grad_norm": 4.033365726470947,
      "learning_rate": 9.576910215867699e-06,
      "loss": 0.1605,
      "step": 2306
    },
    {
      "epoch": 1.5410821643286572,
      "grad_norm": 0.03317001834511757,
      "learning_rate": 9.56992127611092e-06,
      "loss": 0.0008,
      "step": 2307
    },
    {
      "epoch": 1.541750167000668,
      "grad_norm": 3.77439022064209,
      "learning_rate": 9.562932546810271e-06,
      "loss": 0.1066,
      "step": 2308
    },
    {
      "epoch": 1.5424181696726786,
      "grad_norm": 1.9122657775878906,
      "learning_rate": 9.555944031385637e-06,
      "loss": 0.1226,
      "step": 2309
    },
    {
      "epoch": 1.5430861723446894,
      "grad_norm": 0.23038765788078308,
      "learning_rate": 9.548955733256803e-06,
      "loss": 0.0023,
      "step": 2310
    },
    {
      "epoch": 1.5437541750167,
      "grad_norm": 13.202011108398438,
      "learning_rate": 9.541967655843441e-06,
      "loss": 0.2974,
      "step": 2311
    },
    {
      "epoch": 1.5444221776887108,
      "grad_norm": 0.15184298157691956,
      "learning_rate": 9.534979802565127e-06,
      "loss": 0.0016,
      "step": 2312
    },
    {
      "epoch": 1.5450901803607215,
      "grad_norm": 6.409593105316162,
      "learning_rate": 9.527992176841315e-06,
      "loss": 0.1253,
      "step": 2313
    },
    {
      "epoch": 1.5457581830327323,
      "grad_norm": 2.192186117172241,
      "learning_rate": 9.521004782091351e-06,
      "loss": 0.1256,
      "step": 2314
    },
    {
      "epoch": 1.5464261857047428,
      "grad_norm": 2.4763567447662354,
      "learning_rate": 9.514017621734474e-06,
      "loss": 0.0634,
      "step": 2315
    },
    {
      "epoch": 1.5470941883767535,
      "grad_norm": 2.331308126449585,
      "learning_rate": 9.507030699189802e-06,
      "loss": 0.0806,
      "step": 2316
    },
    {
      "epoch": 1.5477621910487642,
      "grad_norm": 8.970393180847168,
      "learning_rate": 9.500044017876335e-06,
      "loss": 0.3212,
      "step": 2317
    },
    {
      "epoch": 1.5484301937207747,
      "grad_norm": 10.070446014404297,
      "learning_rate": 9.493057581212966e-06,
      "loss": 0.1464,
      "step": 2318
    },
    {
      "epoch": 1.5490981963927855,
      "grad_norm": 2.5147786140441895,
      "learning_rate": 9.486071392618453e-06,
      "loss": 0.196,
      "step": 2319
    },
    {
      "epoch": 1.5497661990647962,
      "grad_norm": 3.9489853382110596,
      "learning_rate": 9.479085455511447e-06,
      "loss": 0.1264,
      "step": 2320
    },
    {
      "epoch": 1.550434201736807,
      "grad_norm": 2.543158769607544,
      "learning_rate": 9.472099773310468e-06,
      "loss": 0.1594,
      "step": 2321
    },
    {
      "epoch": 1.5511022044088176,
      "grad_norm": 4.145870208740234,
      "learning_rate": 9.46511434943391e-06,
      "loss": 0.0523,
      "step": 2322
    },
    {
      "epoch": 1.5517702070808284,
      "grad_norm": 7.490248203277588,
      "learning_rate": 9.45812918730004e-06,
      "loss": 0.1971,
      "step": 2323
    },
    {
      "epoch": 1.552438209752839,
      "grad_norm": 2.441948890686035,
      "learning_rate": 9.451144290327008e-06,
      "loss": 0.0374,
      "step": 2324
    },
    {
      "epoch": 1.5531062124248498,
      "grad_norm": 1.9485622644424438,
      "learning_rate": 9.444159661932819e-06,
      "loss": 0.1267,
      "step": 2325
    },
    {
      "epoch": 1.5537742150968605,
      "grad_norm": 1.335965871810913,
      "learning_rate": 9.437175305535358e-06,
      "loss": 0.0921,
      "step": 2326
    },
    {
      "epoch": 1.554442217768871,
      "grad_norm": 8.980155944824219,
      "learning_rate": 9.430191224552372e-06,
      "loss": 0.3306,
      "step": 2327
    },
    {
      "epoch": 1.5551102204408818,
      "grad_norm": 2.709573268890381,
      "learning_rate": 9.423207422401476e-06,
      "loss": 0.0569,
      "step": 2328
    },
    {
      "epoch": 1.5557782231128925,
      "grad_norm": 4.291081428527832,
      "learning_rate": 9.416223902500145e-06,
      "loss": 0.124,
      "step": 2329
    },
    {
      "epoch": 1.556446225784903,
      "grad_norm": 0.17616987228393555,
      "learning_rate": 9.409240668265718e-06,
      "loss": 0.0022,
      "step": 2330
    },
    {
      "epoch": 1.5571142284569137,
      "grad_norm": 2.044159173965454,
      "learning_rate": 9.402257723115389e-06,
      "loss": 0.0178,
      "step": 2331
    },
    {
      "epoch": 1.5577822311289244,
      "grad_norm": 3.2048733234405518,
      "learning_rate": 9.39527507046622e-06,
      "loss": 0.156,
      "step": 2332
    },
    {
      "epoch": 1.5584502338009352,
      "grad_norm": 3.0168662071228027,
      "learning_rate": 9.388292713735123e-06,
      "loss": 0.1846,
      "step": 2333
    },
    {
      "epoch": 1.559118236472946,
      "grad_norm": 1.9662545919418335,
      "learning_rate": 9.381310656338868e-06,
      "loss": 0.1412,
      "step": 2334
    },
    {
      "epoch": 1.5597862391449566,
      "grad_norm": 0.09128352254629135,
      "learning_rate": 9.374328901694082e-06,
      "loss": 0.0011,
      "step": 2335
    },
    {
      "epoch": 1.5604542418169673,
      "grad_norm": 0.14066116511821747,
      "learning_rate": 9.367347453217231e-06,
      "loss": 0.0016,
      "step": 2336
    },
    {
      "epoch": 1.561122244488978,
      "grad_norm": 9.251428604125977,
      "learning_rate": 9.360366314324646e-06,
      "loss": 0.2372,
      "step": 2337
    },
    {
      "epoch": 1.5617902471609888,
      "grad_norm": 1.5753835439682007,
      "learning_rate": 9.353385488432498e-06,
      "loss": 0.0527,
      "step": 2338
    },
    {
      "epoch": 1.5624582498329993,
      "grad_norm": 1.6370176076889038,
      "learning_rate": 9.346404978956811e-06,
      "loss": 0.0673,
      "step": 2339
    },
    {
      "epoch": 1.56312625250501,
      "grad_norm": 1.419437050819397,
      "learning_rate": 9.339424789313445e-06,
      "loss": 0.1271,
      "step": 2340
    },
    {
      "epoch": 1.5637942551770208,
      "grad_norm": 2.973797559738159,
      "learning_rate": 9.332444922918112e-06,
      "loss": 0.0424,
      "step": 2341
    },
    {
      "epoch": 1.5644622578490313,
      "grad_norm": 0.9481572508811951,
      "learning_rate": 9.32546538318636e-06,
      "loss": 0.0117,
      "step": 2342
    },
    {
      "epoch": 1.565130260521042,
      "grad_norm": 5.477781295776367,
      "learning_rate": 9.318486173533584e-06,
      "loss": 0.1514,
      "step": 2343
    },
    {
      "epoch": 1.5657982631930527,
      "grad_norm": 0.18387913703918457,
      "learning_rate": 9.311507297375007e-06,
      "loss": 0.0022,
      "step": 2344
    },
    {
      "epoch": 1.5664662658650634,
      "grad_norm": 1.9778060913085938,
      "learning_rate": 9.3045287581257e-06,
      "loss": 0.118,
      "step": 2345
    },
    {
      "epoch": 1.5671342685370742,
      "grad_norm": 7.03849983215332,
      "learning_rate": 9.297550559200563e-06,
      "loss": 0.4007,
      "step": 2346
    },
    {
      "epoch": 1.5678022712090849,
      "grad_norm": 0.27231135964393616,
      "learning_rate": 9.290572704014331e-06,
      "loss": 0.0035,
      "step": 2347
    },
    {
      "epoch": 1.5684702738810956,
      "grad_norm": 0.09624979645013809,
      "learning_rate": 9.283595195981572e-06,
      "loss": 0.0014,
      "step": 2348
    },
    {
      "epoch": 1.5691382765531063,
      "grad_norm": 2.4045767784118652,
      "learning_rate": 9.27661803851668e-06,
      "loss": 0.0703,
      "step": 2349
    },
    {
      "epoch": 1.569806279225117,
      "grad_norm": 0.8846023082733154,
      "learning_rate": 9.269641235033878e-06,
      "loss": 0.0144,
      "step": 2350
    },
    {
      "epoch": 1.5704742818971276,
      "grad_norm": 0.2553115487098694,
      "learning_rate": 9.262664788947223e-06,
      "loss": 0.0021,
      "step": 2351
    },
    {
      "epoch": 1.5711422845691383,
      "grad_norm": 2.8539702892303467,
      "learning_rate": 9.255688703670587e-06,
      "loss": 0.1288,
      "step": 2352
    },
    {
      "epoch": 1.571810287241149,
      "grad_norm": 0.04322289675474167,
      "learning_rate": 9.248712982617675e-06,
      "loss": 0.0006,
      "step": 2353
    },
    {
      "epoch": 1.5724782899131595,
      "grad_norm": 2.2023544311523438,
      "learning_rate": 9.241737629202007e-06,
      "loss": 0.1474,
      "step": 2354
    },
    {
      "epoch": 1.5731462925851702,
      "grad_norm": 0.11493704468011856,
      "learning_rate": 9.234762646836923e-06,
      "loss": 0.0015,
      "step": 2355
    },
    {
      "epoch": 1.573814295257181,
      "grad_norm": 1.445294976234436,
      "learning_rate": 9.227788038935586e-06,
      "loss": 0.086,
      "step": 2356
    },
    {
      "epoch": 1.5744822979291917,
      "grad_norm": 1.5613988637924194,
      "learning_rate": 9.220813808910978e-06,
      "loss": 0.0507,
      "step": 2357
    },
    {
      "epoch": 1.5751503006012024,
      "grad_norm": 1.6536885499954224,
      "learning_rate": 9.213839960175881e-06,
      "loss": 0.0194,
      "step": 2358
    },
    {
      "epoch": 1.5758183032732132,
      "grad_norm": 1.5602325201034546,
      "learning_rate": 9.206866496142908e-06,
      "loss": 0.1517,
      "step": 2359
    },
    {
      "epoch": 1.5764863059452239,
      "grad_norm": 5.021401882171631,
      "learning_rate": 9.199893420224476e-06,
      "loss": 0.127,
      "step": 2360
    },
    {
      "epoch": 1.5771543086172346,
      "grad_norm": 0.969576358795166,
      "learning_rate": 9.192920735832811e-06,
      "loss": 0.0142,
      "step": 2361
    },
    {
      "epoch": 1.577822311289245,
      "grad_norm": 5.052484512329102,
      "learning_rate": 9.185948446379954e-06,
      "loss": 0.1175,
      "step": 2362
    },
    {
      "epoch": 1.5784903139612558,
      "grad_norm": 0.03376109153032303,
      "learning_rate": 9.178976555277738e-06,
      "loss": 0.0005,
      "step": 2363
    },
    {
      "epoch": 1.5791583166332666,
      "grad_norm": 0.24915091693401337,
      "learning_rate": 9.172005065937822e-06,
      "loss": 0.0026,
      "step": 2364
    },
    {
      "epoch": 1.579826319305277,
      "grad_norm": 2.5736756324768066,
      "learning_rate": 9.165033981771654e-06,
      "loss": 0.161,
      "step": 2365
    },
    {
      "epoch": 1.5804943219772878,
      "grad_norm": 2.667686939239502,
      "learning_rate": 9.158063306190481e-06,
      "loss": 0.0351,
      "step": 2366
    },
    {
      "epoch": 1.5811623246492985,
      "grad_norm": 1.0164750814437866,
      "learning_rate": 9.151093042605363e-06,
      "loss": 0.0123,
      "step": 2367
    },
    {
      "epoch": 1.5818303273213092,
      "grad_norm": 3.9740498065948486,
      "learning_rate": 9.144123194427149e-06,
      "loss": 0.0589,
      "step": 2368
    },
    {
      "epoch": 1.58249832999332,
      "grad_norm": 6.459676742553711,
      "learning_rate": 9.137153765066485e-06,
      "loss": 0.0901,
      "step": 2369
    },
    {
      "epoch": 1.5831663326653307,
      "grad_norm": 11.125082969665527,
      "learning_rate": 9.13018475793382e-06,
      "loss": 0.4578,
      "step": 2370
    },
    {
      "epoch": 1.5838343353373414,
      "grad_norm": 1.8266233205795288,
      "learning_rate": 9.123216176439385e-06,
      "loss": 0.0257,
      "step": 2371
    },
    {
      "epoch": 1.5845023380093521,
      "grad_norm": 0.06679642200469971,
      "learning_rate": 9.116248023993213e-06,
      "loss": 0.0007,
      "step": 2372
    },
    {
      "epoch": 1.5851703406813629,
      "grad_norm": 1.2806098461151123,
      "learning_rate": 9.10928030400512e-06,
      "loss": 0.02,
      "step": 2373
    },
    {
      "epoch": 1.5858383433533734,
      "grad_norm": 0.8494387865066528,
      "learning_rate": 9.102313019884718e-06,
      "loss": 0.0109,
      "step": 2374
    },
    {
      "epoch": 1.586506346025384,
      "grad_norm": 0.5831490159034729,
      "learning_rate": 9.095346175041391e-06,
      "loss": 0.0076,
      "step": 2375
    },
    {
      "epoch": 1.5871743486973948,
      "grad_norm": 0.028693431988358498,
      "learning_rate": 9.088379772884325e-06,
      "loss": 0.0005,
      "step": 2376
    },
    {
      "epoch": 1.5878423513694053,
      "grad_norm": 0.403534859418869,
      "learning_rate": 9.081413816822477e-06,
      "loss": 0.0032,
      "step": 2377
    },
    {
      "epoch": 1.588510354041416,
      "grad_norm": 2.283507823944092,
      "learning_rate": 9.074448310264594e-06,
      "loss": 0.1476,
      "step": 2378
    },
    {
      "epoch": 1.5891783567134268,
      "grad_norm": 4.4420342445373535,
      "learning_rate": 9.067483256619198e-06,
      "loss": 0.1337,
      "step": 2379
    },
    {
      "epoch": 1.5898463593854375,
      "grad_norm": 1.3229442834854126,
      "learning_rate": 9.060518659294595e-06,
      "loss": 0.0615,
      "step": 2380
    },
    {
      "epoch": 1.5905143620574482,
      "grad_norm": 2.164893627166748,
      "learning_rate": 9.053554521698861e-06,
      "loss": 0.1109,
      "step": 2381
    },
    {
      "epoch": 1.591182364729459,
      "grad_norm": 7.821169376373291,
      "learning_rate": 9.046590847239847e-06,
      "loss": 0.34,
      "step": 2382
    },
    {
      "epoch": 1.5918503674014697,
      "grad_norm": 0.8951804041862488,
      "learning_rate": 9.039627639325188e-06,
      "loss": 0.007,
      "step": 2383
    },
    {
      "epoch": 1.5925183700734804,
      "grad_norm": 0.06528373062610626,
      "learning_rate": 9.032664901362275e-06,
      "loss": 0.0008,
      "step": 2384
    },
    {
      "epoch": 1.5931863727454911,
      "grad_norm": 2.3657026290893555,
      "learning_rate": 9.025702636758278e-06,
      "loss": 0.0409,
      "step": 2385
    },
    {
      "epoch": 1.5938543754175016,
      "grad_norm": 10.458907127380371,
      "learning_rate": 9.018740848920138e-06,
      "loss": 0.3451,
      "step": 2386
    },
    {
      "epoch": 1.5945223780895124,
      "grad_norm": 8.465986251831055,
      "learning_rate": 9.011779541254558e-06,
      "loss": 0.2109,
      "step": 2387
    },
    {
      "epoch": 1.595190380761523,
      "grad_norm": 0.37172192335128784,
      "learning_rate": 9.004818717168005e-06,
      "loss": 0.0052,
      "step": 2388
    },
    {
      "epoch": 1.5958583834335336,
      "grad_norm": 2.230849027633667,
      "learning_rate": 8.997858380066713e-06,
      "loss": 0.1331,
      "step": 2389
    },
    {
      "epoch": 1.5965263861055443,
      "grad_norm": 3.998091459274292,
      "learning_rate": 8.990898533356674e-06,
      "loss": 0.1811,
      "step": 2390
    },
    {
      "epoch": 1.597194388777555,
      "grad_norm": 1.718709111213684,
      "learning_rate": 8.983939180443646e-06,
      "loss": 0.0975,
      "step": 2391
    },
    {
      "epoch": 1.5978623914495658,
      "grad_norm": 3.520913600921631,
      "learning_rate": 8.976980324733143e-06,
      "loss": 0.2116,
      "step": 2392
    },
    {
      "epoch": 1.5985303941215765,
      "grad_norm": 5.902225017547607,
      "learning_rate": 8.970021969630427e-06,
      "loss": 0.0743,
      "step": 2393
    },
    {
      "epoch": 1.5991983967935872,
      "grad_norm": 0.4347761571407318,
      "learning_rate": 8.963064118540525e-06,
      "loss": 0.0043,
      "step": 2394
    },
    {
      "epoch": 1.599866399465598,
      "grad_norm": 2.1828582286834717,
      "learning_rate": 8.956106774868215e-06,
      "loss": 0.1638,
      "step": 2395
    },
    {
      "epoch": 1.6005344021376087,
      "grad_norm": 4.240903854370117,
      "learning_rate": 8.949149942018025e-06,
      "loss": 0.0527,
      "step": 2396
    },
    {
      "epoch": 1.6012024048096194,
      "grad_norm": 12.088401794433594,
      "learning_rate": 8.942193623394241e-06,
      "loss": 0.4569,
      "step": 2397
    },
    {
      "epoch": 1.60187040748163,
      "grad_norm": 0.08336787670850754,
      "learning_rate": 8.935237822400882e-06,
      "loss": 0.001,
      "step": 2398
    },
    {
      "epoch": 1.6025384101536406,
      "grad_norm": 0.030852558091282845,
      "learning_rate": 8.928282542441727e-06,
      "loss": 0.0006,
      "step": 2399
    },
    {
      "epoch": 1.6032064128256514,
      "grad_norm": 0.28155720233917236,
      "learning_rate": 8.921327786920294e-06,
      "loss": 0.0035,
      "step": 2400
    },
    {
      "epoch": 1.6038744154976619,
      "grad_norm": 2.4118781089782715,
      "learning_rate": 8.914373559239853e-06,
      "loss": 0.1499,
      "step": 2401
    },
    {
      "epoch": 1.6045424181696726,
      "grad_norm": 2.695169687271118,
      "learning_rate": 8.907419862803394e-06,
      "loss": 0.091,
      "step": 2402
    },
    {
      "epoch": 1.6052104208416833,
      "grad_norm": 3.777845621109009,
      "learning_rate": 8.900466701013672e-06,
      "loss": 0.1114,
      "step": 2403
    },
    {
      "epoch": 1.605878423513694,
      "grad_norm": 1.7317075729370117,
      "learning_rate": 8.893514077273165e-06,
      "loss": 0.0786,
      "step": 2404
    },
    {
      "epoch": 1.6065464261857048,
      "grad_norm": 0.07655294984579086,
      "learning_rate": 8.886561994984096e-06,
      "loss": 0.0011,
      "step": 2405
    },
    {
      "epoch": 1.6072144288577155,
      "grad_norm": 2.341193437576294,
      "learning_rate": 8.879610457548417e-06,
      "loss": 0.0466,
      "step": 2406
    },
    {
      "epoch": 1.6078824315297262,
      "grad_norm": 3.4991748332977295,
      "learning_rate": 8.872659468367822e-06,
      "loss": 0.1272,
      "step": 2407
    },
    {
      "epoch": 1.608550434201737,
      "grad_norm": 2.9295406341552734,
      "learning_rate": 8.865709030843724e-06,
      "loss": 0.1297,
      "step": 2408
    },
    {
      "epoch": 1.6092184368737477,
      "grad_norm": 5.515775680541992,
      "learning_rate": 8.858759148377272e-06,
      "loss": 0.3505,
      "step": 2409
    },
    {
      "epoch": 1.6098864395457582,
      "grad_norm": 2.19486665725708,
      "learning_rate": 8.851809824369354e-06,
      "loss": 0.1191,
      "step": 2410
    },
    {
      "epoch": 1.610554442217769,
      "grad_norm": 1.6426352262496948,
      "learning_rate": 8.844861062220564e-06,
      "loss": 0.0173,
      "step": 2411
    },
    {
      "epoch": 1.6112224448897794,
      "grad_norm": 3.115724802017212,
      "learning_rate": 8.837912865331236e-06,
      "loss": 0.1476,
      "step": 2412
    },
    {
      "epoch": 1.6118904475617901,
      "grad_norm": 0.01592918299138546,
      "learning_rate": 8.830965237101424e-06,
      "loss": 0.0004,
      "step": 2413
    },
    {
      "epoch": 1.6125584502338008,
      "grad_norm": 4.2038469314575195,
      "learning_rate": 8.824018180930904e-06,
      "loss": 0.152,
      "step": 2414
    },
    {
      "epoch": 1.6132264529058116,
      "grad_norm": 0.781204342842102,
      "learning_rate": 8.817071700219167e-06,
      "loss": 0.0081,
      "step": 2415
    },
    {
      "epoch": 1.6138944555778223,
      "grad_norm": 10.304012298583984,
      "learning_rate": 8.810125798365432e-06,
      "loss": 0.4227,
      "step": 2416
    },
    {
      "epoch": 1.614562458249833,
      "grad_norm": 5.643354415893555,
      "learning_rate": 8.803180478768625e-06,
      "loss": 0.2497,
      "step": 2417
    },
    {
      "epoch": 1.6152304609218437,
      "grad_norm": 4.0132575035095215,
      "learning_rate": 8.796235744827397e-06,
      "loss": 0.2248,
      "step": 2418
    },
    {
      "epoch": 1.6158984635938545,
      "grad_norm": 0.01966637559235096,
      "learning_rate": 8.7892915999401e-06,
      "loss": 0.0004,
      "step": 2419
    },
    {
      "epoch": 1.6165664662658652,
      "grad_norm": 13.419589042663574,
      "learning_rate": 8.782348047504808e-06,
      "loss": 0.265,
      "step": 2420
    },
    {
      "epoch": 1.6172344689378757,
      "grad_norm": 4.976502895355225,
      "learning_rate": 8.7754050909193e-06,
      "loss": 0.1957,
      "step": 2421
    },
    {
      "epoch": 1.6179024716098864,
      "grad_norm": 13.243074417114258,
      "learning_rate": 8.768462733581067e-06,
      "loss": 0.6798,
      "step": 2422
    },
    {
      "epoch": 1.6185704742818972,
      "grad_norm": 21.530914306640625,
      "learning_rate": 8.7615209788873e-06,
      "loss": 0.2254,
      "step": 2423
    },
    {
      "epoch": 1.6192384769539077,
      "grad_norm": 8.907418251037598,
      "learning_rate": 8.754579830234908e-06,
      "loss": 0.1376,
      "step": 2424
    },
    {
      "epoch": 1.6199064796259184,
      "grad_norm": 0.019006988033652306,
      "learning_rate": 8.747639291020489e-06,
      "loss": 0.0003,
      "step": 2425
    },
    {
      "epoch": 1.620574482297929,
      "grad_norm": 6.32862663269043,
      "learning_rate": 8.740699364640355e-06,
      "loss": 0.2267,
      "step": 2426
    },
    {
      "epoch": 1.6212424849699398,
      "grad_norm": 4.587523937225342,
      "learning_rate": 8.73376005449051e-06,
      "loss": 0.1191,
      "step": 2427
    },
    {
      "epoch": 1.6219104876419506,
      "grad_norm": 3.1882524490356445,
      "learning_rate": 8.726821363966654e-06,
      "loss": 0.1277,
      "step": 2428
    },
    {
      "epoch": 1.6225784903139613,
      "grad_norm": 11.194189071655273,
      "learning_rate": 8.71988329646419e-06,
      "loss": 0.4585,
      "step": 2429
    },
    {
      "epoch": 1.623246492985972,
      "grad_norm": 2.2915472984313965,
      "learning_rate": 8.712945855378218e-06,
      "loss": 0.0467,
      "step": 2430
    },
    {
      "epoch": 1.6239144956579827,
      "grad_norm": 0.07635447382926941,
      "learning_rate": 8.706009044103527e-06,
      "loss": 0.0009,
      "step": 2431
    },
    {
      "epoch": 1.6245824983299935,
      "grad_norm": 0.477427214384079,
      "learning_rate": 8.6990728660346e-06,
      "loss": 0.0047,
      "step": 2432
    },
    {
      "epoch": 1.625250501002004,
      "grad_norm": 2.108428478240967,
      "learning_rate": 8.692137324565604e-06,
      "loss": 0.0741,
      "step": 2433
    },
    {
      "epoch": 1.6259185036740147,
      "grad_norm": 2.1771130561828613,
      "learning_rate": 8.685202423090404e-06,
      "loss": 0.1247,
      "step": 2434
    },
    {
      "epoch": 1.6265865063460254,
      "grad_norm": 3.6858205795288086,
      "learning_rate": 8.678268165002549e-06,
      "loss": 0.1317,
      "step": 2435
    },
    {
      "epoch": 1.627254509018036,
      "grad_norm": 0.012943251058459282,
      "learning_rate": 8.671334553695269e-06,
      "loss": 0.0003,
      "step": 2436
    },
    {
      "epoch": 1.6279225116900466,
      "grad_norm": 2.4449548721313477,
      "learning_rate": 8.664401592561477e-06,
      "loss": 0.081,
      "step": 2437
    },
    {
      "epoch": 1.6285905143620574,
      "grad_norm": 1.6676223278045654,
      "learning_rate": 8.657469284993776e-06,
      "loss": 0.0837,
      "step": 2438
    },
    {
      "epoch": 1.629258517034068,
      "grad_norm": 3.945467472076416,
      "learning_rate": 8.65053763438444e-06,
      "loss": 0.0802,
      "step": 2439
    },
    {
      "epoch": 1.6299265197060788,
      "grad_norm": 2.7736880779266357,
      "learning_rate": 8.643606644125427e-06,
      "loss": 0.1409,
      "step": 2440
    },
    {
      "epoch": 1.6305945223780896,
      "grad_norm": 0.09321442246437073,
      "learning_rate": 8.636676317608372e-06,
      "loss": 0.0011,
      "step": 2441
    },
    {
      "epoch": 1.6312625250501003,
      "grad_norm": 1.3990628719329834,
      "learning_rate": 8.62974665822458e-06,
      "loss": 0.0126,
      "step": 2442
    },
    {
      "epoch": 1.631930527722111,
      "grad_norm": 2.0162203311920166,
      "learning_rate": 8.622817669365038e-06,
      "loss": 0.0755,
      "step": 2443
    },
    {
      "epoch": 1.6325985303941217,
      "grad_norm": 17.46970558166504,
      "learning_rate": 8.615889354420396e-06,
      "loss": 0.8016,
      "step": 2444
    },
    {
      "epoch": 1.6332665330661322,
      "grad_norm": 11.314149856567383,
      "learning_rate": 8.608961716780984e-06,
      "loss": 0.3729,
      "step": 2445
    },
    {
      "epoch": 1.633934535738143,
      "grad_norm": 0.04392258822917938,
      "learning_rate": 8.602034759836788e-06,
      "loss": 0.0007,
      "step": 2446
    },
    {
      "epoch": 1.6346025384101537,
      "grad_norm": 1.238856315612793,
      "learning_rate": 8.59510848697747e-06,
      "loss": 0.0158,
      "step": 2447
    },
    {
      "epoch": 1.6352705410821642,
      "grad_norm": 1.144517183303833,
      "learning_rate": 8.588182901592355e-06,
      "loss": 0.0088,
      "step": 2448
    },
    {
      "epoch": 1.635938543754175,
      "grad_norm": 2.111332416534424,
      "learning_rate": 8.581258007070433e-06,
      "loss": 0.1073,
      "step": 2449
    },
    {
      "epoch": 1.6366065464261856,
      "grad_norm": 0.02594326063990593,
      "learning_rate": 8.574333806800352e-06,
      "loss": 0.0004,
      "step": 2450
    },
    {
      "epoch": 1.6372745490981964,
      "grad_norm": 2.2994537353515625,
      "learning_rate": 8.567410304170425e-06,
      "loss": 0.1118,
      "step": 2451
    },
    {
      "epoch": 1.637942551770207,
      "grad_norm": 1.5755183696746826,
      "learning_rate": 8.56048750256862e-06,
      "loss": 0.0164,
      "step": 2452
    },
    {
      "epoch": 1.6386105544422178,
      "grad_norm": 1.2993459701538086,
      "learning_rate": 8.553565405382567e-06,
      "loss": 0.0099,
      "step": 2453
    },
    {
      "epoch": 1.6392785571142285,
      "grad_norm": 13.259910583496094,
      "learning_rate": 8.546644015999545e-06,
      "loss": 0.3994,
      "step": 2454
    },
    {
      "epoch": 1.6399465597862393,
      "grad_norm": 0.05378111079335213,
      "learning_rate": 8.539723337806487e-06,
      "loss": 0.0007,
      "step": 2455
    },
    {
      "epoch": 1.64061456245825,
      "grad_norm": 3.60551118850708,
      "learning_rate": 8.532803374189981e-06,
      "loss": 0.0803,
      "step": 2456
    },
    {
      "epoch": 1.6412825651302605,
      "grad_norm": 3.161006450653076,
      "learning_rate": 8.525884128536268e-06,
      "loss": 0.1317,
      "step": 2457
    },
    {
      "epoch": 1.6419505678022712,
      "grad_norm": 0.03794589638710022,
      "learning_rate": 8.51896560423123e-06,
      "loss": 0.0006,
      "step": 2458
    },
    {
      "epoch": 1.642618570474282,
      "grad_norm": 3.084115743637085,
      "learning_rate": 8.512047804660403e-06,
      "loss": 0.2002,
      "step": 2459
    },
    {
      "epoch": 1.6432865731462925,
      "grad_norm": 2.772899627685547,
      "learning_rate": 8.505130733208968e-06,
      "loss": 0.1284,
      "step": 2460
    },
    {
      "epoch": 1.6439545758183032,
      "grad_norm": 7.106797695159912,
      "learning_rate": 8.498214393261742e-06,
      "loss": 0.2581,
      "step": 2461
    },
    {
      "epoch": 1.644622578490314,
      "grad_norm": 0.10432620346546173,
      "learning_rate": 8.491298788203191e-06,
      "loss": 0.0012,
      "step": 2462
    },
    {
      "epoch": 1.6452905811623246,
      "grad_norm": 3.072197675704956,
      "learning_rate": 8.484383921417426e-06,
      "loss": 0.0666,
      "step": 2463
    },
    {
      "epoch": 1.6459585838343354,
      "grad_norm": 2.8256523609161377,
      "learning_rate": 8.477469796288179e-06,
      "loss": 0.1439,
      "step": 2464
    },
    {
      "epoch": 1.646626586506346,
      "grad_norm": 13.209890365600586,
      "learning_rate": 8.47055641619884e-06,
      "loss": 0.6429,
      "step": 2465
    },
    {
      "epoch": 1.6472945891783568,
      "grad_norm": 0.39629536867141724,
      "learning_rate": 8.46364378453242e-06,
      "loss": 0.0038,
      "step": 2466
    },
    {
      "epoch": 1.6479625918503675,
      "grad_norm": 0.0404532253742218,
      "learning_rate": 8.45673190467157e-06,
      "loss": 0.0009,
      "step": 2467
    },
    {
      "epoch": 1.648630594522378,
      "grad_norm": 0.20560063421726227,
      "learning_rate": 8.449820779998575e-06,
      "loss": 0.002,
      "step": 2468
    },
    {
      "epoch": 1.6492985971943888,
      "grad_norm": 14.994217872619629,
      "learning_rate": 8.44291041389534e-06,
      "loss": 0.3141,
      "step": 2469
    },
    {
      "epoch": 1.6499665998663995,
      "grad_norm": 4.380988597869873,
      "learning_rate": 8.436000809743415e-06,
      "loss": 0.1277,
      "step": 2470
    },
    {
      "epoch": 1.65063460253841,
      "grad_norm": 0.03985094651579857,
      "learning_rate": 8.429091970923966e-06,
      "loss": 0.0006,
      "step": 2471
    },
    {
      "epoch": 1.6513026052104207,
      "grad_norm": 1.6631335020065308,
      "learning_rate": 8.422183900817782e-06,
      "loss": 0.0114,
      "step": 2472
    },
    {
      "epoch": 1.6519706078824314,
      "grad_norm": 4.066437721252441,
      "learning_rate": 8.415276602805283e-06,
      "loss": 0.0964,
      "step": 2473
    },
    {
      "epoch": 1.6526386105544422,
      "grad_norm": 2.0131735801696777,
      "learning_rate": 8.40837008026651e-06,
      "loss": 0.0614,
      "step": 2474
    },
    {
      "epoch": 1.653306613226453,
      "grad_norm": 0.8714884519577026,
      "learning_rate": 8.40146433658112e-06,
      "loss": 0.0051,
      "step": 2475
    },
    {
      "epoch": 1.6539746158984636,
      "grad_norm": 12.655879974365234,
      "learning_rate": 8.394559375128397e-06,
      "loss": 0.3777,
      "step": 2476
    },
    {
      "epoch": 1.6546426185704743,
      "grad_norm": 4.63913631439209,
      "learning_rate": 8.387655199287233e-06,
      "loss": 0.2228,
      "step": 2477
    },
    {
      "epoch": 1.655310621242485,
      "grad_norm": 6.872304439544678,
      "learning_rate": 8.380751812436146e-06,
      "loss": 0.1523,
      "step": 2478
    },
    {
      "epoch": 1.6559786239144958,
      "grad_norm": 0.053375113755464554,
      "learning_rate": 8.373849217953256e-06,
      "loss": 0.0008,
      "step": 2479
    },
    {
      "epoch": 1.6566466265865063,
      "grad_norm": 2.4976766109466553,
      "learning_rate": 8.366947419216306e-06,
      "loss": 0.0737,
      "step": 2480
    },
    {
      "epoch": 1.657314629258517,
      "grad_norm": 9.69607162475586,
      "learning_rate": 8.360046419602636e-06,
      "loss": 0.3881,
      "step": 2481
    },
    {
      "epoch": 1.6579826319305278,
      "grad_norm": 1.9125134944915771,
      "learning_rate": 8.353146222489215e-06,
      "loss": 0.0704,
      "step": 2482
    },
    {
      "epoch": 1.6586506346025383,
      "grad_norm": 0.3780556321144104,
      "learning_rate": 8.346246831252599e-06,
      "loss": 0.0027,
      "step": 2483
    },
    {
      "epoch": 1.659318637274549,
      "grad_norm": 11.776028633117676,
      "learning_rate": 8.339348249268963e-06,
      "loss": 0.5549,
      "step": 2484
    },
    {
      "epoch": 1.6599866399465597,
      "grad_norm": 1.6507140398025513,
      "learning_rate": 8.33245047991408e-06,
      "loss": 0.0632,
      "step": 2485
    },
    {
      "epoch": 1.6606546426185704,
      "grad_norm": 4.896416664123535,
      "learning_rate": 8.325553526563327e-06,
      "loss": 0.1958,
      "step": 2486
    },
    {
      "epoch": 1.6613226452905812,
      "grad_norm": 2.5525920391082764,
      "learning_rate": 8.318657392591686e-06,
      "loss": 0.1103,
      "step": 2487
    },
    {
      "epoch": 1.6619906479625919,
      "grad_norm": 0.2999780774116516,
      "learning_rate": 8.311762081373728e-06,
      "loss": 0.0035,
      "step": 2488
    },
    {
      "epoch": 1.6626586506346026,
      "grad_norm": 11.356390953063965,
      "learning_rate": 8.304867596283633e-06,
      "loss": 0.3301,
      "step": 2489
    },
    {
      "epoch": 1.6633266533066133,
      "grad_norm": 1.7227081060409546,
      "learning_rate": 8.297973940695164e-06,
      "loss": 0.0904,
      "step": 2490
    },
    {
      "epoch": 1.663994655978624,
      "grad_norm": 3.0361220836639404,
      "learning_rate": 8.291081117981687e-06,
      "loss": 0.1726,
      "step": 2491
    },
    {
      "epoch": 1.6646626586506346,
      "grad_norm": 2.995093584060669,
      "learning_rate": 8.284189131516162e-06,
      "loss": 0.2078,
      "step": 2492
    },
    {
      "epoch": 1.6653306613226453,
      "grad_norm": 1.857338547706604,
      "learning_rate": 8.277297984671134e-06,
      "loss": 0.0685,
      "step": 2493
    },
    {
      "epoch": 1.665998663994656,
      "grad_norm": 0.015851914882659912,
      "learning_rate": 8.270407680818736e-06,
      "loss": 0.0003,
      "step": 2494
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 3.686009645462036,
      "learning_rate": 8.263518223330698e-06,
      "loss": 0.1493,
      "step": 2495
    },
    {
      "epoch": 1.6673346693386772,
      "grad_norm": 0.18817515671253204,
      "learning_rate": 8.256629615578324e-06,
      "loss": 0.0018,
      "step": 2496
    },
    {
      "epoch": 1.668002672010688,
      "grad_norm": 0.06483982503414154,
      "learning_rate": 8.249741860932513e-06,
      "loss": 0.0009,
      "step": 2497
    },
    {
      "epoch": 1.6686706746826987,
      "grad_norm": 0.21399463713169098,
      "learning_rate": 8.24285496276374e-06,
      "loss": 0.0018,
      "step": 2498
    },
    {
      "epoch": 1.6693386773547094,
      "grad_norm": 3.4974145889282227,
      "learning_rate": 8.235968924442058e-06,
      "loss": 0.2236,
      "step": 2499
    },
    {
      "epoch": 1.6700066800267201,
      "grad_norm": 4.193124294281006,
      "learning_rate": 8.229083749337106e-06,
      "loss": 0.0963,
      "step": 2500
    },
    {
      "epoch": 1.6706746826987309,
      "grad_norm": 5.203175067901611,
      "learning_rate": 8.222199440818099e-06,
      "loss": 0.1452,
      "step": 2501
    },
    {
      "epoch": 1.6713426853707416,
      "grad_norm": 0.8791658878326416,
      "learning_rate": 8.215316002253825e-06,
      "loss": 0.0097,
      "step": 2502
    },
    {
      "epoch": 1.6720106880427523,
      "grad_norm": 3.3744704723358154,
      "learning_rate": 8.208433437012652e-06,
      "loss": 0.1991,
      "step": 2503
    },
    {
      "epoch": 1.6726786907147628,
      "grad_norm": 1.6156518459320068,
      "learning_rate": 8.201551748462514e-06,
      "loss": 0.0385,
      "step": 2504
    },
    {
      "epoch": 1.6733466933867736,
      "grad_norm": 5.065295219421387,
      "learning_rate": 8.194670939970921e-06,
      "loss": 0.2012,
      "step": 2505
    },
    {
      "epoch": 1.6740146960587843,
      "grad_norm": 0.06738738715648651,
      "learning_rate": 8.18779101490495e-06,
      "loss": 0.0009,
      "step": 2506
    },
    {
      "epoch": 1.6746826987307948,
      "grad_norm": 15.513924598693848,
      "learning_rate": 8.180911976631246e-06,
      "loss": 0.2436,
      "step": 2507
    },
    {
      "epoch": 1.6753507014028055,
      "grad_norm": 3.458505630493164,
      "learning_rate": 8.174033828516014e-06,
      "loss": 0.1829,
      "step": 2508
    },
    {
      "epoch": 1.6760187040748162,
      "grad_norm": 1.0250548124313354,
      "learning_rate": 8.167156573925039e-06,
      "loss": 0.0084,
      "step": 2509
    },
    {
      "epoch": 1.676686706746827,
      "grad_norm": 6.334372520446777,
      "learning_rate": 8.160280216223653e-06,
      "loss": 0.0635,
      "step": 2510
    },
    {
      "epoch": 1.6773547094188377,
      "grad_norm": 9.241316795349121,
      "learning_rate": 8.153404758776757e-06,
      "loss": 0.3998,
      "step": 2511
    },
    {
      "epoch": 1.6780227120908484,
      "grad_norm": 1.803844690322876,
      "learning_rate": 8.146530204948811e-06,
      "loss": 0.0944,
      "step": 2512
    },
    {
      "epoch": 1.6786907147628591,
      "grad_norm": 2.032973051071167,
      "learning_rate": 8.13965655810383e-06,
      "loss": 0.0772,
      "step": 2513
    },
    {
      "epoch": 1.6793587174348699,
      "grad_norm": 0.36467599868774414,
      "learning_rate": 8.132783821605387e-06,
      "loss": 0.0037,
      "step": 2514
    },
    {
      "epoch": 1.6800267201068806,
      "grad_norm": 4.729567527770996,
      "learning_rate": 8.125911998816611e-06,
      "loss": 0.1131,
      "step": 2515
    },
    {
      "epoch": 1.680694722778891,
      "grad_norm": 2.6185853481292725,
      "learning_rate": 8.119041093100183e-06,
      "loss": 0.1278,
      "step": 2516
    },
    {
      "epoch": 1.6813627254509018,
      "grad_norm": 0.1935180276632309,
      "learning_rate": 8.11217110781833e-06,
      "loss": 0.002,
      "step": 2517
    },
    {
      "epoch": 1.6820307281229125,
      "grad_norm": 17.140695571899414,
      "learning_rate": 8.105302046332837e-06,
      "loss": 0.4037,
      "step": 2518
    },
    {
      "epoch": 1.682698730794923,
      "grad_norm": 1.7780238389968872,
      "learning_rate": 8.098433912005028e-06,
      "loss": 0.1049,
      "step": 2519
    },
    {
      "epoch": 1.6833667334669338,
      "grad_norm": 1.782686710357666,
      "learning_rate": 8.091566708195786e-06,
      "loss": 0.1123,
      "step": 2520
    },
    {
      "epoch": 1.6840347361389445,
      "grad_norm": 5.289880275726318,
      "learning_rate": 8.084700438265522e-06,
      "loss": 0.2676,
      "step": 2521
    },
    {
      "epoch": 1.6847027388109552,
      "grad_norm": 2.874788761138916,
      "learning_rate": 8.077835105574208e-06,
      "loss": 0.2232,
      "step": 2522
    },
    {
      "epoch": 1.685370741482966,
      "grad_norm": 8.58620548248291,
      "learning_rate": 8.070970713481341e-06,
      "loss": 0.2196,
      "step": 2523
    },
    {
      "epoch": 1.6860387441549767,
      "grad_norm": 6.460493087768555,
      "learning_rate": 8.064107265345975e-06,
      "loss": 0.2889,
      "step": 2524
    },
    {
      "epoch": 1.6867067468269874,
      "grad_norm": 4.931967735290527,
      "learning_rate": 8.05724476452668e-06,
      "loss": 0.0987,
      "step": 2525
    },
    {
      "epoch": 1.6873747494989981,
      "grad_norm": 5.091831684112549,
      "learning_rate": 8.05038321438158e-06,
      "loss": 0.275,
      "step": 2526
    },
    {
      "epoch": 1.6880427521710086,
      "grad_norm": 6.103927135467529,
      "learning_rate": 8.043522618268327e-06,
      "loss": 0.2146,
      "step": 2527
    },
    {
      "epoch": 1.6887107548430194,
      "grad_norm": 3.543755531311035,
      "learning_rate": 8.03666297954411e-06,
      "loss": 0.0349,
      "step": 2528
    },
    {
      "epoch": 1.68937875751503,
      "grad_norm": 3.444753885269165,
      "learning_rate": 8.029804301565645e-06,
      "loss": 0.144,
      "step": 2529
    },
    {
      "epoch": 1.6900467601870406,
      "grad_norm": 0.03239089623093605,
      "learning_rate": 8.02294658768918e-06,
      "loss": 0.0005,
      "step": 2530
    },
    {
      "epoch": 1.6907147628590513,
      "grad_norm": 5.3471198081970215,
      "learning_rate": 8.016089841270495e-06,
      "loss": 0.0943,
      "step": 2531
    },
    {
      "epoch": 1.691382765531062,
      "grad_norm": 1.0099854469299316,
      "learning_rate": 8.009234065664887e-06,
      "loss": 0.0087,
      "step": 2532
    },
    {
      "epoch": 1.6920507682030728,
      "grad_norm": 4.134491443634033,
      "learning_rate": 8.002379264227189e-06,
      "loss": 0.1275,
      "step": 2533
    },
    {
      "epoch": 1.6927187708750835,
      "grad_norm": 2.989103078842163,
      "learning_rate": 7.995525440311746e-06,
      "loss": 0.1266,
      "step": 2534
    },
    {
      "epoch": 1.6933867735470942,
      "grad_norm": 0.7901011109352112,
      "learning_rate": 7.988672597272434e-06,
      "loss": 0.0106,
      "step": 2535
    },
    {
      "epoch": 1.694054776219105,
      "grad_norm": 8.886364936828613,
      "learning_rate": 7.981820738462646e-06,
      "loss": 0.2216,
      "step": 2536
    },
    {
      "epoch": 1.6947227788911157,
      "grad_norm": 2.4428231716156006,
      "learning_rate": 7.974969867235289e-06,
      "loss": 0.1701,
      "step": 2537
    },
    {
      "epoch": 1.6953907815631264,
      "grad_norm": 1.4809484481811523,
      "learning_rate": 7.968119986942798e-06,
      "loss": 0.1222,
      "step": 2538
    },
    {
      "epoch": 1.696058784235137,
      "grad_norm": 0.04590412229299545,
      "learning_rate": 7.961271100937112e-06,
      "loss": 0.0005,
      "step": 2539
    },
    {
      "epoch": 1.6967267869071476,
      "grad_norm": 0.22576509416103363,
      "learning_rate": 7.954423212569683e-06,
      "loss": 0.0027,
      "step": 2540
    },
    {
      "epoch": 1.6973947895791583,
      "grad_norm": 4.962433815002441,
      "learning_rate": 7.947576325191486e-06,
      "loss": 0.1282,
      "step": 2541
    },
    {
      "epoch": 1.6980627922511689,
      "grad_norm": 0.0386151559650898,
      "learning_rate": 7.940730442152998e-06,
      "loss": 0.0005,
      "step": 2542
    },
    {
      "epoch": 1.6987307949231796,
      "grad_norm": 2.3355884552001953,
      "learning_rate": 7.9338855668042e-06,
      "loss": 0.0969,
      "step": 2543
    },
    {
      "epoch": 1.6993987975951903,
      "grad_norm": 3.111144781112671,
      "learning_rate": 7.927041702494594e-06,
      "loss": 0.1303,
      "step": 2544
    },
    {
      "epoch": 1.700066800267201,
      "grad_norm": 0.24247321486473083,
      "learning_rate": 7.920198852573172e-06,
      "loss": 0.0027,
      "step": 2545
    },
    {
      "epoch": 1.7007348029392118,
      "grad_norm": 3.7830982208251953,
      "learning_rate": 7.913357020388437e-06,
      "loss": 0.1568,
      "step": 2546
    },
    {
      "epoch": 1.7014028056112225,
      "grad_norm": 9.69860553741455,
      "learning_rate": 7.906516209288399e-06,
      "loss": 0.2524,
      "step": 2547
    },
    {
      "epoch": 1.7020708082832332,
      "grad_norm": 6.946743488311768,
      "learning_rate": 7.899676422620558e-06,
      "loss": 0.0977,
      "step": 2548
    },
    {
      "epoch": 1.702738810955244,
      "grad_norm": 1.8678792715072632,
      "learning_rate": 7.892837663731919e-06,
      "loss": 0.0819,
      "step": 2549
    },
    {
      "epoch": 1.7034068136272547,
      "grad_norm": 3.214998722076416,
      "learning_rate": 7.885999935968982e-06,
      "loss": 0.1055,
      "step": 2550
    },
    {
      "epoch": 1.7040748162992652,
      "grad_norm": 1.8626035451889038,
      "learning_rate": 7.879163242677751e-06,
      "loss": 0.0847,
      "step": 2551
    },
    {
      "epoch": 1.7047428189712759,
      "grad_norm": 4.348304748535156,
      "learning_rate": 7.872327587203701e-06,
      "loss": 0.0932,
      "step": 2552
    },
    {
      "epoch": 1.7054108216432866,
      "grad_norm": 4.174911975860596,
      "learning_rate": 7.865492972891824e-06,
      "loss": 0.0962,
      "step": 2553
    },
    {
      "epoch": 1.7060788243152971,
      "grad_norm": 3.3291406631469727,
      "learning_rate": 7.858659403086589e-06,
      "loss": 0.2308,
      "step": 2554
    },
    {
      "epoch": 1.7067468269873078,
      "grad_norm": 11.557015419006348,
      "learning_rate": 7.851826881131959e-06,
      "loss": 0.3556,
      "step": 2555
    },
    {
      "epoch": 1.7074148296593186,
      "grad_norm": 11.143560409545898,
      "learning_rate": 7.844995410371381e-06,
      "loss": 0.6784,
      "step": 2556
    },
    {
      "epoch": 1.7080828323313293,
      "grad_norm": 3.93977952003479,
      "learning_rate": 7.838164994147792e-06,
      "loss": 0.0493,
      "step": 2557
    },
    {
      "epoch": 1.70875083500334,
      "grad_norm": 3.52976131439209,
      "learning_rate": 7.831335635803608e-06,
      "loss": 0.0608,
      "step": 2558
    },
    {
      "epoch": 1.7094188376753507,
      "grad_norm": 0.20560699701309204,
      "learning_rate": 7.824507338680729e-06,
      "loss": 0.0028,
      "step": 2559
    },
    {
      "epoch": 1.7100868403473615,
      "grad_norm": 0.014674664475023746,
      "learning_rate": 7.817680106120541e-06,
      "loss": 0.0003,
      "step": 2560
    },
    {
      "epoch": 1.7107548430193722,
      "grad_norm": 0.044783320277929306,
      "learning_rate": 7.810853941463898e-06,
      "loss": 0.0006,
      "step": 2561
    },
    {
      "epoch": 1.711422845691383,
      "grad_norm": 2.7460222244262695,
      "learning_rate": 7.80402884805114e-06,
      "loss": 0.1927,
      "step": 2562
    },
    {
      "epoch": 1.7120908483633934,
      "grad_norm": 2.2819528579711914,
      "learning_rate": 7.79720482922208e-06,
      "loss": 0.0984,
      "step": 2563
    },
    {
      "epoch": 1.7127588510354042,
      "grad_norm": 5.842660427093506,
      "learning_rate": 7.790381888316009e-06,
      "loss": 0.1002,
      "step": 2564
    },
    {
      "epoch": 1.7134268537074149,
      "grad_norm": 2.3462469577789307,
      "learning_rate": 7.78356002867168e-06,
      "loss": 0.1004,
      "step": 2565
    },
    {
      "epoch": 1.7140948563794254,
      "grad_norm": 0.06022985652089119,
      "learning_rate": 7.776739253627334e-06,
      "loss": 0.0007,
      "step": 2566
    },
    {
      "epoch": 1.714762859051436,
      "grad_norm": 5.44453239440918,
      "learning_rate": 7.769919566520662e-06,
      "loss": 0.2117,
      "step": 2567
    },
    {
      "epoch": 1.7154308617234468,
      "grad_norm": 2.3032443523406982,
      "learning_rate": 7.763100970688838e-06,
      "loss": 0.1225,
      "step": 2568
    },
    {
      "epoch": 1.7160988643954576,
      "grad_norm": 3.6962149143218994,
      "learning_rate": 7.756283469468498e-06,
      "loss": 0.1385,
      "step": 2569
    },
    {
      "epoch": 1.7167668670674683,
      "grad_norm": 2.371624708175659,
      "learning_rate": 7.749467066195732e-06,
      "loss": 0.0993,
      "step": 2570
    },
    {
      "epoch": 1.717434869739479,
      "grad_norm": 4.588716506958008,
      "learning_rate": 7.742651764206104e-06,
      "loss": 0.2091,
      "step": 2571
    },
    {
      "epoch": 1.7181028724114897,
      "grad_norm": 3.1662187576293945,
      "learning_rate": 7.735837566834639e-06,
      "loss": 0.0321,
      "step": 2572
    },
    {
      "epoch": 1.7187708750835005,
      "grad_norm": 3.45961594581604,
      "learning_rate": 7.729024477415817e-06,
      "loss": 0.1032,
      "step": 2573
    },
    {
      "epoch": 1.7194388777555112,
      "grad_norm": 0.1152808889746666,
      "learning_rate": 7.722212499283579e-06,
      "loss": 0.0021,
      "step": 2574
    },
    {
      "epoch": 1.7201068804275217,
      "grad_norm": 3.982513904571533,
      "learning_rate": 7.715401635771316e-06,
      "loss": 0.283,
      "step": 2575
    },
    {
      "epoch": 1.7207748830995324,
      "grad_norm": 1.4500993490219116,
      "learning_rate": 7.708591890211885e-06,
      "loss": 0.0138,
      "step": 2576
    },
    {
      "epoch": 1.7214428857715431,
      "grad_norm": 5.115664482116699,
      "learning_rate": 7.701783265937583e-06,
      "loss": 0.0315,
      "step": 2577
    },
    {
      "epoch": 1.7221108884435536,
      "grad_norm": 0.9819155335426331,
      "learning_rate": 7.694975766280173e-06,
      "loss": 0.0161,
      "step": 2578
    },
    {
      "epoch": 1.7227788911155644,
      "grad_norm": 0.054200418293476105,
      "learning_rate": 7.688169394570846e-06,
      "loss": 0.0007,
      "step": 2579
    },
    {
      "epoch": 1.723446893787575,
      "grad_norm": 13.060599327087402,
      "learning_rate": 7.681364154140264e-06,
      "loss": 0.4437,
      "step": 2580
    },
    {
      "epoch": 1.7241148964595858,
      "grad_norm": 0.5166065096855164,
      "learning_rate": 7.674560048318522e-06,
      "loss": 0.0045,
      "step": 2581
    },
    {
      "epoch": 1.7247828991315965,
      "grad_norm": 0.11318790167570114,
      "learning_rate": 7.667757080435166e-06,
      "loss": 0.0014,
      "step": 2582
    },
    {
      "epoch": 1.7254509018036073,
      "grad_norm": 2.4331953525543213,
      "learning_rate": 7.660955253819178e-06,
      "loss": 0.0994,
      "step": 2583
    },
    {
      "epoch": 1.726118904475618,
      "grad_norm": 0.37997403740882874,
      "learning_rate": 7.654154571798991e-06,
      "loss": 0.0043,
      "step": 2584
    },
    {
      "epoch": 1.7267869071476287,
      "grad_norm": 3.92252516746521,
      "learning_rate": 7.64735503770247e-06,
      "loss": 0.1092,
      "step": 2585
    },
    {
      "epoch": 1.7274549098196392,
      "grad_norm": 0.8469244241714478,
      "learning_rate": 7.640556654856927e-06,
      "loss": 0.0087,
      "step": 2586
    },
    {
      "epoch": 1.72812291249165,
      "grad_norm": 7.00700044631958,
      "learning_rate": 7.633759426589093e-06,
      "loss": 0.3674,
      "step": 2587
    },
    {
      "epoch": 1.7287909151636607,
      "grad_norm": 1.9733301401138306,
      "learning_rate": 7.626963356225156e-06,
      "loss": 0.0667,
      "step": 2588
    },
    {
      "epoch": 1.7294589178356712,
      "grad_norm": 3.897984027862549,
      "learning_rate": 7.620168447090722e-06,
      "loss": 0.2142,
      "step": 2589
    },
    {
      "epoch": 1.730126920507682,
      "grad_norm": 3.2313127517700195,
      "learning_rate": 7.6133747025108385e-06,
      "loss": 0.1624,
      "step": 2590
    },
    {
      "epoch": 1.7307949231796926,
      "grad_norm": 0.04615160822868347,
      "learning_rate": 7.606582125809976e-06,
      "loss": 0.0005,
      "step": 2591
    },
    {
      "epoch": 1.7314629258517034,
      "grad_norm": 0.3527034521102905,
      "learning_rate": 7.599790720312035e-06,
      "loss": 0.0033,
      "step": 2592
    },
    {
      "epoch": 1.732130928523714,
      "grad_norm": 0.6358649134635925,
      "learning_rate": 7.593000489340347e-06,
      "loss": 0.0066,
      "step": 2593
    },
    {
      "epoch": 1.7327989311957248,
      "grad_norm": 7.880998134613037,
      "learning_rate": 7.586211436217662e-06,
      "loss": 0.2041,
      "step": 2594
    },
    {
      "epoch": 1.7334669338677355,
      "grad_norm": 6.841890335083008,
      "learning_rate": 7.579423564266164e-06,
      "loss": 0.2378,
      "step": 2595
    },
    {
      "epoch": 1.7341349365397463,
      "grad_norm": 3.0670955181121826,
      "learning_rate": 7.5726368768074465e-06,
      "loss": 0.2143,
      "step": 2596
    },
    {
      "epoch": 1.734802939211757,
      "grad_norm": 0.054359592497348785,
      "learning_rate": 7.565851377162532e-06,
      "loss": 0.0008,
      "step": 2597
    },
    {
      "epoch": 1.7354709418837675,
      "grad_norm": 6.507416725158691,
      "learning_rate": 7.559067068651855e-06,
      "loss": 0.0927,
      "step": 2598
    },
    {
      "epoch": 1.7361389445557782,
      "grad_norm": 7.280198574066162,
      "learning_rate": 7.552283954595277e-06,
      "loss": 0.106,
      "step": 2599
    },
    {
      "epoch": 1.736806947227789,
      "grad_norm": 0.733461320400238,
      "learning_rate": 7.545502038312062e-06,
      "loss": 0.0063,
      "step": 2600
    },
    {
      "epoch": 1.7374749498997994,
      "grad_norm": 0.08690186589956284,
      "learning_rate": 7.538721323120905e-06,
      "loss": 0.0011,
      "step": 2601
    },
    {
      "epoch": 1.7381429525718102,
      "grad_norm": 3.6215548515319824,
      "learning_rate": 7.531941812339894e-06,
      "loss": 0.1975,
      "step": 2602
    },
    {
      "epoch": 1.738810955243821,
      "grad_norm": 0.283404141664505,
      "learning_rate": 7.525163509286544e-06,
      "loss": 0.0028,
      "step": 2603
    },
    {
      "epoch": 1.7394789579158316,
      "grad_norm": 1.315273404121399,
      "learning_rate": 7.51838641727777e-06,
      "loss": 0.0429,
      "step": 2604
    },
    {
      "epoch": 1.7401469605878424,
      "grad_norm": 1.3803060054779053,
      "learning_rate": 7.511610539629895e-06,
      "loss": 0.0116,
      "step": 2605
    },
    {
      "epoch": 1.740814963259853,
      "grad_norm": 0.12222836166620255,
      "learning_rate": 7.504835879658645e-06,
      "loss": 0.0018,
      "step": 2606
    },
    {
      "epoch": 1.7414829659318638,
      "grad_norm": 0.11051100492477417,
      "learning_rate": 7.4980624406791616e-06,
      "loss": 0.0017,
      "step": 2607
    },
    {
      "epoch": 1.7421509686038745,
      "grad_norm": 0.8500162363052368,
      "learning_rate": 7.491290226005976e-06,
      "loss": 0.0261,
      "step": 2608
    },
    {
      "epoch": 1.7428189712758853,
      "grad_norm": 0.01678202673792839,
      "learning_rate": 7.48451923895303e-06,
      "loss": 0.0004,
      "step": 2609
    },
    {
      "epoch": 1.7434869739478958,
      "grad_norm": 0.038141146302223206,
      "learning_rate": 7.477749482833659e-06,
      "loss": 0.0005,
      "step": 2610
    },
    {
      "epoch": 1.7441549766199065,
      "grad_norm": 4.556097984313965,
      "learning_rate": 7.470980960960597e-06,
      "loss": 0.1115,
      "step": 2611
    },
    {
      "epoch": 1.7448229792919172,
      "grad_norm": 19.637187957763672,
      "learning_rate": 7.464213676645975e-06,
      "loss": 0.6059,
      "step": 2612
    },
    {
      "epoch": 1.7454909819639277,
      "grad_norm": 2.9165279865264893,
      "learning_rate": 7.457447633201322e-06,
      "loss": 0.107,
      "step": 2613
    },
    {
      "epoch": 1.7461589846359384,
      "grad_norm": 0.012732157483696938,
      "learning_rate": 7.450682833937547e-06,
      "loss": 0.0003,
      "step": 2614
    },
    {
      "epoch": 1.7468269873079492,
      "grad_norm": 5.227341175079346,
      "learning_rate": 7.443919282164967e-06,
      "loss": 0.1459,
      "step": 2615
    },
    {
      "epoch": 1.74749498997996,
      "grad_norm": 4.601859092712402,
      "learning_rate": 7.437156981193275e-06,
      "loss": 0.1857,
      "step": 2616
    },
    {
      "epoch": 1.7481629926519706,
      "grad_norm": 5.936230659484863,
      "learning_rate": 7.43039593433156e-06,
      "loss": 0.2604,
      "step": 2617
    },
    {
      "epoch": 1.7488309953239813,
      "grad_norm": 1.7465709447860718,
      "learning_rate": 7.4236361448882955e-06,
      "loss": 0.0772,
      "step": 2618
    },
    {
      "epoch": 1.749498997995992,
      "grad_norm": 0.07671176642179489,
      "learning_rate": 7.416877616171336e-06,
      "loss": 0.001,
      "step": 2619
    },
    {
      "epoch": 1.7501670006680028,
      "grad_norm": 4.705132007598877,
      "learning_rate": 7.410120351487927e-06,
      "loss": 0.2266,
      "step": 2620
    },
    {
      "epoch": 1.7508350033400135,
      "grad_norm": 0.1332361400127411,
      "learning_rate": 7.4033643541446844e-06,
      "loss": 0.0015,
      "step": 2621
    },
    {
      "epoch": 1.751503006012024,
      "grad_norm": 0.7887873649597168,
      "learning_rate": 7.3966096274476196e-06,
      "loss": 0.0085,
      "step": 2622
    },
    {
      "epoch": 1.7521710086840347,
      "grad_norm": 0.06898272782564163,
      "learning_rate": 7.389856174702101e-06,
      "loss": 0.0008,
      "step": 2623
    },
    {
      "epoch": 1.7528390113560455,
      "grad_norm": 0.05045164003968239,
      "learning_rate": 7.383103999212893e-06,
      "loss": 0.0009,
      "step": 2624
    },
    {
      "epoch": 1.753507014028056,
      "grad_norm": 10.019340515136719,
      "learning_rate": 7.3763531042841215e-06,
      "loss": 0.1831,
      "step": 2625
    },
    {
      "epoch": 1.7541750167000667,
      "grad_norm": 0.32986146211624146,
      "learning_rate": 7.369603493219297e-06,
      "loss": 0.0024,
      "step": 2626
    },
    {
      "epoch": 1.7548430193720774,
      "grad_norm": 3.245800018310547,
      "learning_rate": 7.362855169321291e-06,
      "loss": 0.2468,
      "step": 2627
    },
    {
      "epoch": 1.7555110220440882,
      "grad_norm": 0.26718392968177795,
      "learning_rate": 7.356108135892357e-06,
      "loss": 0.0027,
      "step": 2628
    },
    {
      "epoch": 1.7561790247160989,
      "grad_norm": 12.752044677734375,
      "learning_rate": 7.349362396234103e-06,
      "loss": 0.1549,
      "step": 2629
    },
    {
      "epoch": 1.7568470273881096,
      "grad_norm": 8.403145790100098,
      "learning_rate": 7.342617953647517e-06,
      "loss": 0.1961,
      "step": 2630
    },
    {
      "epoch": 1.7575150300601203,
      "grad_norm": 18.930377960205078,
      "learning_rate": 7.335874811432948e-06,
      "loss": 0.3723,
      "step": 2631
    },
    {
      "epoch": 1.758183032732131,
      "grad_norm": 13.407149314880371,
      "learning_rate": 7.329132972890101e-06,
      "loss": 0.36,
      "step": 2632
    },
    {
      "epoch": 1.7588510354041418,
      "grad_norm": 3.1491246223449707,
      "learning_rate": 7.322392441318049e-06,
      "loss": 0.1809,
      "step": 2633
    },
    {
      "epoch": 1.7595190380761523,
      "grad_norm": 2.4944632053375244,
      "learning_rate": 7.315653220015233e-06,
      "loss": 0.1043,
      "step": 2634
    },
    {
      "epoch": 1.760187040748163,
      "grad_norm": 11.40693187713623,
      "learning_rate": 7.308915312279438e-06,
      "loss": 0.3143,
      "step": 2635
    },
    {
      "epoch": 1.7608550434201735,
      "grad_norm": 6.927013874053955,
      "learning_rate": 7.302178721407819e-06,
      "loss": 0.221,
      "step": 2636
    },
    {
      "epoch": 1.7615230460921842,
      "grad_norm": 0.20245879888534546,
      "learning_rate": 7.29544345069688e-06,
      "loss": 0.0009,
      "step": 2637
    },
    {
      "epoch": 1.762191048764195,
      "grad_norm": 4.09792947769165,
      "learning_rate": 7.288709503442477e-06,
      "loss": 0.1644,
      "step": 2638
    },
    {
      "epoch": 1.7628590514362057,
      "grad_norm": 2.2349066734313965,
      "learning_rate": 7.281976882939829e-06,
      "loss": 0.1046,
      "step": 2639
    },
    {
      "epoch": 1.7635270541082164,
      "grad_norm": 0.08189456909894943,
      "learning_rate": 7.275245592483493e-06,
      "loss": 0.0007,
      "step": 2640
    },
    {
      "epoch": 1.7641950567802271,
      "grad_norm": 3.9824934005737305,
      "learning_rate": 7.26851563536738e-06,
      "loss": 0.2194,
      "step": 2641
    },
    {
      "epoch": 1.7648630594522379,
      "grad_norm": 0.024622144177556038,
      "learning_rate": 7.261787014884752e-06,
      "loss": 0.0003,
      "step": 2642
    },
    {
      "epoch": 1.7655310621242486,
      "grad_norm": 1.8985627889633179,
      "learning_rate": 7.2550597343282135e-06,
      "loss": 0.0269,
      "step": 2643
    },
    {
      "epoch": 1.7661990647962593,
      "grad_norm": 0.5188906788825989,
      "learning_rate": 7.248333796989713e-06,
      "loss": 0.0044,
      "step": 2644
    },
    {
      "epoch": 1.7668670674682698,
      "grad_norm": 3.5202438831329346,
      "learning_rate": 7.241609206160543e-06,
      "loss": 0.2346,
      "step": 2645
    },
    {
      "epoch": 1.7675350701402806,
      "grad_norm": 1.5614243745803833,
      "learning_rate": 7.234885965131337e-06,
      "loss": 0.045,
      "step": 2646
    },
    {
      "epoch": 1.7682030728122913,
      "grad_norm": 2.5465915203094482,
      "learning_rate": 7.2281640771920695e-06,
      "loss": 0.0951,
      "step": 2647
    },
    {
      "epoch": 1.7688710754843018,
      "grad_norm": 4.130868911743164,
      "learning_rate": 7.22144354563205e-06,
      "loss": 0.2146,
      "step": 2648
    },
    {
      "epoch": 1.7695390781563125,
      "grad_norm": 0.04443024843931198,
      "learning_rate": 7.214724373739924e-06,
      "loss": 0.0006,
      "step": 2649
    },
    {
      "epoch": 1.7702070808283232,
      "grad_norm": 2.6650681495666504,
      "learning_rate": 7.208006564803672e-06,
      "loss": 0.1706,
      "step": 2650
    },
    {
      "epoch": 1.770875083500334,
      "grad_norm": 4.907276153564453,
      "learning_rate": 7.201290122110611e-06,
      "loss": 0.2438,
      "step": 2651
    },
    {
      "epoch": 1.7715430861723447,
      "grad_norm": 0.29235538840293884,
      "learning_rate": 7.194575048947385e-06,
      "loss": 0.0033,
      "step": 2652
    },
    {
      "epoch": 1.7722110888443554,
      "grad_norm": 0.3141949474811554,
      "learning_rate": 7.187861348599974e-06,
      "loss": 0.0029,
      "step": 2653
    },
    {
      "epoch": 1.7728790915163661,
      "grad_norm": 4.7815022468566895,
      "learning_rate": 7.181149024353677e-06,
      "loss": 0.2393,
      "step": 2654
    },
    {
      "epoch": 1.7735470941883769,
      "grad_norm": 2.4314353466033936,
      "learning_rate": 7.174438079493128e-06,
      "loss": 0.1622,
      "step": 2655
    },
    {
      "epoch": 1.7742150968603876,
      "grad_norm": 5.378669738769531,
      "learning_rate": 7.1677285173022815e-06,
      "loss": 0.1441,
      "step": 2656
    },
    {
      "epoch": 1.774883099532398,
      "grad_norm": 0.38477960228919983,
      "learning_rate": 7.16102034106442e-06,
      "loss": 0.0052,
      "step": 2657
    },
    {
      "epoch": 1.7755511022044088,
      "grad_norm": 0.03848780319094658,
      "learning_rate": 7.154313554062137e-06,
      "loss": 0.0006,
      "step": 2658
    },
    {
      "epoch": 1.7762191048764195,
      "grad_norm": 0.050698548555374146,
      "learning_rate": 7.147608159577359e-06,
      "loss": 0.0007,
      "step": 2659
    },
    {
      "epoch": 1.77688710754843,
      "grad_norm": 1.1444698572158813,
      "learning_rate": 7.140904160891322e-06,
      "loss": 0.0074,
      "step": 2660
    },
    {
      "epoch": 1.7775551102204408,
      "grad_norm": 7.657905101776123,
      "learning_rate": 7.134201561284588e-06,
      "loss": 0.1101,
      "step": 2661
    },
    {
      "epoch": 1.7782231128924515,
      "grad_norm": 2.2282614707946777,
      "learning_rate": 7.1275003640370255e-06,
      "loss": 0.187,
      "step": 2662
    },
    {
      "epoch": 1.7788911155644622,
      "grad_norm": 0.024886684492230415,
      "learning_rate": 7.12080057242782e-06,
      "loss": 0.0004,
      "step": 2663
    },
    {
      "epoch": 1.779559118236473,
      "grad_norm": 3.782835006713867,
      "learning_rate": 7.11410218973547e-06,
      "loss": 0.2138,
      "step": 2664
    },
    {
      "epoch": 1.7802271209084837,
      "grad_norm": 3.1601150035858154,
      "learning_rate": 7.107405219237782e-06,
      "loss": 0.1723,
      "step": 2665
    },
    {
      "epoch": 1.7808951235804944,
      "grad_norm": 0.17189988493919373,
      "learning_rate": 7.100709664211881e-06,
      "loss": 0.0016,
      "step": 2666
    },
    {
      "epoch": 1.7815631262525051,
      "grad_norm": 2.9153575897216797,
      "learning_rate": 7.094015527934184e-06,
      "loss": 0.1845,
      "step": 2667
    },
    {
      "epoch": 1.7822311289245159,
      "grad_norm": 2.9054834842681885,
      "learning_rate": 7.087322813680422e-06,
      "loss": 0.0686,
      "step": 2668
    },
    {
      "epoch": 1.7828991315965264,
      "grad_norm": 0.16785947978496552,
      "learning_rate": 7.080631524725632e-06,
      "loss": 0.002,
      "step": 2669
    },
    {
      "epoch": 1.783567134268537,
      "grad_norm": 4.656161308288574,
      "learning_rate": 7.0739416643441525e-06,
      "loss": 0.1875,
      "step": 2670
    },
    {
      "epoch": 1.7842351369405478,
      "grad_norm": 5.7742486000061035,
      "learning_rate": 7.067253235809617e-06,
      "loss": 0.3368,
      "step": 2671
    },
    {
      "epoch": 1.7849031396125583,
      "grad_norm": 4.537130355834961,
      "learning_rate": 7.060566242394967e-06,
      "loss": 0.1423,
      "step": 2672
    },
    {
      "epoch": 1.785571142284569,
      "grad_norm": 0.2660506069660187,
      "learning_rate": 7.053880687372436e-06,
      "loss": 0.0018,
      "step": 2673
    },
    {
      "epoch": 1.7862391449565798,
      "grad_norm": 3.169595718383789,
      "learning_rate": 7.047196574013557e-06,
      "loss": 0.1123,
      "step": 2674
    },
    {
      "epoch": 1.7869071476285905,
      "grad_norm": 4.05760383605957,
      "learning_rate": 7.040513905589157e-06,
      "loss": 0.1897,
      "step": 2675
    },
    {
      "epoch": 1.7875751503006012,
      "grad_norm": 8.444608688354492,
      "learning_rate": 7.03383268536935e-06,
      "loss": 0.2959,
      "step": 2676
    },
    {
      "epoch": 1.788243152972612,
      "grad_norm": 6.314746856689453,
      "learning_rate": 7.027152916623546e-06,
      "loss": 0.1408,
      "step": 2677
    },
    {
      "epoch": 1.7889111556446227,
      "grad_norm": 3.30155348777771,
      "learning_rate": 7.020474602620451e-06,
      "loss": 0.1316,
      "step": 2678
    },
    {
      "epoch": 1.7895791583166334,
      "grad_norm": 4.885916709899902,
      "learning_rate": 7.013797746628046e-06,
      "loss": 0.1478,
      "step": 2679
    },
    {
      "epoch": 1.7902471609886441,
      "grad_norm": 3.665462017059326,
      "learning_rate": 7.007122351913614e-06,
      "loss": 0.1195,
      "step": 2680
    },
    {
      "epoch": 1.7909151636606546,
      "grad_norm": 3.4987878799438477,
      "learning_rate": 7.000448421743704e-06,
      "loss": 0.2072,
      "step": 2681
    },
    {
      "epoch": 1.7915831663326653,
      "grad_norm": 1.5778945684432983,
      "learning_rate": 6.993775959384168e-06,
      "loss": 0.0243,
      "step": 2682
    },
    {
      "epoch": 1.792251169004676,
      "grad_norm": 2.063211441040039,
      "learning_rate": 6.987104968100127e-06,
      "loss": 0.0566,
      "step": 2683
    },
    {
      "epoch": 1.7929191716766866,
      "grad_norm": 3.5848045349121094,
      "learning_rate": 6.980435451155987e-06,
      "loss": 0.1488,
      "step": 2684
    },
    {
      "epoch": 1.7935871743486973,
      "grad_norm": 9.997234344482422,
      "learning_rate": 6.973767411815426e-06,
      "loss": 0.3678,
      "step": 2685
    },
    {
      "epoch": 1.794255177020708,
      "grad_norm": 9.150728225708008,
      "learning_rate": 6.967100853341409e-06,
      "loss": 0.1532,
      "step": 2686
    },
    {
      "epoch": 1.7949231796927188,
      "grad_norm": 5.172848224639893,
      "learning_rate": 6.960435778996169e-06,
      "loss": 0.1771,
      "step": 2687
    },
    {
      "epoch": 1.7955911823647295,
      "grad_norm": 3.0433287620544434,
      "learning_rate": 6.9537721920412185e-06,
      "loss": 0.1546,
      "step": 2688
    },
    {
      "epoch": 1.7962591850367402,
      "grad_norm": 0.9303971529006958,
      "learning_rate": 6.947110095737337e-06,
      "loss": 0.0087,
      "step": 2689
    },
    {
      "epoch": 1.796927187708751,
      "grad_norm": 4.753009796142578,
      "learning_rate": 6.940449493344574e-06,
      "loss": 0.1732,
      "step": 2690
    },
    {
      "epoch": 1.7975951903807617,
      "grad_norm": 16.561182022094727,
      "learning_rate": 6.9337903881222555e-06,
      "loss": 0.2404,
      "step": 2691
    },
    {
      "epoch": 1.7982631930527722,
      "grad_norm": 0.06212937831878662,
      "learning_rate": 6.927132783328969e-06,
      "loss": 0.0008,
      "step": 2692
    },
    {
      "epoch": 1.7989311957247829,
      "grad_norm": 3.8371918201446533,
      "learning_rate": 6.920476682222563e-06,
      "loss": 0.0538,
      "step": 2693
    },
    {
      "epoch": 1.7995991983967936,
      "grad_norm": 4.178527355194092,
      "learning_rate": 6.9138220880601625e-06,
      "loss": 0.0949,
      "step": 2694
    },
    {
      "epoch": 1.8002672010688041,
      "grad_norm": 0.026049476116895676,
      "learning_rate": 6.907169004098144e-06,
      "loss": 0.0004,
      "step": 2695
    },
    {
      "epoch": 1.8009352037408148,
      "grad_norm": 5.363479137420654,
      "learning_rate": 6.900517433592151e-06,
      "loss": 0.2353,
      "step": 2696
    },
    {
      "epoch": 1.8016032064128256,
      "grad_norm": 5.587368011474609,
      "learning_rate": 6.893867379797085e-06,
      "loss": 0.1548,
      "step": 2697
    },
    {
      "epoch": 1.8022712090848363,
      "grad_norm": 1.1633515357971191,
      "learning_rate": 6.887218845967102e-06,
      "loss": 0.0376,
      "step": 2698
    },
    {
      "epoch": 1.802939211756847,
      "grad_norm": 3.8651580810546875,
      "learning_rate": 6.880571835355623e-06,
      "loss": 0.2183,
      "step": 2699
    },
    {
      "epoch": 1.8036072144288577,
      "grad_norm": 3.083190679550171,
      "learning_rate": 6.873926351215312e-06,
      "loss": 0.0829,
      "step": 2700
    },
    {
      "epoch": 1.8042752171008685,
      "grad_norm": 3.017427921295166,
      "learning_rate": 6.8672823967981e-06,
      "loss": 0.1667,
      "step": 2701
    },
    {
      "epoch": 1.8049432197728792,
      "grad_norm": 6.341733455657959,
      "learning_rate": 6.860639975355152e-06,
      "loss": 0.2132,
      "step": 2702
    },
    {
      "epoch": 1.80561122244489,
      "grad_norm": 2.7259671688079834,
      "learning_rate": 6.853999090136897e-06,
      "loss": 0.0202,
      "step": 2703
    },
    {
      "epoch": 1.8062792251169004,
      "grad_norm": 0.47281020879745483,
      "learning_rate": 6.847359744393005e-06,
      "loss": 0.0032,
      "step": 2704
    },
    {
      "epoch": 1.8069472277889111,
      "grad_norm": 3.3438422679901123,
      "learning_rate": 6.840721941372399e-06,
      "loss": 0.1274,
      "step": 2705
    },
    {
      "epoch": 1.8076152304609219,
      "grad_norm": 1.4754420518875122,
      "learning_rate": 6.8340856843232384e-06,
      "loss": 0.0632,
      "step": 2706
    },
    {
      "epoch": 1.8082832331329324,
      "grad_norm": 2.4831855297088623,
      "learning_rate": 6.827450976492936e-06,
      "loss": 0.0747,
      "step": 2707
    },
    {
      "epoch": 1.808951235804943,
      "grad_norm": 9.58777141571045,
      "learning_rate": 6.820817821128138e-06,
      "loss": 0.2427,
      "step": 2708
    },
    {
      "epoch": 1.8096192384769538,
      "grad_norm": 2.8107545375823975,
      "learning_rate": 6.8141862214747355e-06,
      "loss": 0.1802,
      "step": 2709
    },
    {
      "epoch": 1.8102872411489646,
      "grad_norm": 2.4303693771362305,
      "learning_rate": 6.807556180777861e-06,
      "loss": 0.0704,
      "step": 2710
    },
    {
      "epoch": 1.8109552438209753,
      "grad_norm": 2.614103078842163,
      "learning_rate": 6.800927702281872e-06,
      "loss": 0.1925,
      "step": 2711
    },
    {
      "epoch": 1.811623246492986,
      "grad_norm": 1.262574553489685,
      "learning_rate": 6.794300789230374e-06,
      "loss": 0.0147,
      "step": 2712
    },
    {
      "epoch": 1.8122912491649967,
      "grad_norm": 1.8962520360946655,
      "learning_rate": 6.787675444866204e-06,
      "loss": 0.0428,
      "step": 2713
    },
    {
      "epoch": 1.8129592518370075,
      "grad_norm": 3.4906811714172363,
      "learning_rate": 6.781051672431425e-06,
      "loss": 0.1842,
      "step": 2714
    },
    {
      "epoch": 1.8136272545090182,
      "grad_norm": 2.45837664604187,
      "learning_rate": 6.774429475167341e-06,
      "loss": 0.148,
      "step": 2715
    },
    {
      "epoch": 1.8142952571810287,
      "grad_norm": 0.28162235021591187,
      "learning_rate": 6.767808856314478e-06,
      "loss": 0.0031,
      "step": 2716
    },
    {
      "epoch": 1.8149632598530394,
      "grad_norm": 2.2434213161468506,
      "learning_rate": 6.761189819112587e-06,
      "loss": 0.0295,
      "step": 2717
    },
    {
      "epoch": 1.8156312625250501,
      "grad_norm": 0.03312617912888527,
      "learning_rate": 6.754572366800656e-06,
      "loss": 0.0005,
      "step": 2718
    },
    {
      "epoch": 1.8162992651970606,
      "grad_norm": 2.203205108642578,
      "learning_rate": 6.747956502616888e-06,
      "loss": 0.1222,
      "step": 2719
    },
    {
      "epoch": 1.8169672678690714,
      "grad_norm": 2.702003240585327,
      "learning_rate": 6.741342229798707e-06,
      "loss": 0.1899,
      "step": 2720
    },
    {
      "epoch": 1.817635270541082,
      "grad_norm": 11.692598342895508,
      "learning_rate": 6.734729551582771e-06,
      "loss": 0.552,
      "step": 2721
    },
    {
      "epoch": 1.8183032732130928,
      "grad_norm": 2.0337882041931152,
      "learning_rate": 6.728118471204943e-06,
      "loss": 0.068,
      "step": 2722
    },
    {
      "epoch": 1.8189712758851035,
      "grad_norm": 0.19038549065589905,
      "learning_rate": 6.721508991900312e-06,
      "loss": 0.0026,
      "step": 2723
    },
    {
      "epoch": 1.8196392785571143,
      "grad_norm": 1.886469841003418,
      "learning_rate": 6.714901116903185e-06,
      "loss": 0.1003,
      "step": 2724
    },
    {
      "epoch": 1.820307281229125,
      "grad_norm": 5.0861430168151855,
      "learning_rate": 6.708294849447078e-06,
      "loss": 0.2063,
      "step": 2725
    },
    {
      "epoch": 1.8209752839011357,
      "grad_norm": 1.2268829345703125,
      "learning_rate": 6.701690192764727e-06,
      "loss": 0.0212,
      "step": 2726
    },
    {
      "epoch": 1.8216432865731464,
      "grad_norm": 1.2232340574264526,
      "learning_rate": 6.695087150088071e-06,
      "loss": 0.008,
      "step": 2727
    },
    {
      "epoch": 1.822311289245157,
      "grad_norm": 3.2957661151885986,
      "learning_rate": 6.688485724648276e-06,
      "loss": 0.1275,
      "step": 2728
    },
    {
      "epoch": 1.8229792919171677,
      "grad_norm": 2.373464345932007,
      "learning_rate": 6.681885919675689e-06,
      "loss": 0.0802,
      "step": 2729
    },
    {
      "epoch": 1.8236472945891784,
      "grad_norm": 7.145394802093506,
      "learning_rate": 6.675287738399891e-06,
      "loss": 0.1964,
      "step": 2730
    },
    {
      "epoch": 1.824315297261189,
      "grad_norm": 0.05906536430120468,
      "learning_rate": 6.668691184049652e-06,
      "loss": 0.0008,
      "step": 2731
    },
    {
      "epoch": 1.8249832999331996,
      "grad_norm": 4.680846691131592,
      "learning_rate": 6.662096259852955e-06,
      "loss": 0.1269,
      "step": 2732
    },
    {
      "epoch": 1.8256513026052104,
      "grad_norm": 21.14930534362793,
      "learning_rate": 6.65550296903698e-06,
      "loss": 0.6223,
      "step": 2733
    },
    {
      "epoch": 1.826319305277221,
      "grad_norm": 0.015856890007853508,
      "learning_rate": 6.648911314828113e-06,
      "loss": 0.0003,
      "step": 2734
    },
    {
      "epoch": 1.8269873079492318,
      "grad_norm": 17.837915420532227,
      "learning_rate": 6.642321300451931e-06,
      "loss": 0.3625,
      "step": 2735
    },
    {
      "epoch": 1.8276553106212425,
      "grad_norm": 2.669966697692871,
      "learning_rate": 6.635732929133214e-06,
      "loss": 0.0187,
      "step": 2736
    },
    {
      "epoch": 1.8283233132932533,
      "grad_norm": 4.7442755699157715,
      "learning_rate": 6.629146204095942e-06,
      "loss": 0.136,
      "step": 2737
    },
    {
      "epoch": 1.828991315965264,
      "grad_norm": 1.4502066373825073,
      "learning_rate": 6.622561128563278e-06,
      "loss": 0.0728,
      "step": 2738
    },
    {
      "epoch": 1.8296593186372747,
      "grad_norm": 5.520856857299805,
      "learning_rate": 6.615977705757586e-06,
      "loss": 0.1792,
      "step": 2739
    },
    {
      "epoch": 1.8303273213092852,
      "grad_norm": 0.38440629839897156,
      "learning_rate": 6.609395938900422e-06,
      "loss": 0.0032,
      "step": 2740
    },
    {
      "epoch": 1.830995323981296,
      "grad_norm": 0.04907229542732239,
      "learning_rate": 6.602815831212528e-06,
      "loss": 0.0007,
      "step": 2741
    },
    {
      "epoch": 1.8316633266533067,
      "grad_norm": 1.100751519203186,
      "learning_rate": 6.596237385913834e-06,
      "loss": 0.06,
      "step": 2742
    },
    {
      "epoch": 1.8323313293253172,
      "grad_norm": 0.3770729899406433,
      "learning_rate": 6.58966060622346e-06,
      "loss": 0.0035,
      "step": 2743
    },
    {
      "epoch": 1.832999331997328,
      "grad_norm": 1.7813901901245117,
      "learning_rate": 6.583085495359708e-06,
      "loss": 0.0685,
      "step": 2744
    },
    {
      "epoch": 1.8336673346693386,
      "grad_norm": 3.128340721130371,
      "learning_rate": 6.5765120565400675e-06,
      "loss": 0.1862,
      "step": 2745
    },
    {
      "epoch": 1.8343353373413493,
      "grad_norm": 2.2369067668914795,
      "learning_rate": 6.569940292981202e-06,
      "loss": 0.0213,
      "step": 2746
    },
    {
      "epoch": 1.83500334001336,
      "grad_norm": 1.4531700611114502,
      "learning_rate": 6.56337020789896e-06,
      "loss": 0.0887,
      "step": 2747
    },
    {
      "epoch": 1.8356713426853708,
      "grad_norm": 13.721091270446777,
      "learning_rate": 6.556801804508368e-06,
      "loss": 0.268,
      "step": 2748
    },
    {
      "epoch": 1.8363393453573815,
      "grad_norm": 4.911805152893066,
      "learning_rate": 6.550235086023636e-06,
      "loss": 0.0475,
      "step": 2749
    },
    {
      "epoch": 1.8370073480293923,
      "grad_norm": 4.284163951873779,
      "learning_rate": 6.543670055658134e-06,
      "loss": 0.138,
      "step": 2750
    },
    {
      "epoch": 1.8376753507014028,
      "grad_norm": 2.7640926837921143,
      "learning_rate": 6.537106716624423e-06,
      "loss": 0.1524,
      "step": 2751
    },
    {
      "epoch": 1.8383433533734135,
      "grad_norm": 5.414822578430176,
      "learning_rate": 6.530545072134225e-06,
      "loss": 0.3384,
      "step": 2752
    },
    {
      "epoch": 1.8390113560454242,
      "grad_norm": 3.7943105697631836,
      "learning_rate": 6.523985125398439e-06,
      "loss": 0.1472,
      "step": 2753
    },
    {
      "epoch": 1.8396793587174347,
      "grad_norm": 5.106864929199219,
      "learning_rate": 6.517426879627131e-06,
      "loss": 0.062,
      "step": 2754
    },
    {
      "epoch": 1.8403473613894454,
      "grad_norm": 0.7804569602012634,
      "learning_rate": 6.510870338029532e-06,
      "loss": 0.0094,
      "step": 2755
    },
    {
      "epoch": 1.8410153640614562,
      "grad_norm": 0.06518200784921646,
      "learning_rate": 6.504315503814041e-06,
      "loss": 0.0011,
      "step": 2756
    },
    {
      "epoch": 1.8416833667334669,
      "grad_norm": 2.270103693008423,
      "learning_rate": 6.497762380188224e-06,
      "loss": 0.1718,
      "step": 2757
    },
    {
      "epoch": 1.8423513694054776,
      "grad_norm": 0.2774357497692108,
      "learning_rate": 6.491210970358807e-06,
      "loss": 0.0029,
      "step": 2758
    },
    {
      "epoch": 1.8430193720774883,
      "grad_norm": 4.456607341766357,
      "learning_rate": 6.484661277531678e-06,
      "loss": 0.0778,
      "step": 2759
    },
    {
      "epoch": 1.843687374749499,
      "grad_norm": 2.56416654586792,
      "learning_rate": 6.478113304911886e-06,
      "loss": 0.1241,
      "step": 2760
    },
    {
      "epoch": 1.8443553774215098,
      "grad_norm": 0.7905250787734985,
      "learning_rate": 6.47156705570364e-06,
      "loss": 0.0086,
      "step": 2761
    },
    {
      "epoch": 1.8450233800935205,
      "grad_norm": 0.046059444546699524,
      "learning_rate": 6.465022533110299e-06,
      "loss": 0.0009,
      "step": 2762
    },
    {
      "epoch": 1.845691382765531,
      "grad_norm": 5.031114101409912,
      "learning_rate": 6.458479740334382e-06,
      "loss": 0.2057,
      "step": 2763
    },
    {
      "epoch": 1.8463593854375417,
      "grad_norm": 2.120201349258423,
      "learning_rate": 6.451938680577559e-06,
      "loss": 0.1413,
      "step": 2764
    },
    {
      "epoch": 1.8470273881095525,
      "grad_norm": 24.190073013305664,
      "learning_rate": 6.445399357040657e-06,
      "loss": 0.404,
      "step": 2765
    },
    {
      "epoch": 1.847695390781563,
      "grad_norm": 1.6013989448547363,
      "learning_rate": 6.4388617729236455e-06,
      "loss": 0.0375,
      "step": 2766
    },
    {
      "epoch": 1.8483633934535737,
      "grad_norm": 6.325222969055176,
      "learning_rate": 6.432325931425654e-06,
      "loss": 0.3636,
      "step": 2767
    },
    {
      "epoch": 1.8490313961255844,
      "grad_norm": 3.4933207035064697,
      "learning_rate": 6.425791835744946e-06,
      "loss": 0.1081,
      "step": 2768
    },
    {
      "epoch": 1.8496993987975952,
      "grad_norm": 2.555590867996216,
      "learning_rate": 6.41925948907894e-06,
      "loss": 0.1227,
      "step": 2769
    },
    {
      "epoch": 1.8503674014696059,
      "grad_norm": 0.09389714896678925,
      "learning_rate": 6.412728894624195e-06,
      "loss": 0.0013,
      "step": 2770
    },
    {
      "epoch": 1.8510354041416166,
      "grad_norm": 5.728804588317871,
      "learning_rate": 6.406200055576414e-06,
      "loss": 0.2691,
      "step": 2771
    },
    {
      "epoch": 1.8517034068136273,
      "grad_norm": 0.33310237526893616,
      "learning_rate": 6.3996729751304446e-06,
      "loss": 0.0039,
      "step": 2772
    },
    {
      "epoch": 1.852371409485638,
      "grad_norm": 12.14593505859375,
      "learning_rate": 6.393147656480262e-06,
      "loss": 0.316,
      "step": 2773
    },
    {
      "epoch": 1.8530394121576488,
      "grad_norm": 4.32020902633667,
      "learning_rate": 6.3866241028189914e-06,
      "loss": 0.1122,
      "step": 2774
    },
    {
      "epoch": 1.8537074148296593,
      "grad_norm": 2.9970481395721436,
      "learning_rate": 6.380102317338887e-06,
      "loss": 0.2173,
      "step": 2775
    },
    {
      "epoch": 1.85437541750167,
      "grad_norm": 3.4010465145111084,
      "learning_rate": 6.3735823032313435e-06,
      "loss": 0.1394,
      "step": 2776
    },
    {
      "epoch": 1.8550434201736807,
      "grad_norm": 5.327027320861816,
      "learning_rate": 6.367064063686884e-06,
      "loss": 0.3197,
      "step": 2777
    },
    {
      "epoch": 1.8557114228456912,
      "grad_norm": 2.5904617309570312,
      "learning_rate": 6.360547601895169e-06,
      "loss": 0.1378,
      "step": 2778
    },
    {
      "epoch": 1.856379425517702,
      "grad_norm": 0.1408872753381729,
      "learning_rate": 6.354032921044979e-06,
      "loss": 0.0011,
      "step": 2779
    },
    {
      "epoch": 1.8570474281897127,
      "grad_norm": 4.586174964904785,
      "learning_rate": 6.3475200243242345e-06,
      "loss": 0.1868,
      "step": 2780
    },
    {
      "epoch": 1.8577154308617234,
      "grad_norm": 1.224170446395874,
      "learning_rate": 6.3410089149199785e-06,
      "loss": 0.0081,
      "step": 2781
    },
    {
      "epoch": 1.8583834335337341,
      "grad_norm": 0.26688718795776367,
      "learning_rate": 6.334499596018373e-06,
      "loss": 0.0026,
      "step": 2782
    },
    {
      "epoch": 1.8590514362057449,
      "grad_norm": 0.12041707336902618,
      "learning_rate": 6.327992070804711e-06,
      "loss": 0.0013,
      "step": 2783
    },
    {
      "epoch": 1.8597194388777556,
      "grad_norm": 2.567241668701172,
      "learning_rate": 6.3214863424634085e-06,
      "loss": 0.1465,
      "step": 2784
    },
    {
      "epoch": 1.8603874415497663,
      "grad_norm": 3.7304744720458984,
      "learning_rate": 6.314982414177997e-06,
      "loss": 0.2102,
      "step": 2785
    },
    {
      "epoch": 1.861055444221777,
      "grad_norm": 8.629049301147461,
      "learning_rate": 6.308480289131134e-06,
      "loss": 0.2497,
      "step": 2786
    },
    {
      "epoch": 1.8617234468937875,
      "grad_norm": 0.044905975461006165,
      "learning_rate": 6.3019799705045885e-06,
      "loss": 0.0006,
      "step": 2787
    },
    {
      "epoch": 1.8623914495657983,
      "grad_norm": 8.471861839294434,
      "learning_rate": 6.295481461479245e-06,
      "loss": 0.2576,
      "step": 2788
    },
    {
      "epoch": 1.863059452237809,
      "grad_norm": 14.618785858154297,
      "learning_rate": 6.288984765235109e-06,
      "loss": 0.5046,
      "step": 2789
    },
    {
      "epoch": 1.8637274549098195,
      "grad_norm": 2.1870856285095215,
      "learning_rate": 6.282489884951295e-06,
      "loss": 0.1283,
      "step": 2790
    },
    {
      "epoch": 1.8643954575818302,
      "grad_norm": 0.663895308971405,
      "learning_rate": 6.275996823806025e-06,
      "loss": 0.0046,
      "step": 2791
    },
    {
      "epoch": 1.865063460253841,
      "grad_norm": 0.33744627237319946,
      "learning_rate": 6.26950558497664e-06,
      "loss": 0.0038,
      "step": 2792
    },
    {
      "epoch": 1.8657314629258517,
      "grad_norm": 3.1360151767730713,
      "learning_rate": 6.26301617163958e-06,
      "loss": 0.1951,
      "step": 2793
    },
    {
      "epoch": 1.8663994655978624,
      "grad_norm": 0.2387341856956482,
      "learning_rate": 6.256528586970395e-06,
      "loss": 0.0018,
      "step": 2794
    },
    {
      "epoch": 1.8670674682698731,
      "grad_norm": 2.9348373413085938,
      "learning_rate": 6.250042834143746e-06,
      "loss": 0.0982,
      "step": 2795
    },
    {
      "epoch": 1.8677354709418839,
      "grad_norm": 1.849568486213684,
      "learning_rate": 6.2435589163333865e-06,
      "loss": 0.0269,
      "step": 2796
    },
    {
      "epoch": 1.8684034736138946,
      "grad_norm": 2.401569366455078,
      "learning_rate": 6.237076836712184e-06,
      "loss": 0.0877,
      "step": 2797
    },
    {
      "epoch": 1.8690714762859053,
      "grad_norm": 0.4266090989112854,
      "learning_rate": 6.230596598452094e-06,
      "loss": 0.0035,
      "step": 2798
    },
    {
      "epoch": 1.8697394789579158,
      "grad_norm": 13.665571212768555,
      "learning_rate": 6.224118204724186e-06,
      "loss": 0.7069,
      "step": 2799
    },
    {
      "epoch": 1.8704074816299265,
      "grad_norm": 9.35159683227539,
      "learning_rate": 6.217641658698612e-06,
      "loss": 0.3555,
      "step": 2800
    },
    {
      "epoch": 1.871075484301937,
      "grad_norm": 1.5103199481964111,
      "learning_rate": 6.211166963544626e-06,
      "loss": 0.112,
      "step": 2801
    },
    {
      "epoch": 1.8717434869739478,
      "grad_norm": 6.810654163360596,
      "learning_rate": 6.204694122430577e-06,
      "loss": 0.1609,
      "step": 2802
    },
    {
      "epoch": 1.8724114896459585,
      "grad_norm": 0.3906777501106262,
      "learning_rate": 6.198223138523909e-06,
      "loss": 0.0034,
      "step": 2803
    },
    {
      "epoch": 1.8730794923179692,
      "grad_norm": 2.55389142036438,
      "learning_rate": 6.1917540149911505e-06,
      "loss": 0.1751,
      "step": 2804
    },
    {
      "epoch": 1.87374749498998,
      "grad_norm": 0.20883484184741974,
      "learning_rate": 6.1852867549979275e-06,
      "loss": 0.002,
      "step": 2805
    },
    {
      "epoch": 1.8744154976619907,
      "grad_norm": 2.7806556224823,
      "learning_rate": 6.178821361708946e-06,
      "loss": 0.2109,
      "step": 2806
    },
    {
      "epoch": 1.8750835003340014,
      "grad_norm": 2.325408935546875,
      "learning_rate": 6.1723578382880125e-06,
      "loss": 0.0794,
      "step": 2807
    },
    {
      "epoch": 1.8757515030060121,
      "grad_norm": 0.020174073055386543,
      "learning_rate": 6.165896187897994e-06,
      "loss": 0.0003,
      "step": 2808
    },
    {
      "epoch": 1.8764195056780228,
      "grad_norm": 3.3411293029785156,
      "learning_rate": 6.159436413700864e-06,
      "loss": 0.1584,
      "step": 2809
    },
    {
      "epoch": 1.8770875083500334,
      "grad_norm": 0.1627403050661087,
      "learning_rate": 6.152978518857669e-06,
      "loss": 0.0017,
      "step": 2810
    },
    {
      "epoch": 1.877755511022044,
      "grad_norm": 0.032398100942373276,
      "learning_rate": 6.146522506528535e-06,
      "loss": 0.0004,
      "step": 2811
    },
    {
      "epoch": 1.8784235136940548,
      "grad_norm": 4.38653564453125,
      "learning_rate": 6.140068379872668e-06,
      "loss": 0.1117,
      "step": 2812
    },
    {
      "epoch": 1.8790915163660653,
      "grad_norm": 1.9504352807998657,
      "learning_rate": 6.133616142048353e-06,
      "loss": 0.0633,
      "step": 2813
    },
    {
      "epoch": 1.879759519038076,
      "grad_norm": 1.6471571922302246,
      "learning_rate": 6.12716579621295e-06,
      "loss": 0.0632,
      "step": 2814
    },
    {
      "epoch": 1.8804275217100868,
      "grad_norm": 2.4996840953826904,
      "learning_rate": 6.120717345522889e-06,
      "loss": 0.1529,
      "step": 2815
    },
    {
      "epoch": 1.8810955243820975,
      "grad_norm": 3.5087709426879883,
      "learning_rate": 6.114270793133679e-06,
      "loss": 0.1079,
      "step": 2816
    },
    {
      "epoch": 1.8817635270541082,
      "grad_norm": 2.8785295486450195,
      "learning_rate": 6.107826142199895e-06,
      "loss": 0.0994,
      "step": 2817
    },
    {
      "epoch": 1.882431529726119,
      "grad_norm": 0.06543712317943573,
      "learning_rate": 6.101383395875183e-06,
      "loss": 0.0011,
      "step": 2818
    },
    {
      "epoch": 1.8830995323981297,
      "grad_norm": 10.127190589904785,
      "learning_rate": 6.09494255731226e-06,
      "loss": 0.3272,
      "step": 2819
    },
    {
      "epoch": 1.8837675350701404,
      "grad_norm": 0.14721740782260895,
      "learning_rate": 6.088503629662906e-06,
      "loss": 0.0012,
      "step": 2820
    },
    {
      "epoch": 1.8844355377421511,
      "grad_norm": 5.465529441833496,
      "learning_rate": 6.082066616077964e-06,
      "loss": 0.0546,
      "step": 2821
    },
    {
      "epoch": 1.8851035404141616,
      "grad_norm": 13.219554901123047,
      "learning_rate": 6.075631519707349e-06,
      "loss": 0.3849,
      "step": 2822
    },
    {
      "epoch": 1.8857715430861723,
      "grad_norm": 0.14272800087928772,
      "learning_rate": 6.069198343700027e-06,
      "loss": 0.0014,
      "step": 2823
    },
    {
      "epoch": 1.886439545758183,
      "grad_norm": 2.041602849960327,
      "learning_rate": 6.0627670912040316e-06,
      "loss": 0.0367,
      "step": 2824
    },
    {
      "epoch": 1.8871075484301936,
      "grad_norm": 3.218036413192749,
      "learning_rate": 6.056337765366456e-06,
      "loss": 0.1465,
      "step": 2825
    },
    {
      "epoch": 1.8877755511022043,
      "grad_norm": 0.4434228241443634,
      "learning_rate": 6.049910369333441e-06,
      "loss": 0.0045,
      "step": 2826
    },
    {
      "epoch": 1.888443553774215,
      "grad_norm": 7.351701259613037,
      "learning_rate": 6.043484906250192e-06,
      "loss": 0.2479,
      "step": 2827
    },
    {
      "epoch": 1.8891115564462257,
      "grad_norm": 0.04642453417181969,
      "learning_rate": 6.037061379260969e-06,
      "loss": 0.0006,
      "step": 2828
    },
    {
      "epoch": 1.8897795591182365,
      "grad_norm": 2.538705825805664,
      "learning_rate": 6.0306397915090765e-06,
      "loss": 0.1735,
      "step": 2829
    },
    {
      "epoch": 1.8904475617902472,
      "grad_norm": 0.1783725470304489,
      "learning_rate": 6.0242201461368796e-06,
      "loss": 0.0013,
      "step": 2830
    },
    {
      "epoch": 1.891115564462258,
      "grad_norm": 2.112994432449341,
      "learning_rate": 6.017802446285786e-06,
      "loss": 0.0645,
      "step": 2831
    },
    {
      "epoch": 1.8917835671342687,
      "grad_norm": 3.976271152496338,
      "learning_rate": 6.011386695096257e-06,
      "loss": 0.2575,
      "step": 2832
    },
    {
      "epoch": 1.8924515698062794,
      "grad_norm": 5.931666851043701,
      "learning_rate": 6.0049728957077965e-06,
      "loss": 0.1187,
      "step": 2833
    },
    {
      "epoch": 1.8931195724782899,
      "grad_norm": 8.141884803771973,
      "learning_rate": 5.998561051258953e-06,
      "loss": 0.0513,
      "step": 2834
    },
    {
      "epoch": 1.8937875751503006,
      "grad_norm": 0.15999969840049744,
      "learning_rate": 5.9921511648873164e-06,
      "loss": 0.0021,
      "step": 2835
    },
    {
      "epoch": 1.8944555778223113,
      "grad_norm": 6.378645896911621,
      "learning_rate": 5.9857432397295266e-06,
      "loss": 0.3245,
      "step": 2836
    },
    {
      "epoch": 1.8951235804943218,
      "grad_norm": 2.4600398540496826,
      "learning_rate": 5.979337278921254e-06,
      "loss": 0.1276,
      "step": 2837
    },
    {
      "epoch": 1.8957915831663326,
      "grad_norm": 5.2066850662231445,
      "learning_rate": 5.972933285597217e-06,
      "loss": 0.0591,
      "step": 2838
    },
    {
      "epoch": 1.8964595858383433,
      "grad_norm": 1.508067011833191,
      "learning_rate": 5.966531262891164e-06,
      "loss": 0.0129,
      "step": 2839
    },
    {
      "epoch": 1.897127588510354,
      "grad_norm": 1.2462677955627441,
      "learning_rate": 5.96013121393588e-06,
      "loss": 0.0478,
      "step": 2840
    },
    {
      "epoch": 1.8977955911823647,
      "grad_norm": 7.996589183807373,
      "learning_rate": 5.953733141863189e-06,
      "loss": 0.2664,
      "step": 2841
    },
    {
      "epoch": 1.8984635938543755,
      "grad_norm": 1.917492151260376,
      "learning_rate": 5.9473370498039425e-06,
      "loss": 0.137,
      "step": 2842
    },
    {
      "epoch": 1.8991315965263862,
      "grad_norm": 2.4609923362731934,
      "learning_rate": 5.940942940888031e-06,
      "loss": 0.0236,
      "step": 2843
    },
    {
      "epoch": 1.899799599198397,
      "grad_norm": 0.032623954117298126,
      "learning_rate": 5.934550818244361e-06,
      "loss": 0.0006,
      "step": 2844
    },
    {
      "epoch": 1.9004676018704076,
      "grad_norm": 5.155665874481201,
      "learning_rate": 5.928160685000874e-06,
      "loss": 0.2463,
      "step": 2845
    },
    {
      "epoch": 1.9011356045424181,
      "grad_norm": 1.3738356828689575,
      "learning_rate": 5.9217725442845465e-06,
      "loss": 0.0151,
      "step": 2846
    },
    {
      "epoch": 1.9018036072144289,
      "grad_norm": 1.1471762657165527,
      "learning_rate": 5.915386399221367e-06,
      "loss": 0.0647,
      "step": 2847
    },
    {
      "epoch": 1.9024716098864396,
      "grad_norm": 4.671694755554199,
      "learning_rate": 5.90900225293635e-06,
      "loss": 0.0808,
      "step": 2848
    },
    {
      "epoch": 1.90313961255845,
      "grad_norm": 3.5603747367858887,
      "learning_rate": 5.902620108553541e-06,
      "loss": 0.0397,
      "step": 2849
    },
    {
      "epoch": 1.9038076152304608,
      "grad_norm": 3.5060527324676514,
      "learning_rate": 5.896239969195994e-06,
      "loss": 0.1576,
      "step": 2850
    },
    {
      "epoch": 1.9044756179024716,
      "grad_norm": 0.26970499753952026,
      "learning_rate": 5.889861837985791e-06,
      "loss": 0.0022,
      "step": 2851
    },
    {
      "epoch": 1.9051436205744823,
      "grad_norm": 2.3846683502197266,
      "learning_rate": 5.8834857180440285e-06,
      "loss": 0.0604,
      "step": 2852
    },
    {
      "epoch": 1.905811623246493,
      "grad_norm": 0.03256542608141899,
      "learning_rate": 5.877111612490813e-06,
      "loss": 0.0005,
      "step": 2853
    },
    {
      "epoch": 1.9064796259185037,
      "grad_norm": 0.0539461188018322,
      "learning_rate": 5.87073952444527e-06,
      "loss": 0.0006,
      "step": 2854
    },
    {
      "epoch": 1.9071476285905145,
      "grad_norm": 1.1624369621276855,
      "learning_rate": 5.864369457025543e-06,
      "loss": 0.0076,
      "step": 2855
    },
    {
      "epoch": 1.9078156312625252,
      "grad_norm": 4.226470470428467,
      "learning_rate": 5.858001413348777e-06,
      "loss": 0.2697,
      "step": 2856
    },
    {
      "epoch": 1.9084836339345357,
      "grad_norm": 3.06905198097229,
      "learning_rate": 5.851635396531135e-06,
      "loss": 0.1242,
      "step": 2857
    },
    {
      "epoch": 1.9091516366065464,
      "grad_norm": 2.8954944610595703,
      "learning_rate": 5.84527140968778e-06,
      "loss": 0.0502,
      "step": 2858
    },
    {
      "epoch": 1.9098196392785571,
      "grad_norm": 0.09732886403799057,
      "learning_rate": 5.838909455932893e-06,
      "loss": 0.001,
      "step": 2859
    },
    {
      "epoch": 1.9104876419505676,
      "grad_norm": 3.071704149246216,
      "learning_rate": 5.832549538379651e-06,
      "loss": 0.1782,
      "step": 2860
    },
    {
      "epoch": 1.9111556446225784,
      "grad_norm": 3.888092279434204,
      "learning_rate": 5.826191660140229e-06,
      "loss": 0.2398,
      "step": 2861
    },
    {
      "epoch": 1.911823647294589,
      "grad_norm": 4.585902690887451,
      "learning_rate": 5.819835824325823e-06,
      "loss": 0.1404,
      "step": 2862
    },
    {
      "epoch": 1.9124916499665998,
      "grad_norm": 1.8542184829711914,
      "learning_rate": 5.813482034046609e-06,
      "loss": 0.1038,
      "step": 2863
    },
    {
      "epoch": 1.9131596526386105,
      "grad_norm": 2.121511936187744,
      "learning_rate": 5.807130292411776e-06,
      "loss": 0.0966,
      "step": 2864
    },
    {
      "epoch": 1.9138276553106213,
      "grad_norm": 1.1398496627807617,
      "learning_rate": 5.800780602529506e-06,
      "loss": 0.0088,
      "step": 2865
    },
    {
      "epoch": 1.914495657982632,
      "grad_norm": 0.01859535649418831,
      "learning_rate": 5.7944329675069795e-06,
      "loss": 0.0003,
      "step": 2866
    },
    {
      "epoch": 1.9151636606546427,
      "grad_norm": 5.057049751281738,
      "learning_rate": 5.788087390450364e-06,
      "loss": 0.2008,
      "step": 2867
    },
    {
      "epoch": 1.9158316633266534,
      "grad_norm": 3.8155741691589355,
      "learning_rate": 5.781743874464827e-06,
      "loss": 0.176,
      "step": 2868
    },
    {
      "epoch": 1.916499665998664,
      "grad_norm": 0.4986487329006195,
      "learning_rate": 5.775402422654529e-06,
      "loss": 0.0054,
      "step": 2869
    },
    {
      "epoch": 1.9171676686706747,
      "grad_norm": 0.5810790061950684,
      "learning_rate": 5.7690630381226134e-06,
      "loss": 0.0041,
      "step": 2870
    },
    {
      "epoch": 1.9178356713426854,
      "grad_norm": 0.08485814929008484,
      "learning_rate": 5.762725723971212e-06,
      "loss": 0.0008,
      "step": 2871
    },
    {
      "epoch": 1.918503674014696,
      "grad_norm": 6.073153018951416,
      "learning_rate": 5.756390483301448e-06,
      "loss": 0.1125,
      "step": 2872
    },
    {
      "epoch": 1.9191716766867066,
      "grad_norm": 6.0853071212768555,
      "learning_rate": 5.750057319213437e-06,
      "loss": 0.1972,
      "step": 2873
    },
    {
      "epoch": 1.9198396793587174,
      "grad_norm": 3.9523322582244873,
      "learning_rate": 5.743726234806259e-06,
      "loss": 0.0311,
      "step": 2874
    },
    {
      "epoch": 1.920507682030728,
      "grad_norm": 2.0371007919311523,
      "learning_rate": 5.737397233177993e-06,
      "loss": 0.0553,
      "step": 2875
    },
    {
      "epoch": 1.9211756847027388,
      "grad_norm": 4.760241985321045,
      "learning_rate": 5.731070317425692e-06,
      "loss": 0.2147,
      "step": 2876
    },
    {
      "epoch": 1.9218436873747495,
      "grad_norm": 10.371074676513672,
      "learning_rate": 5.724745490645396e-06,
      "loss": 0.4166,
      "step": 2877
    },
    {
      "epoch": 1.9225116900467603,
      "grad_norm": 0.07374821603298187,
      "learning_rate": 5.71842275593211e-06,
      "loss": 0.0006,
      "step": 2878
    },
    {
      "epoch": 1.923179692718771,
      "grad_norm": 2.4539873600006104,
      "learning_rate": 5.7121021163798184e-06,
      "loss": 0.1325,
      "step": 2879
    },
    {
      "epoch": 1.9238476953907817,
      "grad_norm": 0.48997876048088074,
      "learning_rate": 5.705783575081487e-06,
      "loss": 0.0038,
      "step": 2880
    },
    {
      "epoch": 1.9245156980627922,
      "grad_norm": 0.09327011555433273,
      "learning_rate": 5.6994671351290575e-06,
      "loss": 0.0009,
      "step": 2881
    },
    {
      "epoch": 1.925183700734803,
      "grad_norm": 6.361788272857666,
      "learning_rate": 5.693152799613428e-06,
      "loss": 0.2493,
      "step": 2882
    },
    {
      "epoch": 1.9258517034068137,
      "grad_norm": 0.0671042948961258,
      "learning_rate": 5.686840571624479e-06,
      "loss": 0.0008,
      "step": 2883
    },
    {
      "epoch": 1.9265197060788242,
      "grad_norm": 13.106527328491211,
      "learning_rate": 5.680530454251059e-06,
      "loss": 0.3641,
      "step": 2884
    },
    {
      "epoch": 1.927187708750835,
      "grad_norm": 0.05027145892381668,
      "learning_rate": 5.674222450580984e-06,
      "loss": 0.0006,
      "step": 2885
    },
    {
      "epoch": 1.9278557114228456,
      "grad_norm": 0.19583407044410706,
      "learning_rate": 5.667916563701026e-06,
      "loss": 0.0022,
      "step": 2886
    },
    {
      "epoch": 1.9285237140948563,
      "grad_norm": 5.0029473304748535,
      "learning_rate": 5.661612796696935e-06,
      "loss": 0.2643,
      "step": 2887
    },
    {
      "epoch": 1.929191716766867,
      "grad_norm": 4.4377665519714355,
      "learning_rate": 5.6553111526534085e-06,
      "loss": 0.1985,
      "step": 2888
    },
    {
      "epoch": 1.9298597194388778,
      "grad_norm": 2.77288818359375,
      "learning_rate": 5.649011634654125e-06,
      "loss": 0.0259,
      "step": 2889
    },
    {
      "epoch": 1.9305277221108885,
      "grad_norm": 3.730163335800171,
      "learning_rate": 5.6427142457817e-06,
      "loss": 0.1015,
      "step": 2890
    },
    {
      "epoch": 1.9311957247828992,
      "grad_norm": 5.5562028884887695,
      "learning_rate": 5.636418989117723e-06,
      "loss": 0.1221,
      "step": 2891
    },
    {
      "epoch": 1.93186372745491,
      "grad_norm": 0.0236018318682909,
      "learning_rate": 5.630125867742741e-06,
      "loss": 0.0004,
      "step": 2892
    },
    {
      "epoch": 1.9325317301269205,
      "grad_norm": 19.47378921508789,
      "learning_rate": 5.62383488473624e-06,
      "loss": 0.6694,
      "step": 2893
    },
    {
      "epoch": 1.9331997327989312,
      "grad_norm": 0.011362590827047825,
      "learning_rate": 5.617546043176676e-06,
      "loss": 0.0003,
      "step": 2894
    },
    {
      "epoch": 1.933867735470942,
      "grad_norm": 1.5232868194580078,
      "learning_rate": 5.611259346141451e-06,
      "loss": 0.0183,
      "step": 2895
    },
    {
      "epoch": 1.9345357381429524,
      "grad_norm": 2.6121809482574463,
      "learning_rate": 5.604974796706921e-06,
      "loss": 0.0201,
      "step": 2896
    },
    {
      "epoch": 1.9352037408149632,
      "grad_norm": 0.02768111415207386,
      "learning_rate": 5.598692397948385e-06,
      "loss": 0.0004,
      "step": 2897
    },
    {
      "epoch": 1.9358717434869739,
      "grad_norm": 2.4813108444213867,
      "learning_rate": 5.592412152940088e-06,
      "loss": 0.0486,
      "step": 2898
    },
    {
      "epoch": 1.9365397461589846,
      "grad_norm": 4.135622024536133,
      "learning_rate": 5.586134064755231e-06,
      "loss": 0.0941,
      "step": 2899
    },
    {
      "epoch": 1.9372077488309953,
      "grad_norm": 7.499017715454102,
      "learning_rate": 5.579858136465956e-06,
      "loss": 0.4073,
      "step": 2900
    },
    {
      "epoch": 1.937875751503006,
      "grad_norm": 0.5958297848701477,
      "learning_rate": 5.573584371143339e-06,
      "loss": 0.004,
      "step": 2901
    },
    {
      "epoch": 1.9385437541750168,
      "grad_norm": 0.12301227450370789,
      "learning_rate": 5.567312771857409e-06,
      "loss": 0.0011,
      "step": 2902
    },
    {
      "epoch": 1.9392117568470275,
      "grad_norm": 0.022744007408618927,
      "learning_rate": 5.561043341677131e-06,
      "loss": 0.0003,
      "step": 2903
    },
    {
      "epoch": 1.9398797595190382,
      "grad_norm": 0.18762408196926117,
      "learning_rate": 5.5547760836704125e-06,
      "loss": 0.0019,
      "step": 2904
    },
    {
      "epoch": 1.9405477621910487,
      "grad_norm": 2.4107141494750977,
      "learning_rate": 5.548511000904091e-06,
      "loss": 0.0992,
      "step": 2905
    },
    {
      "epoch": 1.9412157648630595,
      "grad_norm": 20.27765464782715,
      "learning_rate": 5.542248096443936e-06,
      "loss": 0.6107,
      "step": 2906
    },
    {
      "epoch": 1.9418837675350702,
      "grad_norm": 0.012972085736691952,
      "learning_rate": 5.5359873733546636e-06,
      "loss": 0.0003,
      "step": 2907
    },
    {
      "epoch": 1.9425517702070807,
      "grad_norm": 7.8262457847595215,
      "learning_rate": 5.52972883469992e-06,
      "loss": 0.2724,
      "step": 2908
    },
    {
      "epoch": 1.9432197728790914,
      "grad_norm": 1.7688713073730469,
      "learning_rate": 5.523472483542271e-06,
      "loss": 0.149,
      "step": 2909
    },
    {
      "epoch": 1.9438877755511021,
      "grad_norm": 0.01822379231452942,
      "learning_rate": 5.517218322943224e-06,
      "loss": 0.0003,
      "step": 2910
    },
    {
      "epoch": 1.9445557782231129,
      "grad_norm": 5.266509056091309,
      "learning_rate": 5.51096635596321e-06,
      "loss": 0.279,
      "step": 2911
    },
    {
      "epoch": 1.9452237808951236,
      "grad_norm": 5.131836891174316,
      "learning_rate": 5.5047165856615915e-06,
      "loss": 0.179,
      "step": 2912
    },
    {
      "epoch": 1.9458917835671343,
      "grad_norm": 0.010364959016442299,
      "learning_rate": 5.498469015096647e-06,
      "loss": 0.0002,
      "step": 2913
    },
    {
      "epoch": 1.946559786239145,
      "grad_norm": 2.0534045696258545,
      "learning_rate": 5.492223647325579e-06,
      "loss": 0.131,
      "step": 2914
    },
    {
      "epoch": 1.9472277889111558,
      "grad_norm": 6.060097694396973,
      "learning_rate": 5.485980485404521e-06,
      "loss": 0.209,
      "step": 2915
    },
    {
      "epoch": 1.9478957915831663,
      "grad_norm": 0.39423149824142456,
      "learning_rate": 5.4797395323885265e-06,
      "loss": 0.004,
      "step": 2916
    },
    {
      "epoch": 1.948563794255177,
      "grad_norm": 8.081321716308594,
      "learning_rate": 5.473500791331554e-06,
      "loss": 0.2102,
      "step": 2917
    },
    {
      "epoch": 1.9492317969271877,
      "grad_norm": 4.530712127685547,
      "learning_rate": 5.467264265286494e-06,
      "loss": 0.0889,
      "step": 2918
    },
    {
      "epoch": 1.9498997995991982,
      "grad_norm": 1.6309632062911987,
      "learning_rate": 5.461029957305154e-06,
      "loss": 0.0179,
      "step": 2919
    },
    {
      "epoch": 1.950567802271209,
      "grad_norm": 1.1762738227844238,
      "learning_rate": 5.454797870438241e-06,
      "loss": 0.0069,
      "step": 2920
    },
    {
      "epoch": 1.9512358049432197,
      "grad_norm": 4.996862888336182,
      "learning_rate": 5.448568007735391e-06,
      "loss": 0.1423,
      "step": 2921
    },
    {
      "epoch": 1.9519038076152304,
      "grad_norm": 5.510782718658447,
      "learning_rate": 5.442340372245145e-06,
      "loss": 0.21,
      "step": 2922
    },
    {
      "epoch": 1.9525718102872411,
      "grad_norm": 7.97096061706543,
      "learning_rate": 5.436114967014952e-06,
      "loss": 0.2274,
      "step": 2923
    },
    {
      "epoch": 1.9532398129592519,
      "grad_norm": 2.3157870769500732,
      "learning_rate": 5.429891795091176e-06,
      "loss": 0.0253,
      "step": 2924
    },
    {
      "epoch": 1.9539078156312626,
      "grad_norm": 0.13392652571201324,
      "learning_rate": 5.423670859519079e-06,
      "loss": 0.0011,
      "step": 2925
    },
    {
      "epoch": 1.9545758183032733,
      "grad_norm": 0.2165621966123581,
      "learning_rate": 5.417452163342835e-06,
      "loss": 0.0014,
      "step": 2926
    },
    {
      "epoch": 1.955243820975284,
      "grad_norm": 10.415045738220215,
      "learning_rate": 5.4112357096055276e-06,
      "loss": 0.295,
      "step": 2927
    },
    {
      "epoch": 1.9559118236472945,
      "grad_norm": 0.4764462113380432,
      "learning_rate": 5.405021501349128e-06,
      "loss": 0.0042,
      "step": 2928
    },
    {
      "epoch": 1.9565798263193053,
      "grad_norm": 2.6946401596069336,
      "learning_rate": 5.39880954161452e-06,
      "loss": 0.1191,
      "step": 2929
    },
    {
      "epoch": 1.957247828991316,
      "grad_norm": 0.8570851683616638,
      "learning_rate": 5.392599833441487e-06,
      "loss": 0.0083,
      "step": 2930
    },
    {
      "epoch": 1.9579158316633265,
      "grad_norm": 0.8939826488494873,
      "learning_rate": 5.386392379868712e-06,
      "loss": 0.0095,
      "step": 2931
    },
    {
      "epoch": 1.9585838343353372,
      "grad_norm": 3.5846290588378906,
      "learning_rate": 5.3801871839337585e-06,
      "loss": 0.1182,
      "step": 2932
    },
    {
      "epoch": 1.959251837007348,
      "grad_norm": 0.009843244217336178,
      "learning_rate": 5.373984248673103e-06,
      "loss": 0.0003,
      "step": 2933
    },
    {
      "epoch": 1.9599198396793587,
      "grad_norm": 3.1637868881225586,
      "learning_rate": 5.36778357712211e-06,
      "loss": 0.131,
      "step": 2934
    },
    {
      "epoch": 1.9605878423513694,
      "grad_norm": 0.7736606001853943,
      "learning_rate": 5.361585172315042e-06,
      "loss": 0.0064,
      "step": 2935
    },
    {
      "epoch": 1.9612558450233801,
      "grad_norm": 2.195472002029419,
      "learning_rate": 5.355389037285037e-06,
      "loss": 0.142,
      "step": 2936
    },
    {
      "epoch": 1.9619238476953909,
      "grad_norm": 6.347877502441406,
      "learning_rate": 5.349195175064137e-06,
      "loss": 0.243,
      "step": 2937
    },
    {
      "epoch": 1.9625918503674016,
      "grad_norm": 0.37705671787261963,
      "learning_rate": 5.3430035886832695e-06,
      "loss": 0.0047,
      "step": 2938
    },
    {
      "epoch": 1.9632598530394123,
      "grad_norm": 4.216427326202393,
      "learning_rate": 5.33681428117224e-06,
      "loss": 0.1342,
      "step": 2939
    },
    {
      "epoch": 1.9639278557114228,
      "grad_norm": 4.985275745391846,
      "learning_rate": 5.33062725555975e-06,
      "loss": 0.2209,
      "step": 2940
    },
    {
      "epoch": 1.9645958583834335,
      "grad_norm": 2.00380277633667,
      "learning_rate": 5.324442514873372e-06,
      "loss": 0.092,
      "step": 2941
    },
    {
      "epoch": 1.9652638610554443,
      "grad_norm": 2.3678901195526123,
      "learning_rate": 5.3182600621395704e-06,
      "loss": 0.0818,
      "step": 2942
    },
    {
      "epoch": 1.9659318637274548,
      "grad_norm": 0.2747271955013275,
      "learning_rate": 5.312079900383693e-06,
      "loss": 0.0025,
      "step": 2943
    },
    {
      "epoch": 1.9665998663994655,
      "grad_norm": 0.013766273856163025,
      "learning_rate": 5.30590203262995e-06,
      "loss": 0.0003,
      "step": 2944
    },
    {
      "epoch": 1.9672678690714762,
      "grad_norm": 0.4821408987045288,
      "learning_rate": 5.299726461901445e-06,
      "loss": 0.0037,
      "step": 2945
    },
    {
      "epoch": 1.967935871743487,
      "grad_norm": 3.517551898956299,
      "learning_rate": 5.2935531912201555e-06,
      "loss": 0.1772,
      "step": 2946
    },
    {
      "epoch": 1.9686038744154977,
      "grad_norm": 12.535399436950684,
      "learning_rate": 5.28738222360692e-06,
      "loss": 0.3274,
      "step": 2947
    },
    {
      "epoch": 1.9692718770875084,
      "grad_norm": 2.4118525981903076,
      "learning_rate": 5.281213562081466e-06,
      "loss": 0.1846,
      "step": 2948
    },
    {
      "epoch": 1.9699398797595191,
      "grad_norm": 2.8961057662963867,
      "learning_rate": 5.2750472096623916e-06,
      "loss": 0.1542,
      "step": 2949
    },
    {
      "epoch": 1.9706078824315298,
      "grad_norm": 0.26693373918533325,
      "learning_rate": 5.268883169367148e-06,
      "loss": 0.0023,
      "step": 2950
    },
    {
      "epoch": 1.9712758851035406,
      "grad_norm": 2.5281288623809814,
      "learning_rate": 5.262721444212079e-06,
      "loss": 0.0987,
      "step": 2951
    },
    {
      "epoch": 1.971943887775551,
      "grad_norm": 6.762090682983398,
      "learning_rate": 5.256562037212372e-06,
      "loss": 0.1075,
      "step": 2952
    },
    {
      "epoch": 1.9726118904475618,
      "grad_norm": 1.5645509958267212,
      "learning_rate": 5.250404951382098e-06,
      "loss": 0.0419,
      "step": 2953
    },
    {
      "epoch": 1.9732798931195725,
      "grad_norm": 3.349184513092041,
      "learning_rate": 5.244250189734188e-06,
      "loss": 0.1294,
      "step": 2954
    },
    {
      "epoch": 1.973947895791583,
      "grad_norm": 0.3115711808204651,
      "learning_rate": 5.238097755280425e-06,
      "loss": 0.0022,
      "step": 2955
    },
    {
      "epoch": 1.9746158984635938,
      "grad_norm": 0.11601492762565613,
      "learning_rate": 5.231947651031466e-06,
      "loss": 0.0012,
      "step": 2956
    },
    {
      "epoch": 1.9752839011356045,
      "grad_norm": 5.539061546325684,
      "learning_rate": 5.225799879996823e-06,
      "loss": 0.1958,
      "step": 2957
    },
    {
      "epoch": 1.9759519038076152,
      "grad_norm": 3.6861281394958496,
      "learning_rate": 5.219654445184875e-06,
      "loss": 0.1229,
      "step": 2958
    },
    {
      "epoch": 1.976619906479626,
      "grad_norm": 3.0189368724823,
      "learning_rate": 5.213511349602831e-06,
      "loss": 0.1406,
      "step": 2959
    },
    {
      "epoch": 1.9772879091516367,
      "grad_norm": 6.416662693023682,
      "learning_rate": 5.207370596256785e-06,
      "loss": 0.2793,
      "step": 2960
    },
    {
      "epoch": 1.9779559118236474,
      "grad_norm": 0.09206978976726532,
      "learning_rate": 5.20123218815167e-06,
      "loss": 0.0013,
      "step": 2961
    },
    {
      "epoch": 1.978623914495658,
      "grad_norm": 0.27317479252815247,
      "learning_rate": 5.195096128291279e-06,
      "loss": 0.0035,
      "step": 2962
    },
    {
      "epoch": 1.9792919171676688,
      "grad_norm": 0.5705099701881409,
      "learning_rate": 5.188962419678247e-06,
      "loss": 0.0053,
      "step": 2963
    },
    {
      "epoch": 1.9799599198396793,
      "grad_norm": 0.7607130408287048,
      "learning_rate": 5.182831065314062e-06,
      "loss": 0.0051,
      "step": 2964
    },
    {
      "epoch": 1.98062792251169,
      "grad_norm": 0.03203689306974411,
      "learning_rate": 5.176702068199069e-06,
      "loss": 0.0003,
      "step": 2965
    },
    {
      "epoch": 1.9812959251837008,
      "grad_norm": 0.1371910721063614,
      "learning_rate": 5.170575431332442e-06,
      "loss": 0.0013,
      "step": 2966
    },
    {
      "epoch": 1.9819639278557113,
      "grad_norm": 2.6700496673583984,
      "learning_rate": 5.164451157712217e-06,
      "loss": 0.0443,
      "step": 2967
    },
    {
      "epoch": 1.982631930527722,
      "grad_norm": 0.14211034774780273,
      "learning_rate": 5.158329250335259e-06,
      "loss": 0.0015,
      "step": 2968
    },
    {
      "epoch": 1.9832999331997327,
      "grad_norm": 6.998907089233398,
      "learning_rate": 5.152209712197285e-06,
      "loss": 0.0563,
      "step": 2969
    },
    {
      "epoch": 1.9839679358717435,
      "grad_norm": 2.8565385341644287,
      "learning_rate": 5.1460925462928545e-06,
      "loss": 0.1882,
      "step": 2970
    },
    {
      "epoch": 1.9846359385437542,
      "grad_norm": 0.023323677480220795,
      "learning_rate": 5.139977755615354e-06,
      "loss": 0.0003,
      "step": 2971
    },
    {
      "epoch": 1.985303941215765,
      "grad_norm": 5.7597832679748535,
      "learning_rate": 5.133865343157018e-06,
      "loss": 0.228,
      "step": 2972
    },
    {
      "epoch": 1.9859719438877756,
      "grad_norm": 0.8631914258003235,
      "learning_rate": 5.127755311908919e-06,
      "loss": 0.0072,
      "step": 2973
    },
    {
      "epoch": 1.9866399465597864,
      "grad_norm": 0.2032591998577118,
      "learning_rate": 5.1216476648609526e-06,
      "loss": 0.0016,
      "step": 2974
    },
    {
      "epoch": 1.9873079492317969,
      "grad_norm": 3.732595920562744,
      "learning_rate": 5.115542405001861e-06,
      "loss": 0.134,
      "step": 2975
    },
    {
      "epoch": 1.9879759519038076,
      "grad_norm": 0.5814498662948608,
      "learning_rate": 5.109439535319205e-06,
      "loss": 0.0091,
      "step": 2976
    },
    {
      "epoch": 1.9886439545758183,
      "grad_norm": 0.40848708152770996,
      "learning_rate": 5.103339058799391e-06,
      "loss": 0.0046,
      "step": 2977
    },
    {
      "epoch": 1.9893119572478288,
      "grad_norm": 6.2084760665893555,
      "learning_rate": 5.097240978427638e-06,
      "loss": 0.0679,
      "step": 2978
    },
    {
      "epoch": 1.9899799599198396,
      "grad_norm": 0.38090863823890686,
      "learning_rate": 5.091145297188003e-06,
      "loss": 0.0041,
      "step": 2979
    },
    {
      "epoch": 1.9906479625918503,
      "grad_norm": 0.03934559226036072,
      "learning_rate": 5.085052018063367e-06,
      "loss": 0.0004,
      "step": 2980
    },
    {
      "epoch": 1.991315965263861,
      "grad_norm": 2.79226016998291,
      "learning_rate": 5.078961144035443e-06,
      "loss": 0.1267,
      "step": 2981
    },
    {
      "epoch": 1.9919839679358717,
      "grad_norm": 6.9964118003845215,
      "learning_rate": 5.072872678084746e-06,
      "loss": 0.0186,
      "step": 2982
    },
    {
      "epoch": 1.9926519706078825,
      "grad_norm": 2.052438735961914,
      "learning_rate": 5.066786623190633e-06,
      "loss": 0.0528,
      "step": 2983
    },
    {
      "epoch": 1.9933199732798932,
      "grad_norm": 0.41543933749198914,
      "learning_rate": 5.060702982331276e-06,
      "loss": 0.004,
      "step": 2984
    },
    {
      "epoch": 1.993987975951904,
      "grad_norm": 1.7170350551605225,
      "learning_rate": 5.054621758483662e-06,
      "loss": 0.03,
      "step": 2985
    },
    {
      "epoch": 1.9946559786239146,
      "grad_norm": 2.5923352241516113,
      "learning_rate": 5.04854295462359e-06,
      "loss": 0.068,
      "step": 2986
    },
    {
      "epoch": 1.9953239812959251,
      "grad_norm": 4.031283855438232,
      "learning_rate": 5.042466573725688e-06,
      "loss": 0.08,
      "step": 2987
    },
    {
      "epoch": 1.9959919839679359,
      "grad_norm": 0.06200939789414406,
      "learning_rate": 5.0363926187633925e-06,
      "loss": 0.0007,
      "step": 2988
    },
    {
      "epoch": 1.9966599866399466,
      "grad_norm": 3.868673801422119,
      "learning_rate": 5.030321092708954e-06,
      "loss": 0.1538,
      "step": 2989
    },
    {
      "epoch": 1.997327989311957,
      "grad_norm": 3.698941230773926,
      "learning_rate": 5.024251998533427e-06,
      "loss": 0.1236,
      "step": 2990
    },
    {
      "epoch": 1.9979959919839678,
      "grad_norm": 16.602767944335938,
      "learning_rate": 5.018185339206686e-06,
      "loss": 0.3975,
      "step": 2991
    },
    {
      "epoch": 1.9986639946559785,
      "grad_norm": 11.173315048217773,
      "learning_rate": 5.012121117697412e-06,
      "loss": 0.421,
      "step": 2992
    },
    {
      "epoch": 1.9993319973279893,
      "grad_norm": 0.1297881007194519,
      "learning_rate": 5.0060593369730885e-06,
      "loss": 0.0015,
      "step": 2993
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.362758636474609,
      "learning_rate": 5.000000000000003e-06,
      "loss": 0.1331,
      "step": 2994
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.47904191616766467,
      "eval_loss": 0.11859452724456787,
      "eval_runtime": 145.9799,
      "eval_samples_per_second": 1.144,
      "eval_steps_per_second": 1.144,
      "step": 2994
    }
  ],
  "logging_steps": 1,
  "max_steps": 4491,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0966141584625664e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
